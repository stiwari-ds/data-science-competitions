{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzG6jewfS8+PN8la8RLuHF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stiwari-ds/data-science-competitions/blob/main/zindi/landslide_prevention/notebooks/01_xgboost_direct.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "fMe_ffy2a_ac"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyde65PCala3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade xgboost\n",
        "!pip install --upgrade optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import time\n",
        "import warnings\n",
        "import subprocess\n",
        "\n",
        "gc.enable()\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.precision', 4)\n",
        "np.set_printoptions(precision=4)\n",
        "\n",
        "import xgboost\n",
        "import optuna\n",
        "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
        "\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.pruners import HyperbandPruner\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "\n",
        "SEED = 23\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "eKfBaXpBbBUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove cell to run future versions\n",
        "assert optuna.__version__ == '3.0.2', f'Change in Optuna version. Original notebook version: 3.0.2'\n",
        "assert xgboost.__version__ == '1.6.2', f'Change in XGBoost version. Original notebook version: 1.6.2'"
      ],
      "metadata": {
        "id": "QU6c1orQbm3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check GPU availability\n",
        "try:\n",
        "    subprocess.check_output('nvidia-smi')\n",
        "    HAVE_GPU = True\n",
        "except Exception:\n",
        "    HAVE_GPU = False\n",
        "\n",
        "print(f'GPU available: {HAVE_GPU}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBzLRr5pbr7Z",
        "outputId": "6e74585d-4b8b-4807-c7a4-88f41f0f2aed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_o0kubsb5bP",
        "outputId": "88fde959-aeef-410e-a03a-743ee4d0c665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "ZR_l09PCSu-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/drive/MyDrive/data_science_competitions/zindi/landslide_prevention/data'\n",
        "\n",
        "train = pd.read_csv(f'{DATA_PATH}/raw/train.csv')\n",
        "test = pd.read_csv(f'{DATA_PATH}/raw/test.csv')\n",
        "sample_sub = pd.read_csv(f'{DATA_PATH}/raw/sample_sub.csv')\n",
        "\n",
        "train_agg = pd.read_csv(f'{DATA_PATH}/processed/train_agg.csv')\n",
        "test_agg = pd.read_csv(f'{DATA_PATH}/processed/test_agg.csv')"
      ],
      "metadata": {
        "id": "NIx1p0eWSx2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET = train['Label']"
      ],
      "metadata": {
        "id": "qShBGGFfTMOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_features = [f for f in test.columns if f.endswith('geology')]\n",
        "cat_features.extend(['agg_geology_mode', 'agg_geology_nunique'])"
      ],
      "metadata": {
        "id": "M1RrGiUIUtdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(df: pd.DataFrame, is_train: bool = False) -> pd.DataFrame:\n",
        "    \n",
        "    df = df.drop('Sample_ID', axis=1)\n",
        "    if is_train:\n",
        "        df = df.drop('Label', axis=1)\n",
        "    \n",
        "    #reduce memory usage\n",
        "    def reduce_mem(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        for col in df.columns:\n",
        "            col_type = df[col].dtypes\n",
        "            if col_type in ['int16', 'int32', 'int64', 'float32', 'float64']:\n",
        "                c_min = df[col].min()\n",
        "                c_max = df[col].max()\n",
        "                if str(col_type).startswith('int'):\n",
        "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                        df[col] = df[col].astype(np.int8)\n",
        "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                        df[col] = df[col].astype(np.int16)\n",
        "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                        df[col] = df[col].astype(np.int32)\n",
        "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                        df[col] = df[col].astype(np.int64)\n",
        "                else:\n",
        "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                        df[col] = df[col].astype(np.float16)\n",
        "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                        df[col] = df[col].astype(np.float32)\n",
        "                    else:\n",
        "                        df[col] = df[col].astype(np.float64)\n",
        "        return df\n",
        "\n",
        "    df = reduce_mem(df)\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col in cat_features:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "eQg2ew0zTBA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = preprocess(train, is_train=True)\n",
        "test = preprocess(test)"
      ],
      "metadata": {
        "id": "pf6gCPe_WW3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_agg = preprocess(train_agg, is_train=True)\n",
        "test_agg = preprocess(test_agg)"
      ],
      "metadata": {
        "id": "p38C7Oh9WbZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gokKkhoxWi2v",
        "outputId": "eb3e41fc-6ff5-4eae-f474-3477019ee766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline"
      ],
      "metadata": {
        "id": "l-ZLgtRMrJDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_f1(y_true, pred_probs):\n",
        "    preds = (pred_probs >= 0.5).astype('int')\n",
        "    return -f1_score(y_true, preds) #'-' sign since it is evaluated as loss "
      ],
      "metadata": {
        "id": "8I4izzYFG99x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "scores_f1 = []\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "X, y = train, TARGET\n",
        "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
        "    X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n",
        "    X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n",
        "\n",
        "    model = XGBClassifier(\n",
        "        objective='binary:logistic',\n",
        "        tree_method='gpu_hist' if HAVE_GPU else 'hist',\n",
        "        enable_categorical=HAVE_GPU,\n",
        "        eval_metric=custom_f1,\n",
        "        early_stopping_rounds=50, \n",
        "        seed=SEED\n",
        "    ) \n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        verbose=0\n",
        "    )\n",
        "    val_preds = model.predict(X_val)\n",
        "\n",
        "    score = f1_score(y_val, val_preds, average='micro')\n",
        "    scores_f1.append(score)\n",
        "    print(f'Fold #{fold}: ({model.best_iteration} rounds) F1-score = {score:.5f}')\n",
        "    _ = gc.collect()\n",
        "\n",
        "print(f'\\nAvg F1-score = {np.mean(scores_f1):.5f} +/- {np.std(scores_f1):.5f}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccFthHeorwUe",
        "outputId": "f54802a9-d104-4408-8fcc-26d910fb5899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #0: (90 rounds) F1-score = 0.84860\n",
            "Fold #1: (89 rounds) F1-score = 0.85044\n",
            "Fold #2: (95 rounds) F1-score = 0.85274\n",
            "Fold #3: (39 rounds) F1-score = 0.85366\n",
            "Fold #4: (64 rounds) F1-score = 0.86464\n",
            "\n",
            "Avg F1-score = 0.85401 +/- 0.00560\n",
            "\n",
            "CPU times: user 28.1 s, sys: 93.1 ms, total: 28.2 s\n",
            "Wall time: 27.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVZEqwhQ2oi2"
      },
      "source": [
        "# Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3VeEFRe2oBe"
      },
      "outputs": [],
      "source": [
        "def objective(trial, data, base_params):\n",
        "\n",
        "    scores = []\n",
        "    X, y = data\n",
        "\n",
        "    param_grid = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, step=0.01),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 2, 20),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 20, step=0.1), #complexity-control\n",
        "        'alpha': trial.suggest_float('alpha', 0, 5, step=0.05), #L1-reg\n",
        "        'lambda': trial.suggest_float('lambda', 1e-3, 1e5, log=True), #L2-reg\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0, step=0.05),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0, step=0.05),\n",
        "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1.0, step=0.05),\n",
        "        'colsample_bynode': trial.suggest_float('colsample_bynode', 0.5, 1.0, step=0.05),\n",
        "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1, 4, step=0.05)\n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
        "        X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n",
        "        X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n",
        "        \n",
        "        model = XGBClassifier(**base_params, **param_grid)\n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            verbose=0\n",
        "        )\n",
        "        val_preds = model.predict(X_val)\n",
        "        scores.append(f1_score(y_val, val_preds))\n",
        "\n",
        "    return np.mean(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JCjxMSuT3Ep"
      },
      "outputs": [],
      "source": [
        "def tune_params(data, base_params, n_trials=10, direction='maximize'):\n",
        "    study = optuna.create_study(\n",
        "        sampler=TPESampler(seed=SEED),\n",
        "        pruner=HyperbandPruner(),\n",
        "        direction=direction\n",
        "    )\n",
        "    \n",
        "    study.optimize(\n",
        "        func=lambda trial: objective(trial, data, base_params),\n",
        "        n_trials=n_trials,\n",
        "        gc_after_trial=True\n",
        "    )\n",
        "    \n",
        "    return study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-89LWIEHeTr"
      },
      "source": [
        "# Cross-validation and experiment setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsTtaJBBYryk"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(data, model_params, verbose=True):\n",
        "    oof_preds = {}  #out-of-fold predictions on train set\n",
        "    test_preds = {} #predictions on test set for each fold\n",
        "    scores_f1 = [] #F1 scores on validation set\n",
        "\n",
        "    X, X_test, y = data\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
        "        X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n",
        "        X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n",
        "        \n",
        "        model = XGBClassifier(**model_params)\n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            verbose=0\n",
        "        )\n",
        "        val_preds = model.predict(X_val)\n",
        "        oof_preds.update(dict(zip(val_idx, val_preds)))\n",
        "        \n",
        "        test_preds[f'fold{fold}'] = model.predict(X_test)\n",
        "\n",
        "        f1 = f1_score(y_val, val_preds)\n",
        "        scores_f1.append(f1)\n",
        "        if verbose:\n",
        "            print(f'Fold #{fold}: ({model.best_iteration} rounds) F1 = {f1:.5f}')\n",
        "        \n",
        "        _ = gc.collect()\n",
        "\n",
        "    print(f'\\nAvg F1 = {np.mean(scores_f1):.5f} +/- {np.std(scores_f1):.5f}')\n",
        "    \n",
        "    oof_preds = pd.Series(oof_preds).sort_index()\n",
        "    test_preds = pd.DataFrame.from_dict(test_preds)\n",
        "    test_preds['mode'] = test_preds.mode(axis=1)[0]\n",
        "\n",
        "    return oof_preds, test_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0TOKMzxhRt-"
      },
      "outputs": [],
      "source": [
        "def run_experiment(data, n_trials=5):\n",
        "        \n",
        "    X, X_test, y = data\n",
        "    \n",
        "    base_params = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'n_estimators': 10000,\n",
        "        'booster': 'gbtree',\n",
        "        'eval_metric': custom_f1,\n",
        "        'early_stopping_rounds': 100,\n",
        "        'tree_method': 'gpu_hist' if HAVE_GPU else 'hist',\n",
        "        'predictor': 'gpu_predictor' if HAVE_GPU else 'cpu_predictor',\n",
        "        'enable_categorical': HAVE_GPU,\n",
        "        'verbosity': 1,\n",
        "        'seed': SEED\n",
        "    }\n",
        "    \n",
        "    print(f'---------------Hyperparameter tuning---------------')\n",
        "    study = tune_params(\n",
        "        data=(X, y), \n",
        "        base_params=base_params,\n",
        "        n_trials=n_trials,\n",
        "        direction='maximize'\n",
        "    )\n",
        "    print(f'Best trial: {study.best_trial.number} -> Best value(F1): {study.best_value:.5f}')\n",
        "    print(f'Best hyperparameters:')\n",
        "    for k, v in study.best_params.items():\n",
        "        print(f'{k:20} - {v}')\n",
        "    \n",
        "    model_params = {**base_params, **study.best_params}\n",
        "    print(f'-----------------Cross-validation------------------')\n",
        "    oof_preds, test_preds = evaluate_model(\n",
        "        data=(X, X_test, y), \n",
        "        model_params=model_params\n",
        "    )\n",
        "    return oof_preds, test_preds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oof_preds = pd.DataFrame()"
      ],
      "metadata": {
        "id": "Tp-vpGxPJoqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating submission files"
      ],
      "metadata": {
        "id": "77yayiraLXYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NOTEBOOK = '01'\n",
        "SUBMISSION_PATH = f'/content/drive/MyDrive/data_science_competitions/zindi/landslide_prevention/submissions/nb_{NOTEBOOK}'\n",
        "if not os.path.isdir(SUBMISSION_PATH):\n",
        "    os.makedirs(SUBMISSION_PATH)"
      ],
      "metadata": {
        "id": "NO44h9WwLaf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_submission_files(test_preds: pd.DataFrame, expt_num: int):\n",
        "    for col in (test_preds.columns):\n",
        "        sub = sample_sub.copy()\n",
        "        sub['Label'] = test_preds[col]\n",
        "        sub.to_csv(f'{SUBMISSION_PATH}/{expt_num}_{col}.csv', index=False)"
      ],
      "metadata": {
        "id": "SjlGeP1bLuw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test experiment"
      ],
      "metadata": {
        "id": "yC7npR_n949b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "o, t = run_experiment(\n",
        "    data=(train, test, TARGET),\n",
        "    n_trials=5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMeoZe-499ls",
        "outputId": "8730f3ca-afc5-440f-c947-654e22461da7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-09-30 11:24:10,967]\u001b[0m A new study created in memory with name: no-name-d8b15ffa-bdb6-497e-bc5f-10cfb943e9bc\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Hyperparameter tuning---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-09-30 11:24:26,082]\u001b[0m Trial 0 finished with value: 0.6198913647948433 and parameters: {'learning_rate': 0.16, 'max_depth': 12, 'min_child_weight': 16, 'gamma': 5.6000000000000005, 'alpha': 1.1, 'lambda': 308.87067834937415, 'subsample': 0.55, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.8, 'colsample_bynode': 0.7, 'scale_pos_weight': 1.0}. Best is trial 0 with value: 0.6198913647948433.\u001b[0m\n",
            "\u001b[32m[I 2022-09-30 11:24:36,961]\u001b[0m Trial 1 finished with value: 0.6071057089297426 and parameters: {'learning_rate': 0.27, 'max_depth': 11, 'min_child_weight': 7, 'gamma': 11.8, 'alpha': 4.9, 'lambda': 5764.3531133041315, 'subsample': 0.5, 'colsample_bytree': 0.65, 'colsample_bylevel': 0.65, 'colsample_bynode': 0.95, 'scale_pos_weight': 2.9000000000000004}. Best is trial 0 with value: 0.6198913647948433.\u001b[0m\n",
            "\u001b[32m[I 2022-09-30 11:25:09,619]\u001b[0m Trial 2 finished with value: 0.6881244931179191 and parameters: {'learning_rate': 0.04, 'max_depth': 3, 'min_child_weight': 19, 'gamma': 2.8000000000000003, 'alpha': 2.1, 'lambda': 0.5914465750030369, 'subsample': 0.95, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.95, 'colsample_bynode': 0.8500000000000001, 'scale_pos_weight': 1.35}. Best is trial 2 with value: 0.6881244931179191.\u001b[0m\n",
            "\u001b[32m[I 2022-09-30 11:25:20,085]\u001b[0m Trial 3 finished with value: 0.6833041448003101 and parameters: {'learning_rate': 0.18000000000000002, 'max_depth': 4, 'min_child_weight': 3, 'gamma': 16.7, 'alpha': 2.3000000000000003, 'lambda': 0.01977424141771114, 'subsample': 0.8, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8500000000000001, 'scale_pos_weight': 2.7}. Best is trial 2 with value: 0.6881244931179191.\u001b[0m\n",
            "\u001b[32m[I 2022-09-30 11:25:25,704]\u001b[0m Trial 4 finished with value: 0.554296610966653 and parameters: {'learning_rate': 0.060000000000000005, 'max_depth': 5, 'min_child_weight': 11, 'gamma': 7.9, 'alpha': 2.4000000000000004, 'lambda': 44250.555674768046, 'subsample': 0.95, 'colsample_bytree': 0.75, 'colsample_bylevel': 0.95, 'colsample_bynode': 0.95, 'scale_pos_weight': 1.7000000000000002}. Best is trial 2 with value: 0.6881244931179191.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: 2 -> Best value(F1): 0.68812\n",
            "Best hyperparameters:\n",
            "learning_rate        - 0.04\n",
            "max_depth            - 3\n",
            "min_child_weight     - 19\n",
            "gamma                - 2.8000000000000003\n",
            "alpha                - 2.1\n",
            "lambda               - 0.5914465750030369\n",
            "subsample            - 0.95\n",
            "colsample_bytree     - 0.7\n",
            "colsample_bylevel    - 0.95\n",
            "colsample_bynode     - 0.8500000000000001\n",
            "scale_pos_weight     - 1.35\n",
            "-----------------Cross-validation------------------\n",
            "Fold #0: (702 rounds) F1 = 0.67035\n",
            "Fold #1: (490 rounds) F1 = 0.69737\n",
            "Fold #2: (466 rounds) F1 = 0.69011\n",
            "Fold #3: (348 rounds) F1 = 0.67959\n",
            "Fold #4: (333 rounds) F1 = 0.70320\n",
            "\n",
            "Avg F1 = 0.68812 +/- 0.01188\n",
            "CPU times: user 1min 49s, sys: 625 ms, total: 1min 50s\n",
            "Wall time: 1min 48s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment 1: Original features"
      ],
      "metadata": {
        "id": "bzHQSwz3BUkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "oof_preds['1_1'], test_preds_1 = run_experiment(\n",
        "    data=(train, test, TARGET),\n",
        "    n_trials=100\n",
        ")"
      ],
      "metadata": {
        "id": "i60M-qrfJkbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_submission_files(test_preds_1, 1)"
      ],
      "metadata": {
        "id": "UElg_Jlxwhfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment 2: Created features"
      ],
      "metadata": {
        "id": "kBKD2aPUKoj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "created_features = [f for f in test_agg.columns \n",
        "                    if f.startswith('agg_') or f.startswith('grad_')]"
      ],
      "metadata": {
        "id": "oW4HCPmrKnmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "oof_preds['1_2'], test_preds_2 = run_experiment(\n",
        "    data=(train_agg[created_features], test_agg[created_features], TARGET),\n",
        "    n_trials=100\n",
        ")"
      ],
      "metadata": {
        "id": "e6tacNK7K-IA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_submission_files(test_preds_2, 2)"
      ],
      "metadata": {
        "id": "hTfFVMG2wlnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment 3: All features"
      ],
      "metadata": {
        "id": "uONb5uPwLLDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "oof_preds['1_3'], test_preds_3 = run_experiment(\n",
        "    data=(train_agg, test_agg, TARGET),\n",
        "    n_trials=100\n",
        ")"
      ],
      "metadata": {
        "id": "TFtYVWrNLKRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_submission_files(test_preds_3, 3)"
      ],
      "metadata": {
        "id": "KPiAjPHnM17m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Storing OOF predictions"
      ],
      "metadata": {
        "id": "jRbWtNEcwp5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oof_preds.to_csv(f'{SUBMISSION_PATH}/oof_preds.csv', index=False)"
      ],
      "metadata": {
        "id": "E2SCLtizmHix"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}