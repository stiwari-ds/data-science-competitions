{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP2idtR0CutVq00OHKA3mfu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stiwari-ds/data-science-competitions/blob/main/zindi/trailblazers_open2all/notebooks/02_lightgbm_goss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "HO96_P_uh3mj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oJGZ2XRPhK5A"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade optuna\n",
        "!pip install --upgrade lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import time\n",
        "import warnings\n",
        "import subprocess\n",
        "\n",
        "gc.enable()\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.precision', 4)\n",
        "np.set_printoptions(precision=4)\n",
        "\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.pruners import HyperbandPruner\n",
        "from optuna.integration.lightgbm import LightGBMPruningCallback\n",
        "\n",
        "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
        "\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "_t390KWjhZ-D"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove cell to run future versions\n",
        "assert optuna.__version__ == '3.0.2', f'Change in Optuna version. Original notebook version: 3.0.2'\n",
        "assert lgb.__version__ == '3.3.2', f'Change in CatBoost version. Original notebook version: 3.3.2'"
      ],
      "metadata": {
        "id": "NybqUn3whlFZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check GPU availability\n",
        "try:\n",
        "    subprocess.check_output('nvidia-smi')\n",
        "    HAVE_GPU = True\n",
        "except Exception:\n",
        "    HAVE_GPU = False\n",
        "\n",
        "print(f'GPU available: {HAVE_GPU}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUNg_6eUhluU",
        "outputId": "6293d4ea-0cba-441d-b924-fe7e1960cac0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 23\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "QZFT1zVDj31u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_o0kubsb5bP",
        "outputId": "56a1accb-c3ef-41d4-fe3d-0af419bc8689"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/drive/MyDrive/data_science_competitions/zindi/trailblazers_open2all/data'\n",
        "train = pd.read_csv(f'{DATA_PATH}/raw/train.csv')\n",
        "test = pd.read_csv(f'{DATA_PATH}/raw/test.csv')\n",
        "sample_sub = pd.read_csv(f'{DATA_PATH}/raw/sample_sub.csv')"
      ],
      "metadata": {
        "id": "Ts7dyuJcb59B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOTEBOOK = '02'\n",
        "SUBMISSION_PATH = f'/content/drive/MyDrive/data_science_competitions/zindi/trailblazers_open2all/submissions/nb_{NOTEBOOK}'\n",
        "if not os.path.isdir(SUBMISSION_PATH):\n",
        "    os.makedirs(SUBMISSION_PATH)"
      ],
      "metadata": {
        "id": "Fgq12dmvcBN_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "3rK34PzocQb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET = train['target']\n",
        "TEST_INDEX = test['Place_ID X Date'] #for submission files\n",
        "GROUPS = np.array(train['Place_ID']) #for GroupKFold cross-validation"
      ],
      "metadata": {
        "id": "m51lh19QHiPF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(df: pd.DataFrame, is_train: bool = False) -> pd.DataFrame:\n",
        "    #Convert date column to datetime type\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "    #Create date-based features\n",
        "    df['month'] = df['Date'].dt.month\n",
        "    df['day'] = df['Date'].dt.day\n",
        "    df['day_of_week'] = df['Date'].dt.day_of_week\n",
        "\n",
        "    #dropping non-feature columns\n",
        "    df = df.drop(labels=['Place_ID X Date', 'Place_ID', 'Date'], axis=1)\n",
        "    if is_train:\n",
        "        df = df.drop(\n",
        "            labels=['target', 'target_min', 'target_max', 'target_variance', 'target_count'], \n",
        "            axis=1\n",
        "        )\n",
        "    \n",
        "    #reduce memory usage\n",
        "    def reduce_mem(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        for col in df.columns:\n",
        "            col_type = df[col].dtypes\n",
        "            if col_type in ['int64', 'float64']:\n",
        "                c_min = df[col].min()\n",
        "                c_max = df[col].max()\n",
        "                if str(col_type).startswith('int'):\n",
        "                    if c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                        df[col] = df[col].astype(np.int16)\n",
        "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                        df[col] = df[col].astype(np.int32)\n",
        "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                        df[col] = df[col].astype(np.int64)\n",
        "                else:\n",
        "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                        df[col] = df[col].astype(np.float16)\n",
        "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                        df[col] = df[col].astype(np.float32)\n",
        "                    else:\n",
        "                        df[col] = df[col].astype(np.float64)\n",
        "        return df\n",
        "    \n",
        "    return reduce_mem(df)"
      ],
      "metadata": {
        "id": "2X_UZP6LcS3L"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = preprocess(train, is_train=True)\n",
        "test = preprocess(test)\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c_VjXFqVDzX",
        "outputId": "e7d1f059-0ba9-4d36-d4f3-687371b5086e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline"
      ],
      "metadata": {
        "id": "l-ZLgtRMrJDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "scores_rmse = []\n",
        "cv = GroupKFold(n_splits=5)\n",
        "X, y = train, TARGET\n",
        "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y, GROUPS)):\n",
        "    X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n",
        "    X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n",
        "\n",
        "    model = LGBMRegressor(\n",
        "        objective='regression',\n",
        "        boosting_type='goss',\n",
        "        device_type='cpu',\n",
        "        random_state=SEED\n",
        "    ) \n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        early_stopping_rounds=50,\n",
        "        eval_metric='rmse',\n",
        "        verbose=0\n",
        "    )\n",
        "    val_preds = model.predict(X_val)\n",
        "    score = mean_squared_error(y_val, val_preds, squared=False)\n",
        "    scores_rmse.append(score)\n",
        "    print(f'Fold #{fold}: ({model.best_iteration_} rounds) RMSE = {score:.5f}')\n",
        "    _ = gc.collect()\n",
        "\n",
        "print(f'\\nAvg RMSE = {np.mean(scores_rmse):.5f} +/- {np.std(scores_rmse):.5f}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccFthHeorwUe",
        "outputId": "d2326827-48ef-4ed5-abdb-4aa5b2d45ba8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #0: (100 rounds) RMSE = 34.89684\n",
            "Fold #1: (97 rounds) RMSE = 32.71991\n",
            "Fold #2: (96 rounds) RMSE = 29.08208\n",
            "Fold #3: (96 rounds) RMSE = 38.15012\n",
            "Fold #4: (89 rounds) RMSE = 30.54660\n",
            "\n",
            "Avg RMSE = 33.07911 +/- 3.21055\n",
            "\n",
            "CPU times: user 15.5 s, sys: 107 ms, total: 15.6 s\n",
            "Wall time: 8.53 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVZEqwhQ2oi2"
      },
      "source": [
        "# Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "i3VeEFRe2oBe"
      },
      "outputs": [],
      "source": [
        "def objective(trial, data, base_params):\n",
        "\n",
        "    scores = []\n",
        "    X, y = data\n",
        "\n",
        "    param_grid = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, step=0.01),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 200, step=0.1),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 200, step=0.1),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 100, 3000, step=5),\n",
        "        # 'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 0, 1000, step=5),\n",
        "        'min_split_gain': trial.suggest_float('min_split_gain', 0, 15, step=0.01),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.95, step=0.05),\n",
        "        # 'subsample': trial.suggest_float('subsample', 0.5, 0.95, step=0.05), #not for GOSS\n",
        "        # 'subsample_freq': trial.suggest_int('subsample_freq', 2, 25),\n",
        "        'top_rate': trial.suggest_float('top_rate', 0.1, 0.5, step=0.05),\n",
        "        'other_rate': trial.suggest_float('other_rate', 0.05, 0.5, step=0.05)\n",
        "    }\n",
        "\n",
        "    cv = GroupKFold(n_splits=5)\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y, GROUPS)):\n",
        "        X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n",
        "        X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n",
        "        \n",
        "        model = LGBMRegressor(**base_params, **param_grid)\n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            eval_metric='rmse',\n",
        "            early_stopping_rounds=100,\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "        scores.append(mean_squared_error(y_val, preds, squared=False))\n",
        "    return np.mean(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7JCjxMSuT3Ep"
      },
      "outputs": [],
      "source": [
        "def tune_params(data, base_params, n_trials=10, direction='maximize'):\n",
        "    study = optuna.create_study(\n",
        "        sampler=TPESampler(seed=SEED),\n",
        "        pruner=HyperbandPruner(),\n",
        "        direction=direction\n",
        "    )\n",
        "    \n",
        "    study.optimize(\n",
        "        func=lambda trial: objective(trial, data, base_params),\n",
        "        n_trials=n_trials,\n",
        "        gc_after_trial=True\n",
        "    )\n",
        "    \n",
        "    return study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-89LWIEHeTr"
      },
      "source": [
        "# Cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OsTtaJBBYryk"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(data, model_params, verbose=True):\n",
        "    oof_preds = {}  #out-of-fold predictions on train set\n",
        "    test_preds = {} #predictions on test set for each fold\n",
        "    scores_rmse = [] #RMSE scores on validation set\n",
        "\n",
        "    X, X_test, y = data\n",
        "\n",
        "    cv = GroupKFold(n_splits=5)\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y, GROUPS)):\n",
        "        X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n",
        "        X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n",
        "        \n",
        "        model = LGBMRegressor(**model_params)\n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            eval_metric='rmse',\n",
        "            early_stopping_rounds=100,\n",
        "            verbose=False\n",
        "        )\n",
        "        val_preds = model.predict(X_val)\n",
        "        oof_preds.update(dict(zip(val_idx, val_preds)))\n",
        "        test_preds[f'fold{fold}'] = model.predict(X_test)\n",
        "\n",
        "        score = mean_squared_error(y_val, val_preds, squared=False)\n",
        "        scores_rmse.append(score)\n",
        "        if verbose:\n",
        "            print(f'Fold #{fold}: ({model.best_iteration_} rounds) RMSE = {score:.5f}')\n",
        "        \n",
        "        _ = gc.collect()\n",
        "\n",
        "    print(f'\\nAvg RMSE = {np.mean(scores_rmse):.5f} +/- {np.std(scores_rmse):.5f}')\n",
        "    \n",
        "    oof_preds = pd.Series(oof_preds).sort_index()\n",
        "    print(f'OOF RMSE = {mean_squared_error(y, oof_preds, squared=False):.5f}')\n",
        "    \n",
        "    test_preds = pd.DataFrame.from_dict(test_preds)\n",
        "    return oof_preds, test_preds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(data, n_trials=5):\n",
        "        \n",
        "    X, X_test, y = data\n",
        "    \n",
        "    base_params = {\n",
        "        'objective': 'regression',\n",
        "        'n_estimators': 10000,\n",
        "        'boosting_type': 'goss',\n",
        "        'extra_trees': True,\n",
        "        'verbosity': -1,\n",
        "        'random_state': SEED\n",
        "    }\n",
        "    \n",
        "    print(f'---------------Hyperparameter tuning---------------')\n",
        "    study = tune_params(\n",
        "        data=(X, y), \n",
        "        base_params=base_params,\n",
        "        n_trials=n_trials,\n",
        "        direction='minimize'\n",
        "    )\n",
        "    print(f'Best trial: {study.best_trial.number} -> Best value(RMSE): {study.best_value:.5f}')\n",
        "    print(f'Best hyperparameters:')\n",
        "    for k, v in study.best_params.items():\n",
        "        print(f'{k:20} - {v}')\n",
        "    \n",
        "    model_params = {**base_params, **study.best_params}\n",
        "    print(f'-----------------Cross-validation------------------')\n",
        "    oof_preds, test_preds = evaluate_model(\n",
        "        data=(X, X_test, y), \n",
        "        model_params=model_params\n",
        "    )\n",
        "    return oof_preds, test_preds"
      ],
      "metadata": {
        "id": "uXqbo1dgkHoM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "oof_preds, test_preds = run_experiment(data=(train, test, TARGET), n_trials=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEj0Y9k02xzm",
        "outputId": "5ab0adfa-d4c1-4311-e2c8-9aecb171def7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-09-25 04:36:24,551]\u001b[0m A new study created in memory with name: no-name-b610ea52-344f-40b7-8709-5fc4cdfb9f4e\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------Hyperparameter tuning---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-09-25 04:37:24,718]\u001b[0m Trial 0 finished with value: 32.026635480181696 and parameters: {'learning_rate': 0.060000000000000005, 'reg_alpha': 189.4, 'reg_lambda': 153.1, 'num_leaves': 920, 'min_child_samples': 220, 'min_split_gain': 10.3, 'colsample_bytree': 0.55, 'top_rate': 0.25, 'other_rate': 0.35000000000000003}. Best is trial 0 with value: 32.026635480181696.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 04:38:33,366]\u001b[0m Trial 1 finished with value: 32.05208494339203 and parameters: {'learning_rate': 0.05, 'reg_alpha': 0.4, 'reg_lambda': 176.8, 'num_leaves': 2670, 'min_child_samples': 300, 'min_split_gain': 8.84, 'colsample_bytree': 0.95, 'top_rate': 0.45000000000000007, 'other_rate': 0.05}. Best is trial 0 with value: 32.026635480181696.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 04:40:34,785]\u001b[0m Trial 2 finished with value: 31.651630706390996 and parameters: {'learning_rate': 0.03, 'reg_alpha': 57.6, 'reg_lambda': 164.5, 'num_leaves': 1915, 'min_child_samples': 110, 'min_split_gain': 0.0, 'colsample_bytree': 0.95, 'top_rate': 0.15000000000000002, 'other_rate': 0.25}. Best is trial 2 with value: 31.651630706390996.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 04:41:04,154]\u001b[0m Trial 3 finished with value: 34.2441071146594 and parameters: {'learning_rate': 0.04, 'reg_alpha': 174.0, 'reg_lambda': 85.7, 'num_leaves': 2505, 'min_child_samples': 720, 'min_split_gain': 1.78, 'colsample_bytree': 0.75, 'top_rate': 0.15000000000000002, 'other_rate': 0.05}. Best is trial 2 with value: 31.651630706390996.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 04:41:53,942]\u001b[0m Trial 4 finished with value: 32.603799660111996 and parameters: {'learning_rate': 0.09, 'reg_alpha': 92.9, 'reg_lambda': 32.4, 'num_leaves': 1690, 'min_child_samples': 590, 'min_split_gain': 11.61, 'colsample_bytree': 0.8, 'top_rate': 0.35, 'other_rate': 0.1}. Best is trial 2 with value: 31.651630706390996.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 04:43:48,881]\u001b[0m Trial 5 finished with value: 32.37077971718185 and parameters: {'learning_rate': 0.03, 'reg_alpha': 101.2, 'reg_lambda': 79.30000000000001, 'num_leaves': 1500, 'min_child_samples': 960, 'min_split_gain': 13.530000000000001, 'colsample_bytree': 0.75, 'top_rate': 0.45000000000000007, 'other_rate': 0.45}. Best is trial 2 with value: 31.651630706390996.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 04:46:20,700]\u001b[0m Trial 6 finished with value: 31.317942911035686 and parameters: {'learning_rate': 0.03, 'reg_alpha': 15.8, 'reg_lambda': 93.10000000000001, 'num_leaves': 2650, 'min_child_samples': 145, 'min_split_gain': 3.47, 'colsample_bytree': 0.95, 'top_rate': 0.15000000000000002, 'other_rate': 0.5}. Best is trial 6 with value: 31.317942911035686.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 04:47:57,011]\u001b[0m Trial 7 finished with value: 32.415908622570306 and parameters: {'learning_rate': 0.03, 'reg_alpha': 123.2, 'reg_lambda': 190.4, 'num_leaves': 840, 'min_child_samples': 450, 'min_split_gain': 14.59, 'colsample_bytree': 0.6, 'top_rate': 0.15000000000000002, 'other_rate': 0.35000000000000003}. Best is trial 6 with value: 31.317942911035686.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 04:48:45,600]\u001b[0m Trial 8 finished with value: 31.4556526045454 and parameters: {'learning_rate': 0.09, 'reg_alpha': 90.7, 'reg_lambda': 20.200000000000003, 'num_leaves': 1905, 'min_child_samples': 80, 'min_split_gain': 0.79, 'colsample_bytree': 0.65, 'top_rate': 0.5, 'other_rate': 0.4}. Best is trial 6 with value: 31.317942911035686.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 04:50:18,313]\u001b[0m Trial 9 finished with value: 31.937275986563417 and parameters: {'learning_rate': 0.04, 'reg_alpha': 18.5, 'reg_lambda': 25.3, 'num_leaves': 1650, 'min_child_samples': 505, 'min_split_gain': 7.55, 'colsample_bytree': 0.55, 'top_rate': 0.45000000000000007, 'other_rate': 0.3}. Best is trial 6 with value: 31.317942911035686.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 04:59:07,159]\u001b[0m Trial 10 finished with value: 31.05776482209269 and parameters: {'learning_rate': 0.01, 'reg_alpha': 41.300000000000004, 'reg_lambda': 124.5, 'num_leaves': 2885, 'min_child_samples': 15, 'min_split_gain': 4.19, 'colsample_bytree': 0.8500000000000001, 'top_rate': 0.25, 'other_rate': 0.5}. Best is trial 10 with value: 31.05776482209269.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 05:07:29,104]\u001b[0m Trial 11 finished with value: 31.0988826696601 and parameters: {'learning_rate': 0.01, 'reg_alpha': 42.900000000000006, 'reg_lambda': 123.2, 'num_leaves': 2870, 'min_child_samples': 25, 'min_split_gain': 4.0600000000000005, 'colsample_bytree': 0.8500000000000001, 'top_rate': 0.25, 'other_rate': 0.5}. Best is trial 10 with value: 31.05776482209269.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 05:15:55,595]\u001b[0m Trial 12 finished with value: 31.09226832489741 and parameters: {'learning_rate': 0.01, 'reg_alpha': 50.5, 'reg_lambda': 125.30000000000001, 'num_leaves': 2970, 'min_child_samples': 30, 'min_split_gain': 4.8100000000000005, 'colsample_bytree': 0.8500000000000001, 'top_rate': 0.30000000000000004, 'other_rate': 0.5}. Best is trial 10 with value: 31.05776482209269.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 05:20:34,724]\u001b[0m Trial 13 finished with value: 31.988319684836256 and parameters: {'learning_rate': 0.01, 'reg_alpha': 56.7, 'reg_lambda': 126.80000000000001, 'num_leaves': 165, 'min_child_samples': 320, 'min_split_gain': 5.3100000000000005, 'colsample_bytree': 0.8500000000000001, 'top_rate': 0.30000000000000004, 'other_rate': 0.2}. Best is trial 10 with value: 31.05776482209269.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 05:29:25,204]\u001b[0m Trial 14 finished with value: 31.049861074398574 and parameters: {'learning_rate': 0.01, 'reg_alpha': 41.2, 'reg_lambda': 128.9, 'num_leaves': 2305, 'min_child_samples': 30, 'min_split_gain': 6.16, 'colsample_bytree': 0.8500000000000001, 'top_rate': 0.35, 'other_rate': 0.45}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 05:30:23,240]\u001b[0m Trial 15 finished with value: 31.836825127975203 and parameters: {'learning_rate': 0.06999999999999999, 'reg_alpha': 137.9, 'reg_lambda': 54.2, 'num_leaves': 2280, 'min_child_samples': 255, 'min_split_gain': 6.62, 'colsample_bytree': 0.7, 'top_rate': 0.35, 'other_rate': 0.4}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 05:33:50,308]\u001b[0m Trial 16 finished with value: 31.708592479995378 and parameters: {'learning_rate': 0.02, 'reg_alpha': 34.300000000000004, 'reg_lambda': 142.9, 'num_leaves': 2305, 'min_child_samples': 390, 'min_split_gain': 2.4, 'colsample_bytree': 0.9, 'top_rate': 0.25, 'other_rate': 0.45}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 05:35:52,727]\u001b[0m Trial 17 finished with value: 32.657700017977405 and parameters: {'learning_rate': 0.02, 'reg_alpha': 77.5, 'reg_lambda': 109.7, 'num_leaves': 2175, 'min_child_samples': 725, 'min_split_gain': 6.68, 'colsample_bytree': 0.8, 'top_rate': 0.35, 'other_rate': 0.2}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 05:36:40,433]\u001b[0m Trial 18 finished with value: 31.84570384648122 and parameters: {'learning_rate': 0.06999999999999999, 'reg_alpha': 70.4, 'reg_lambda': 58.300000000000004, 'num_leaves': 1220, 'min_child_samples': 200, 'min_split_gain': 9.25, 'colsample_bytree': 0.8, 'top_rate': 0.2, 'other_rate': 0.4}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 05:38:11,471]\u001b[0m Trial 19 finished with value: 31.190552024239643 and parameters: {'learning_rate': 0.09999999999999999, 'reg_alpha': 23.0, 'reg_lambda': 143.0, 'num_leaves': 2065, 'min_child_samples': 0, 'min_split_gain': 5.57, 'colsample_bytree': 0.9, 'top_rate': 0.4, 'other_rate': 0.45}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 05:39:53,145]\u001b[0m Trial 20 finished with value: 33.392087650267555 and parameters: {'learning_rate': 0.02, 'reg_alpha': 0.6000000000000001, 'reg_lambda': 2.0, 'num_leaves': 2500, 'min_child_samples': 940, 'min_split_gain': 2.73, 'colsample_bytree': 0.7, 'top_rate': 0.1, 'other_rate': 0.3}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 05:47:24,841]\u001b[0m Trial 21 finished with value: 31.243528875583166 and parameters: {'learning_rate': 0.01, 'reg_alpha': 45.400000000000006, 'reg_lambda': 114.2, 'num_leaves': 2990, 'min_child_samples': 110, 'min_split_gain': 4.43, 'colsample_bytree': 0.8500000000000001, 'top_rate': 0.30000000000000004, 'other_rate': 0.5}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 05:57:22,818]\u001b[0m Trial 22 finished with value: 31.05264163541013 and parameters: {'learning_rate': 0.01, 'reg_alpha': 67.60000000000001, 'reg_lambda': 128.5, 'num_leaves': 3000, 'min_child_samples': 5, 'min_split_gain': 5.51, 'colsample_bytree': 0.9, 'top_rate': 0.30000000000000004, 'other_rate': 0.5}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 06:00:59,041]\u001b[0m Trial 23 finished with value: 31.458829030081937 and parameters: {'learning_rate': 0.02, 'reg_alpha': 71.0, 'reg_lambda': 139.4, 'num_leaves': 2730, 'min_child_samples': 185, 'min_split_gain': 7.48, 'colsample_bytree': 0.9, 'top_rate': 0.4, 'other_rate': 0.45}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 06:09:25,830]\u001b[0m Trial 24 finished with value: 31.14999593840573 and parameters: {'learning_rate': 0.01, 'reg_alpha': 111.60000000000001, 'reg_lambda': 103.80000000000001, 'num_leaves': 2430, 'min_child_samples': 0, 'min_split_gain': 6.78, 'colsample_bytree': 0.9, 'top_rate': 0.25, 'other_rate': 0.5}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 06:11:29,560]\u001b[0m Trial 25 finished with value: 31.48616487963982 and parameters: {'learning_rate': 0.04, 'reg_alpha': 29.0, 'reg_lambda': 164.8, 'num_leaves': 2750, 'min_child_samples': 105, 'min_split_gain': 5.73, 'colsample_bytree': 0.8, 'top_rate': 0.2, 'other_rate': 0.4}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 06:14:28,999]\u001b[0m Trial 26 finished with value: 31.715170901402423 and parameters: {'learning_rate': 0.02, 'reg_alpha': 78.80000000000001, 'reg_lambda': 71.3, 'num_leaves': 2985, 'min_child_samples': 340, 'min_split_gain': 8.68, 'colsample_bytree': 0.75, 'top_rate': 0.35, 'other_rate': 0.35000000000000003}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 06:15:33,652]\u001b[0m Trial 27 finished with value: 31.727188908959135 and parameters: {'learning_rate': 0.05, 'reg_alpha': 147.0, 'reg_lambda': 103.2, 'num_leaves': 2525, 'min_child_samples': 165, 'min_split_gain': 3.02, 'colsample_bytree': 0.5, 'top_rate': 0.4, 'other_rate': 0.45}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 06:22:42,764]\u001b[0m Trial 28 finished with value: 31.27423955426674 and parameters: {'learning_rate': 0.01, 'reg_alpha': 62.400000000000006, 'reg_lambda': 191.3, 'num_leaves': 2770, 'min_child_samples': 75, 'min_split_gain': 1.4000000000000001, 'colsample_bytree': 0.9, 'top_rate': 0.2, 'other_rate': 0.5}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 06:23:57,500]\u001b[0m Trial 29 finished with value: 31.641463178029426 and parameters: {'learning_rate': 0.060000000000000005, 'reg_alpha': 36.9, 'reg_lambda': 154.20000000000002, 'num_leaves': 630, 'min_child_samples': 235, 'min_split_gain': 3.71, 'colsample_bytree': 0.8500000000000001, 'top_rate': 0.30000000000000004, 'other_rate': 0.35000000000000003}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 06:26:28,184]\u001b[0m Trial 30 finished with value: 32.21192938424247 and parameters: {'learning_rate': 0.02, 'reg_alpha': 185.3, 'reg_lambda': 131.9, 'num_leaves': 1260, 'min_child_samples': 620, 'min_split_gain': 8.02, 'colsample_bytree': 0.95, 'top_rate': 0.30000000000000004, 'other_rate': 0.45}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 06:33:51,316]\u001b[0m Trial 31 finished with value: 31.13236071735559 and parameters: {'learning_rate': 0.01, 'reg_alpha': 46.7, 'reg_lambda': 122.4, 'num_leaves': 2955, 'min_child_samples': 50, 'min_split_gain': 4.7700000000000005, 'colsample_bytree': 0.8500000000000001, 'top_rate': 0.30000000000000004, 'other_rate': 0.5}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 06:41:27,099]\u001b[0m Trial 32 finished with value: 31.222774402365634 and parameters: {'learning_rate': 0.01, 'reg_alpha': 58.300000000000004, 'reg_lambda': 152.8, 'num_leaves': 2680, 'min_child_samples': 45, 'min_split_gain': 4.7700000000000005, 'colsample_bytree': 0.8, 'top_rate': 0.25, 'other_rate': 0.5}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 06:45:30,151]\u001b[0m Trial 33 finished with value: 31.325017084446415 and parameters: {'learning_rate': 0.02, 'reg_alpha': 4.5, 'reg_lambda': 170.70000000000002, 'num_leaves': 2830, 'min_child_samples': 160, 'min_split_gain': 9.950000000000001, 'colsample_bytree': 0.9, 'top_rate': 0.35, 'other_rate': 0.4}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 06:47:40,944]\u001b[0m Trial 34 finished with value: 31.611438749405284 and parameters: {'learning_rate': 0.03, 'reg_alpha': 51.300000000000004, 'reg_lambda': 114.7, 'num_leaves': 2570, 'min_child_samples': 260, 'min_split_gain': 5.83, 'colsample_bytree': 0.95, 'top_rate': 0.25, 'other_rate': 0.45}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 06:53:23,851]\u001b[0m Trial 35 finished with value: 31.451875870833454 and parameters: {'learning_rate': 0.01, 'reg_alpha': 86.9, 'reg_lambda': 153.8, 'num_leaves': 2315, 'min_child_samples': 120, 'min_split_gain': 11.5, 'colsample_bytree': 0.8500000000000001, 'top_rate': 0.30000000000000004, 'other_rate': 0.5}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 06:55:59,490]\u001b[0m Trial 36 finished with value: 31.26138513931495 and parameters: {'learning_rate': 0.04, 'reg_alpha': 66.0, 'reg_lambda': 92.0, 'num_leaves': 2005, 'min_child_samples': 0, 'min_split_gain': 6.37, 'colsample_bytree': 0.75, 'top_rate': 0.4, 'other_rate': 0.1}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 06:58:02,205]\u001b[0m Trial 37 finished with value: 32.441692168990635 and parameters: {'learning_rate': 0.03, 'reg_alpha': 34.7, 'reg_lambda': 134.5, 'num_leaves': 2835, 'min_child_samples': 850, 'min_split_gain': 2.07, 'colsample_bytree': 0.95, 'top_rate': 0.2, 'other_rate': 0.45}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 07:01:39,243]\u001b[0m Trial 38 finished with value: 31.311893248388902 and parameters: {'learning_rate': 0.02, 'reg_alpha': 104.60000000000001, 'reg_lambda': 180.70000000000002, 'num_leaves': 1855, 'min_child_samples': 65, 'min_split_gain': 3.71, 'colsample_bytree': 0.8, 'top_rate': 0.35, 'other_rate': 0.5}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 07:03:21,046]\u001b[0m Trial 39 finished with value: 31.290540810185735 and parameters: {'learning_rate': 0.05, 'reg_alpha': 14.5, 'reg_lambda': 82.60000000000001, 'num_leaves': 2400, 'min_child_samples': 130, 'min_split_gain': 4.76, 'colsample_bytree': 0.8500000000000001, 'top_rate': 0.25, 'other_rate': 0.4}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 07:05:22,781]\u001b[0m Trial 40 finished with value: 31.854928014862132 and parameters: {'learning_rate': 0.03, 'reg_alpha': 77.30000000000001, 'reg_lambda': 93.5, 'num_leaves': 2625, 'min_child_samples': 395, 'min_split_gain': 7.47, 'colsample_bytree': 0.9, 'top_rate': 0.35, 'other_rate': 0.35000000000000003}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 07:13:56,237]\u001b[0m Trial 41 finished with value: 31.072681371566794 and parameters: {'learning_rate': 0.01, 'reg_alpha': 42.800000000000004, 'reg_lambda': 123.5, 'num_leaves': 2890, 'min_child_samples': 45, 'min_split_gain': 3.85, 'colsample_bytree': 0.8500000000000001, 'top_rate': 0.30000000000000004, 'other_rate': 0.5}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 07:21:50,865]\u001b[0m Trial 42 finished with value: 31.121560944604006 and parameters: {'learning_rate': 0.01, 'reg_alpha': 51.400000000000006, 'reg_lambda': 119.30000000000001, 'num_leaves': 2990, 'min_child_samples': 55, 'min_split_gain': 3.18, 'colsample_bytree': 0.8, 'top_rate': 0.30000000000000004, 'other_rate': 0.5}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 07:30:05,005]\u001b[0m Trial 43 finished with value: 31.148250607501403 and parameters: {'learning_rate': 0.01, 'reg_alpha': 24.900000000000002, 'reg_lambda': 128.3, 'num_leaves': 2865, 'min_child_samples': 95, 'min_split_gain': 0.26, 'colsample_bytree': 0.8500000000000001, 'top_rate': 0.30000000000000004, 'other_rate': 0.45}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 07:34:35,983]\u001b[0m Trial 44 finished with value: 31.13733007043563 and parameters: {'learning_rate': 0.02, 'reg_alpha': 39.1, 'reg_lambda': 108.80000000000001, 'num_leaves': 2675, 'min_child_samples': 35, 'min_split_gain': 5.24, 'colsample_bytree': 0.7, 'top_rate': 0.30000000000000004, 'other_rate': 0.5}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 07:37:49,343]\u001b[0m Trial 45 finished with value: 31.247585184407534 and parameters: {'learning_rate': 0.03, 'reg_alpha': 53.900000000000006, 'reg_lambda': 150.20000000000002, 'num_leaves': 2580, 'min_child_samples': 215, 'min_split_gain': 1.42, 'colsample_bytree': 0.95, 'top_rate': 0.5, 'other_rate': 0.5}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 07:43:17,019]\u001b[0m Trial 46 finished with value: 31.439994646758784 and parameters: {'learning_rate': 0.01, 'reg_alpha': 11.4, 'reg_lambda': 137.8, 'num_leaves': 2185, 'min_child_samples': 150, 'min_split_gain': 4.2700000000000005, 'colsample_bytree': 0.75, 'top_rate': 0.2, 'other_rate': 0.45}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 07:44:50,072]\u001b[0m Trial 47 finished with value: 31.402282427781365 and parameters: {'learning_rate': 0.08, 'reg_alpha': 32.7, 'reg_lambda': 98.5, 'num_leaves': 2850, 'min_child_samples': 0, 'min_split_gain': 6.46, 'colsample_bytree': 0.65, 'top_rate': 0.25, 'other_rate': 0.2}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 07:47:57,677]\u001b[0m Trial 48 finished with value: 31.61833572963993 and parameters: {'learning_rate': 0.02, 'reg_alpha': 91.7, 'reg_lambda': 126.0, 'num_leaves': 1795, 'min_child_samples': 290, 'min_split_gain': 3.85, 'colsample_bytree': 0.9, 'top_rate': 0.35, 'other_rate': 0.45}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n",
            "\u001b[32m[I 2022-09-25 07:50:07,221]\u001b[0m Trial 49 finished with value: 31.85907212865579 and parameters: {'learning_rate': 0.03, 'reg_alpha': 62.7, 'reg_lambda': 146.3, 'num_leaves': 2425, 'min_child_samples': 520, 'min_split_gain': 5.99, 'colsample_bytree': 0.8500000000000001, 'top_rate': 0.45000000000000007, 'other_rate': 0.4}. Best is trial 14 with value: 31.049861074398574.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: 14 -> Best value(RMSE): 31.04986\n",
            "Best hyperparameters:\n",
            "learning_rate        - 0.01\n",
            "reg_alpha            - 41.2\n",
            "reg_lambda           - 128.9\n",
            "num_leaves           - 2305\n",
            "min_child_samples    - 30\n",
            "min_split_gain       - 6.16\n",
            "colsample_bytree     - 0.8500000000000001\n",
            "top_rate             - 0.35\n",
            "other_rate           - 0.45\n",
            "-----------------Cross-validation------------------\n",
            "Fold #0: (9657 rounds) RMSE = 32.81238\n",
            "Fold #1: (10000 rounds) RMSE = 30.25674\n",
            "Fold #2: (6770 rounds) RMSE = 27.32033\n",
            "Fold #3: (9998 rounds) RMSE = 36.13793\n",
            "Fold #4: (7245 rounds) RMSE = 28.72193\n",
            "\n",
            "Avg RMSE = 31.04986 +/- 3.12898\n",
            "OOF RMSE = 31.20457\n",
            "CPU times: user 6h 33min 17s, sys: 8min 48s, total: 6h 42min 5s\n",
            "Wall time: 3h 25min 8s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating submission files"
      ],
      "metadata": {
        "id": "Bw_YeofK2lXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in (test_preds.columns):\n",
        "    sub = pd.DataFrame({'Place_ID X Date': TEST_INDEX, 'target': test_preds[col]})\n",
        "    sub.to_csv(f'{SUBMISSION_PATH}/{col}.csv', index=False)\n",
        "\n",
        "sub = pd.DataFrame({'Place_ID X Date': TEST_INDEX, 'target': test_preds.mean(axis=1)})\n",
        "sub.to_csv(f'{SUBMISSION_PATH}/mean.csv', index=False)"
      ],
      "metadata": {
        "id": "YAnTeKAf2kNj"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}