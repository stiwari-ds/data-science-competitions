{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "fMe_ffy2a_ac"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wyde65PCala3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade xgboost\n",
        "!pip install --upgrade optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import time\n",
        "import warnings\n",
        "import subprocess\n",
        "\n",
        "gc.enable()\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.precision', 4)\n",
        "np.set_printoptions(precision=4)\n",
        "\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.pruners import HyperbandPruner\n",
        "\n",
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import average_precision_score, f1_score\n",
        "\n",
        "SEED = 23\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "eKfBaXpBbBUQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove cell to run future versions\n",
        "assert optuna.__version__ == '3.0.3', f'Change in Optuna version. Original notebook version: 3.0.3'\n",
        "assert xgboost.__version__ == '1.6.2', f'Change in XGBoost version. Original notebook version: 1.6.2'"
      ],
      "metadata": {
        "id": "QU6c1orQbm3A"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check GPU availability\n",
        "try:\n",
        "    subprocess.check_output('nvidia-smi')\n",
        "    HAVE_GPU = True\n",
        "except Exception:\n",
        "    HAVE_GPU = False\n",
        "\n",
        "print(f'GPU available: {HAVE_GPU}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBzLRr5pbr7Z",
        "outputId": "f1075ae4-24d9-4ea8-9b71-03753a4ae70c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_URL = 'https://raw.githubusercontent.com/stiwari-ds/data-science-competitions/main/analytics_vidhya/dataverse_hack/data'\n",
        "\n",
        "train = pd.read_csv(f'{DATA_URL}/processed/train.csv') #processed dataset from notebook 00\n",
        "test = pd.read_csv(f'{DATA_URL}/processed/test.csv')\n",
        "sample_sub = pd.read_csv(f'{DATA_URL}/raw/sample_submission.csv')"
      ],
      "metadata": {
        "id": "LOHMVhw1ZZS6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET = 'is_claim'"
      ],
      "metadata": {
        "id": "KEJQopfVZppB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(test.columns)\n",
        "\n",
        "num_features = ['policy_tenure', 'age_of_car', 'age_of_policyholder', \n",
        "                'population_density', 'airbags', 'displacement', 'turning_radius',\n",
        "                'length', 'width','height', 'gross_weight', 'ncap_rating']\n",
        "\n",
        "cat_features = [f for f in features if f not in num_features]"
      ],
      "metadata": {
        "id": "3zTnF1bvZx-o"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[cat_features] = train[cat_features].astype('category')\n",
        "test[cat_features] = test[cat_features].astype('category')"
      ],
      "metadata": {
        "id": "h8hY9cGh2W2b"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline"
      ],
      "metadata": {
        "id": "uur7dQEjf6CY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_threshold(y_true, pred_probs):\n",
        "    candidate_thresholds = np.arange(0, 1, 0.01)\n",
        "    candidate_scores = [f1_score(y_true, (pred_probs >= t).astype('int')) \n",
        "                        for t in candidate_thresholds]\n",
        "    best_threshold = candidate_thresholds[np.argmax(candidate_scores)]\n",
        "    return best_threshold"
      ],
      "metadata": {
        "id": "zjvncV5hf0ZK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "scores_f1 = []\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "X, y = train[features], train[TARGET]\n",
        "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
        "    X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n",
        "    X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n",
        "\n",
        "    model = XGBClassifier(\n",
        "        objective='binary:logistic',\n",
        "        tree_method='gpu_hist' if HAVE_GPU else 'hist',\n",
        "        enable_categorical=HAVE_GPU,\n",
        "        eval_metric='aucpr',\n",
        "        early_stopping_rounds=100, \n",
        "        seed=SEED\n",
        "    ) \n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        verbose=0\n",
        "    )\n",
        "    val_probs = model.predict_proba(X_val)[:, 1]\n",
        "    best_threshold = get_best_threshold(y_val, val_probs)\n",
        "    val_preds = (val_probs >= best_threshold).astype('int')\n",
        "    score = f1_score(y_val, val_preds)\n",
        "    scores_f1.append(score)\n",
        "    print(f'Fold #{fold}: ({model.best_iteration} rounds) F1-score = {score:.5f}')\n",
        "    _ = gc.collect()\n",
        "\n",
        "print(f'\\nAvg F1-score = {np.mean(scores_f1):.5f} +/- {np.std(scores_f1):.5f}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkFlWjOhf5Au",
        "outputId": "ac782a5d-0e31-404c-bb36-1aabe6ecb931"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #0: (5 rounds) F1-score = 0.16726\n",
            "Fold #1: (2 rounds) F1-score = 0.16585\n",
            "Fold #2: (1 rounds) F1-score = 0.17947\n",
            "Fold #3: (9 rounds) F1-score = 0.16408\n",
            "Fold #4: (12 rounds) F1-score = 0.17342\n",
            "\n",
            "Avg F1-score = 0.17002 +/- 0.00568\n",
            "\n",
            "CPU times: user 7.96 s, sys: 285 ms, total: 8.25 s\n",
            "Wall time: 7.58 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVZEqwhQ2oi2"
      },
      "source": [
        "# Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "i3VeEFRe2oBe"
      },
      "outputs": [],
      "source": [
        "def objective(trial, data, model, proba):\n",
        "\n",
        "    scores = []\n",
        "    X, y = data\n",
        "\n",
        "    param_grid = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.025, 0.3, step=0.025),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 2, 20),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 20, step=0.1), #complexity-control\n",
        "        'alpha': trial.suggest_float('alpha', 0, 5, step=0.05), #L1-reg\n",
        "        'lambda': trial.suggest_float('lambda', 1e-3, 1e5, log=True), #L2-reg\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0, step=0.05),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0, step=0.05),\n",
        "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1.0, step=0.05),\n",
        "        'colsample_bynode': trial.suggest_float('colsample_bynode', 0.5, 1.0, step=0.05),\n",
        "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1, 15, step=0.05),\n",
        "        'max_cat_to_onehot': trial.suggest_categorical('max_cat_to_onehot', [3, 6, 11]) \n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
        "        X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n",
        "        X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n",
        "        \n",
        "        model.set_params(**param_grid)\n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            verbose=0\n",
        "        )\n",
        "        if proba:\n",
        "            val_preds = model.predict_proba(X_val)[:, 1]\n",
        "            scores.append(average_precision_score(y_val, val_preds))\n",
        "        else:\n",
        "            val_preds = model.predict(X_val)\n",
        "            scores.append(f1_score(y_val, val_preds))\n",
        "\n",
        "    return np.mean(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "7JCjxMSuT3Ep"
      },
      "outputs": [],
      "source": [
        "def tune_params(data, model, proba, n_trials=10, direction='maximize'):\n",
        "    study = optuna.create_study(\n",
        "        sampler=TPESampler(seed=SEED),\n",
        "        pruner=HyperbandPruner(),\n",
        "        direction=direction\n",
        "    )\n",
        "    study.optimize(\n",
        "        func=lambda trial: objective(trial, data, model, proba),\n",
        "        n_trials=n_trials,\n",
        "        gc_after_trial=True\n",
        "    )\n",
        "    return study"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross-validation"
      ],
      "metadata": {
        "id": "_IdnAvEkjxqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validate_predict(data, model, proba, n_splits=5):\n",
        "    oof_preds = {}  #out-of-fold predictions on train set\n",
        "    test_preds = {} #predictions on test set for each fold\n",
        "    scores = [] #scores on validation set\n",
        "\n",
        "    X, y, X_test = data\n",
        "       \n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
        "        X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n",
        "        X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n",
        "        \n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        if proba:\n",
        "            val_probs = model.predict_proba(X_val)[:, 1]\n",
        "            test_probs = model.predict_proba(X_test)[:, 1]\n",
        "            best_threshold = get_best_threshold(y_val, val_probs)\n",
        "            val_preds = (val_probs >= best_threshold).astype('int')\n",
        "            test_preds_fold = (test_probs >= best_threshold).astype('int')\n",
        "        else:\n",
        "            val_preds = model.predict(X_val)\n",
        "            test_preds_fold = model.predict(X_test)\n",
        "        \n",
        "        oof_preds.update(dict(zip(val_idx, val_preds)))\n",
        "        test_preds[f'fold{fold}'] = test_preds_fold\n",
        "\n",
        "        score = f1_score(y_val, val_preds)\n",
        "        scores.append(score)\n",
        "        print(f'Fold #{fold}: F1 = {score:.5f}')\n",
        "        _ = gc.collect()\n",
        "    print(f'Avg. F1 = {np.mean(scores):.5f} +/- {np.std(scores):.5f}')\n",
        "    \n",
        "    oof_preds = pd.Series(oof_preds).sort_index()\n",
        "    test_preds = pd.DataFrame.from_dict(test_preds)\n",
        "    test_preds['mode'] = test_preds.mode(axis=1)[0].astype('int')\n",
        "\n",
        "    return oof_preds, test_preds"
      ],
      "metadata": {
        "id": "0UBSsqwvj0I2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(data, proba, n_trials=10):\n",
        "    \n",
        "    X, y, X_test = data\n",
        "\n",
        "    base_params = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'n_estimators': 10000,\n",
        "        'booster': 'gbtree',\n",
        "        'eval_metric': 'aucpr',\n",
        "        'early_stopping_rounds': 100,\n",
        "        'tree_method': 'gpu_hist' if HAVE_GPU else 'hist',\n",
        "        'predictor': 'gpu_predictor' if HAVE_GPU else 'cpu_predictor',\n",
        "        'enable_categorical': HAVE_GPU,\n",
        "        'verbosity': 0,\n",
        "        'seed': SEED\n",
        "    }\n",
        "    \n",
        "    model = XGBClassifier(**base_params)\n",
        "    \n",
        "    print(f'----------Hyperparameter tuning----------')\n",
        "    start = time.time()\n",
        "    study = tune_params(\n",
        "        data=(X, y),\n",
        "        model=model,\n",
        "        proba=proba,\n",
        "        n_trials=n_trials, \n",
        "        direction='maximize' #metric: f1-score/avg_precision -> higher is better\n",
        "    )\n",
        "    end = time.time()\n",
        "    print(f'Best trial: {study.best_trial.number} -> Best value: {study.best_value:.5f}')\n",
        "    print(f'Best hyperparameters:')\n",
        "    for k, v in study.best_params.items():\n",
        "        print(f'{k:15} - {v}')\n",
        "    print(f'[Time taken: {end - start:.2f}s]\\n')\n",
        "    \n",
        "    print(f'-----Cross-validation and prediction-----')\n",
        "    start = time.time()\n",
        "    model.set_params(**study.best_params)\n",
        "    oof_preds, test_preds = cross_validate_predict(data, model, proba)\n",
        "    end = time.time()\n",
        "    print(f'[Time taken: {end - start:.2f}s]\\n')\n",
        "\n",
        "    return oof_preds, test_preds"
      ],
      "metadata": {
        "id": "KkMeqc7EkKx-"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trial runs**"
      ],
      "metadata": {
        "id": "Ri22_Ef0kzB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.logging.set_verbosity(optuna.logging.INFO)"
      ],
      "metadata": {
        "id": "1lWtr5SYk0yu"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op, tp = run_experiment(\n",
        "    data=(train[features], train[TARGET], test[features]),\n",
        "    proba=False,\n",
        "    n_trials=3\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAPuSH6Jk4o8",
        "outputId": "3f5c879d-3de3-4ae3-a60c-7899db7a1514"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-13 11:43:56,161]\u001b[0m A new study created in memory with name: no-name-226b120f-34f9-4fa1-a234-63ec1b3bb133\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------Hyperparameter tuning----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-13 11:44:00,242]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'learning_rate': 0.17500000000000002, 'max_depth': 15, 'min_child_weight': 16, 'gamma': 5.6000000000000005, 'alpha': 1.1, 'lambda': 308.87067834937415, 'subsample': 0.55, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.8, 'colsample_bynode': 0.7, 'scale_pos_weight': 1.0, 'max_cat_to_onehot': 6}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "\u001b[32m[I 2022-11-13 11:44:09,217]\u001b[0m Trial 1 finished with value: 0.16540757962781721 and parameters: {'learning_rate': 0.2, 'max_depth': 15, 'min_child_weight': 18, 'gamma': 1.3, 'alpha': 1.4500000000000002, 'lambda': 0.20112938596732194, 'subsample': 0.95, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.55, 'colsample_bynode': 0.5, 'scale_pos_weight': 14.200000000000001, 'max_cat_to_onehot': 6}. Best is trial 1 with value: 0.16540757962781721.\u001b[0m\n",
            "\u001b[32m[I 2022-11-13 11:44:12,855]\u001b[0m Trial 2 finished with value: 0.0005333333333333334 and parameters: {'learning_rate': 0.275, 'max_depth': 8, 'min_child_weight': 17, 'gamma': 14.4, 'alpha': 0.6000000000000001, 'lambda': 59.03008134310796, 'subsample': 0.55, 'colsample_bytree': 0.5, 'colsample_bylevel': 0.95, 'colsample_bynode': 0.75, 'scale_pos_weight': 3.25, 'max_cat_to_onehot': 11}. Best is trial 1 with value: 0.16540757962781721.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: 1 -> Best value: 0.16541\n",
            "Best hyperparameters:\n",
            "learning_rate   - 0.2\n",
            "max_depth       - 15\n",
            "min_child_weight - 18\n",
            "gamma           - 1.3\n",
            "alpha           - 1.4500000000000002\n",
            "lambda          - 0.20112938596732194\n",
            "subsample       - 0.95\n",
            "colsample_bytree - 0.8\n",
            "colsample_bylevel - 0.55\n",
            "colsample_bynode - 0.5\n",
            "scale_pos_weight - 14.200000000000001\n",
            "max_cat_to_onehot - 6\n",
            "[Time taken: 16.76s]\n",
            "\n",
            "-----Cross-validation and prediction-----\n",
            "Fold #0: F1 = 0.16533\n",
            "Fold #1: F1 = 0.16378\n",
            "Fold #2: F1 = 0.17084\n",
            "Fold #3: F1 = 0.15991\n",
            "Fold #4: F1 = 0.16717\n",
            "Avg. F1 = 0.16541 +/- 0.00362\n",
            "[Time taken: 18.12s]\n",
            "\n",
            "CPU times: user 37.3 s, sys: 728 ms, total: 38.1 s\n",
            "Wall time: 34.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op, tp = run_experiment(\n",
        "    data=(train[features], train[TARGET], test[features]),\n",
        "    proba=True,\n",
        "    n_trials=3\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNbZETHzv5yd",
        "outputId": "886934c8-8280-4926-933a-1a64d697f085"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-13 11:44:31,068]\u001b[0m A new study created in memory with name: no-name-58bef7d6-7690-41ff-9d66-d518faefca90\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------Hyperparameter tuning----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-13 11:44:34,180]\u001b[0m Trial 0 finished with value: 0.10380622728647278 and parameters: {'learning_rate': 0.17500000000000002, 'max_depth': 15, 'min_child_weight': 16, 'gamma': 5.6000000000000005, 'alpha': 1.1, 'lambda': 308.87067834937415, 'subsample': 0.55, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.8, 'colsample_bynode': 0.7, 'scale_pos_weight': 1.0, 'max_cat_to_onehot': 6}. Best is trial 0 with value: 0.10380622728647278.\u001b[0m\n",
            "\u001b[32m[I 2022-11-13 11:44:43,120]\u001b[0m Trial 1 finished with value: 0.10666766850252214 and parameters: {'learning_rate': 0.2, 'max_depth': 15, 'min_child_weight': 18, 'gamma': 1.3, 'alpha': 1.4500000000000002, 'lambda': 0.20112938596732194, 'subsample': 0.95, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.55, 'colsample_bynode': 0.5, 'scale_pos_weight': 14.200000000000001, 'max_cat_to_onehot': 6}. Best is trial 1 with value: 0.10666766850252214.\u001b[0m\n",
            "\u001b[32m[I 2022-11-13 11:44:46,833]\u001b[0m Trial 2 finished with value: 0.10629359930563434 and parameters: {'learning_rate': 0.275, 'max_depth': 8, 'min_child_weight': 17, 'gamma': 14.4, 'alpha': 0.6000000000000001, 'lambda': 59.03008134310796, 'subsample': 0.55, 'colsample_bytree': 0.5, 'colsample_bylevel': 0.95, 'colsample_bynode': 0.75, 'scale_pos_weight': 3.25, 'max_cat_to_onehot': 11}. Best is trial 1 with value: 0.10666766850252214.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: 1 -> Best value: 0.10667\n",
            "Best hyperparameters:\n",
            "learning_rate   - 0.2\n",
            "max_depth       - 15\n",
            "min_child_weight - 18\n",
            "gamma           - 1.3\n",
            "alpha           - 1.4500000000000002\n",
            "lambda          - 0.20112938596732194\n",
            "subsample       - 0.95\n",
            "colsample_bytree - 0.8\n",
            "colsample_bylevel - 0.55\n",
            "colsample_bynode - 0.5\n",
            "scale_pos_weight - 14.200000000000001\n",
            "max_cat_to_onehot - 6\n",
            "[Time taken: 15.85s]\n",
            "\n",
            "-----Cross-validation and prediction-----\n",
            "Fold #0: F1 = 0.16735\n",
            "Fold #1: F1 = 0.16651\n",
            "Fold #2: F1 = 0.17813\n",
            "Fold #3: F1 = 0.17052\n",
            "Fold #4: F1 = 0.18313\n",
            "Avg. F1 = 0.17313 +/- 0.00647\n",
            "[Time taken: 20.00s]\n",
            "\n",
            "CPU times: user 38.1 s, sys: 575 ms, total: 38.7 s\n",
            "Wall time: 35.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.logging.set_verbosity(optuna.logging.ERROR)"
      ],
      "metadata": {
        "id": "j6CPkw2AwBfu"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exp 1"
      ],
      "metadata": {
        "id": "XEosvKAmzvvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op1, tp1 = run_experiment(\n",
        "    data=(train[features], train[TARGET], test[features]),\n",
        "    proba=False,\n",
        "    n_trials=200\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSTivemPzzNo",
        "outputId": "80c185a1-39f5-4f7d-fe1b-274dced3ae0b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------Hyperparameter tuning----------\n",
            "Best trial: 144 -> Best value: 0.17686\n",
            "Best hyperparameters:\n",
            "learning_rate   - 0.125\n",
            "max_depth       - 3\n",
            "min_child_weight - 10\n",
            "gamma           - 8.200000000000001\n",
            "alpha           - 3.95\n",
            "lambda          - 0.052999716771597524\n",
            "subsample       - 0.8500000000000001\n",
            "colsample_bytree - 0.75\n",
            "colsample_bylevel - 0.9\n",
            "colsample_bynode - 0.55\n",
            "scale_pos_weight - 10.65\n",
            "max_cat_to_onehot - 6\n",
            "[Time taken: 757.00s]\n",
            "\n",
            "-----Cross-validation and prediction-----\n",
            "Fold #0: F1 = 0.17579\n",
            "Fold #1: F1 = 0.17577\n",
            "Fold #2: F1 = 0.18390\n",
            "Fold #3: F1 = 0.16915\n",
            "Fold #4: F1 = 0.17969\n",
            "Avg. F1 = 0.17686 +/- 0.00488\n",
            "[Time taken: 11.43s]\n",
            "\n",
            "CPU times: user 14min 44s, sys: 10.1 s, total: 14min 54s\n",
            "Wall time: 12min 48s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exp 2"
      ],
      "metadata": {
        "id": "A3PbmLOsz5eN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op2, tp2 = run_experiment(\n",
        "    data=(train[features], train[TARGET], test[features]),\n",
        "    proba=True,\n",
        "    n_trials=200\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkMLAYWpz9i6",
        "outputId": "d7e999f2-05fe-4ce5-f484-7577498147e1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------Hyperparameter tuning----------\n",
            "Best trial: 107 -> Best value: 0.11260\n",
            "Best hyperparameters:\n",
            "learning_rate   - 0.025\n",
            "max_depth       - 6\n",
            "min_child_weight - 5\n",
            "gamma           - 12.0\n",
            "alpha           - 4.55\n",
            "lambda          - 99.88472972267857\n",
            "subsample       - 0.95\n",
            "colsample_bytree - 1.0\n",
            "colsample_bylevel - 0.6\n",
            "colsample_bynode - 0.55\n",
            "scale_pos_weight - 14.600000000000001\n",
            "max_cat_to_onehot - 3\n",
            "[Time taken: 916.49s]\n",
            "\n",
            "-----Cross-validation and prediction-----\n",
            "Fold #0: F1 = 0.17251\n",
            "Fold #1: F1 = 0.17122\n",
            "Fold #2: F1 = 0.18737\n",
            "Fold #3: F1 = 0.16955\n",
            "Fold #4: F1 = 0.17867\n",
            "Avg. F1 = 0.17587 +/- 0.00653\n",
            "[Time taken: 15.49s]\n",
            "\n",
            "CPU times: user 17min 29s, sys: 11.3 s, total: 17min 40s\n",
            "Wall time: 15min 31s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission files"
      ],
      "metadata": {
        "id": "EahA1dJ47Z1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7npzUESt7bGc",
        "outputId": "fbf02c19-bbaf-48bb-be25-b483a6533c5d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NOTEBOOK = '01'\n",
        "SUBMISSION_PATH = f'/content/drive/MyDrive/data_science_competitions/analytics_vidhya/dataverse_hack/submissions/nb_{NOTEBOOK}'\n",
        "if not os.path.isdir(SUBMISSION_PATH):\n",
        "    os.makedirs(SUBMISSION_PATH)"
      ],
      "metadata": {
        "id": "Z39yNfKD7b95"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_submission_files(test_preds: pd.DataFrame, expt_num: int):\n",
        "    for col in (test_preds.columns):\n",
        "        sub = sample_sub.copy()\n",
        "        sub[TARGET] = test_preds[col]\n",
        "        sub.to_csv(f'{SUBMISSION_PATH}/{expt_num}_{col}.csv', index=False)"
      ],
      "metadata": {
        "id": "5y6XhjNx8OJT"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_submission_files(tp1, '01')\n",
        "create_submission_files(tp2, '02')"
      ],
      "metadata": {
        "id": "Ii5dHRpk8Rve"
      },
      "execution_count": 47,
      "outputs": []
    }
  ]
}