{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{"id":"fMe_ffy2a_ac"}},{"cell_type":"code","source":"%%capture\n!pip install --upgrade xgboost\n!pip install --upgrade optuna","metadata":{"id":"wyde65PCala3","execution":{"iopub.status.busy":"2022-11-18T16:20:28.347299Z","iopub.execute_input":"2022-11-18T16:20:28.348246Z","iopub.status.idle":"2022-11-18T16:20:50.248227Z","shell.execute_reply.started":"2022-11-18T16:20:28.348108Z","shell.execute_reply":"2022-11-18T16:20:50.246940Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport time\nimport warnings\nimport subprocess\n\ngc.enable()\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\npd.set_option('display.max_columns', None)\npd.set_option('display.precision', 4)\nnp.set_printoptions(precision=4)\n\nimport optuna\nfrom optuna.samplers import TPESampler\nfrom optuna.pruners import HyperbandPruner\n\nimport xgboost\nfrom xgboost import XGBRegressor\n\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_squared_error\n\nSEED = 2311\nos.environ['PYTHONHASHSEED'] = str(SEED)\nnp.random.seed(SEED)","metadata":{"id":"eKfBaXpBbBUQ","execution":{"iopub.status.busy":"2022-11-18T16:20:50.250493Z","iopub.execute_input":"2022-11-18T16:20:50.250869Z","iopub.status.idle":"2022-11-18T16:20:51.107132Z","shell.execute_reply.started":"2022-11-18T16:20:50.250830Z","shell.execute_reply":"2022-11-18T16:20:51.106229Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#remove cell to run future versions\nassert optuna.__version__ == '3.0.3', f'Change in Optuna version. Original notebook version: 3.0.3'\nassert xgboost.__version__ == '1.6.2', f'Change in XGBoost version. Original notebook version: 1.6.2'","metadata":{"id":"QU6c1orQbm3A","execution":{"iopub.status.busy":"2022-11-18T16:20:51.109305Z","iopub.execute_input":"2022-11-18T16:20:51.109867Z","iopub.status.idle":"2022-11-18T16:20:51.114986Z","shell.execute_reply.started":"2022-11-18T16:20:51.109830Z","shell.execute_reply":"2022-11-18T16:20:51.113893Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Check GPU availability\ntry:\n    subprocess.check_output('nvidia-smi')\n    HAVE_GPU = True\nexcept Exception:\n    HAVE_GPU = False\n\nprint(f'GPU available: {HAVE_GPU}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NBzLRr5pbr7Z","outputId":"ed296196-6415-4aea-d4d9-51b119ac933f","execution":{"iopub.status.busy":"2022-11-18T16:20:51.117800Z","iopub.execute_input":"2022-11-18T16:20:51.118191Z","iopub.status.idle":"2022-11-18T16:20:51.190313Z","shell.execute_reply.started":"2022-11-18T16:20:51.118154Z","shell.execute_reply":"2022-11-18T16:20:51.189146Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"GPU available: True\n","output_type":"stream"}]},{"cell_type":"code","source":"DATA_URL = 'https://raw.githubusercontent.com/stiwari-ds/data-science-competitions/main/analytics_vidhya/jobathon_nov22/data'\n\ntrain = pd.read_csv(f'{DATA_URL}/processed/train.csv') #processed datasets from notebook 00\ntrain_drop = pd.read_csv(f'{DATA_URL}/processed/train_drop.csv')\ntrain_ffill = pd.read_csv(f'{DATA_URL}/processed/train_ffill.csv')\ntrain_bfill = pd.read_csv(f'{DATA_URL}/processed/train_bfill.csv')\ntrain_linear = pd.read_csv(f'{DATA_URL}/processed/train_linear.csv')\ntrain_poly3 = pd.read_csv(f'{DATA_URL}/processed/train_poly3.csv')\ntrain_poly5 = pd.read_csv(f'{DATA_URL}/processed/train_poly5.csv')\ntrain_iterimp = pd.read_csv(f'{DATA_URL}/processed/train_iterimp.csv')\n\ntest = pd.read_csv(f'{DATA_URL}/processed/test.csv')\nsample_sub = pd.read_csv(f'{DATA_URL}/raw/sample_submission.csv')","metadata":{"id":"LOHMVhw1ZZS6","execution":{"iopub.status.busy":"2022-11-18T16:20:51.192140Z","iopub.execute_input":"2022-11-18T16:20:51.192760Z","iopub.status.idle":"2022-11-18T16:20:56.425642Z","shell.execute_reply.started":"2022-11-18T16:20:51.192718Z","shell.execute_reply":"2022-11-18T16:20:56.424683Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"TARGET = 'energy'","metadata":{"id":"KEJQopfVZppB","execution":{"iopub.status.busy":"2022-11-18T16:20:56.427095Z","iopub.execute_input":"2022-11-18T16:20:56.427451Z","iopub.status.idle":"2022-11-18T16:20:56.433517Z","shell.execute_reply.started":"2022-11-18T16:20:56.427415Z","shell.execute_reply":"2022-11-18T16:20:56.431849Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"features = list(test.columns)\n\ncat_features_1 = ['quarter', 'dayofweek']\ncat_features_2 = ['quarter', 'dayofweek', 'month', 'hour']\ncat_features_3 = ['quarter', 'dayofweek', 'month', 'hour', 'dayofmonth', 'weekofyear']","metadata":{"id":"3zTnF1bvZx-o","execution":{"iopub.status.busy":"2022-11-18T16:20:56.434964Z","iopub.execute_input":"2022-11-18T16:20:56.435713Z","iopub.status.idle":"2022-11-18T16:20:56.446742Z","shell.execute_reply.started":"2022-11-18T16:20:56.435676Z","shell.execute_reply":"2022-11-18T16:20:56.445645Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Baseline","metadata":{"id":"uur7dQEjf6CY"}},{"cell_type":"code","source":"%%time\nscores = []\ncv = TimeSeriesSplit(n_splits=10)\nX, y = train_drop[features], train_drop[TARGET]\nX[cat_features_1] = X[cat_features_1].astype('category')\nfor fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n    X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n    X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n\n    model = XGBRegressor(\n        objective='reg:squarederror',\n        tree_method='gpu_hist' if HAVE_GPU else 'hist',\n        enable_categorical=HAVE_GPU,\n        eval_metric='rmse',\n        early_stopping_rounds=100, \n        seed=SEED\n    ) \n    model.fit(\n        X_train, y_train,\n        eval_set=[(X_val, y_val)],\n        verbose=0\n    )\n    val_preds = model.predict(X_val)\n    score = mean_squared_error(y_val, val_preds, squared=False)\n    scores.append(score)\n    print(f'Fold #{fold}: ' \\\n          f'(Data size: train = {X_train.shape[0]:>5}, test = {X_val.shape[0]:4})' \\\n          f' RMSE = {score:.5f} ({model.best_iteration} rounds)')\n    _ = gc.collect()\n\nprint(f'Avg. RMSE = {np.mean(scores):.5f} +/- {np.std(scores):.5f}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XptzMIzqY3QE","outputId":"6d0b4b04-f122-4cde-e98b-a3c03cbf4c2b","execution":{"iopub.status.busy":"2022-11-18T16:20:56.450225Z","iopub.execute_input":"2022-11-18T16:20:56.450479Z","iopub.status.idle":"2022-11-18T16:21:09.241421Z","shell.execute_reply.started":"2022-11-18T16:20:56.450455Z","shell.execute_reply":"2022-11-18T16:21:09.240398Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Fold #0: (Data size: train =  8472, test = 8462) RMSE = 162.71702 (19 rounds)\nFold #1: (Data size: train = 16934, test = 8462) RMSE = 149.14382 (10 rounds)\nFold #2: (Data size: train = 25396, test = 8462) RMSE = 165.26525 (17 rounds)\nFold #3: (Data size: train = 33858, test = 8462) RMSE = 176.48886 (27 rounds)\nFold #4: (Data size: train = 42320, test = 8462) RMSE = 168.28283 (16 rounds)\nFold #5: (Data size: train = 50782, test = 8462) RMSE = 332.18391 (35 rounds)\nFold #6: (Data size: train = 59244, test = 8462) RMSE = 227.13640 (14 rounds)\nFold #7: (Data size: train = 67706, test = 8462) RMSE = 185.63637 (16 rounds)\nFold #8: (Data size: train = 76168, test = 8462) RMSE = 202.32710 (30 rounds)\nFold #9: (Data size: train = 84630, test = 8462) RMSE = 203.59508 (23 rounds)\nAvg. RMSE = 197.27766 +/- 50.10104\nCPU times: user 11.5 s, sys: 507 ms, total: 12 s\nWall time: 12.8 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Hyperparameter tuning","metadata":{"id":"oVZEqwhQ2oi2"}},{"cell_type":"code","source":"def objective(trial, data, cat_features, base_params):\n\n    scores = []\n    X, y = data\n    X[cat_features] = X[cat_features].astype('category')\n\n    param_grid = {\n        'learning_rate': trial.suggest_float('learning_rate', 0.1, 0.5, step=0.05),\n        'max_depth': trial.suggest_int('max_depth', 3, 12),\n        'min_child_weight': trial.suggest_int('min_child_weight', 2, 256),\n        'gamma': trial.suggest_float('gamma', 0, 20, step=0.1), #complexity-control\n        'alpha': trial.suggest_float('alpha', 0, 5, step=0.05), #L1-reg\n        'lambda': trial.suggest_float('lambda', 1e-2, 1e4, log=True), #L2-reg\n        'subsample': trial.suggest_float('subsample', 0.75, 1.0, step=0.05),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.75, 1.0, step=0.05),\n        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.75, 1.0, step=0.05),\n        'colsample_bynode': trial.suggest_float('colsample_bynode', 0.75, 1.0, step=0.05),\n        'max_cat_to_onehot': trial.suggest_categorical('max_cat_to_onehot', [4, 7, 12]) \n    }\n\n    cv = TimeSeriesSplit(n_splits=10)\n    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n        X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n        X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n        \n        model = XGBRegressor(**base_params, **param_grid)\n        model.fit(\n            X_train, y_train,\n            eval_set=[(X_val, y_val)],\n            verbose=0\n        )\n        val_preds = model.predict(X_val)\n        scores.append(mean_squared_error(y_val, val_preds, squared=False))\n    return np.mean(scores)","metadata":{"id":"i3VeEFRe2oBe","execution":{"iopub.status.busy":"2022-11-18T16:21:09.242735Z","iopub.execute_input":"2022-11-18T16:21:09.243528Z","iopub.status.idle":"2022-11-18T16:21:09.256084Z","shell.execute_reply.started":"2022-11-18T16:21:09.243492Z","shell.execute_reply":"2022-11-18T16:21:09.255244Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def tune_params(data, cat_features, base_params, n_trials, direction):\n    study = optuna.create_study(\n        sampler=TPESampler(seed=SEED),\n        pruner=HyperbandPruner(),\n        direction=direction\n    )\n    study.optimize(\n        func=lambda trial: objective(trial, data, cat_features, base_params),\n        n_trials=n_trials,\n        gc_after_trial=True\n    )\n    return study","metadata":{"id":"7JCjxMSuT3Ep","execution":{"iopub.status.busy":"2022-11-18T16:21:09.262138Z","iopub.execute_input":"2022-11-18T16:21:09.262480Z","iopub.status.idle":"2022-11-18T16:21:09.271213Z","shell.execute_reply.started":"2022-11-18T16:21:09.262438Z","shell.execute_reply":"2022-11-18T16:21:09.270090Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Cross-validation","metadata":{"id":"_IdnAvEkjxqS"}},{"cell_type":"code","source":"def cross_validate_predict(data, cat_features, model_params):\n    test_preds = {} #predictions on test set for each fold\n    scores = [] #scores on validation set\n\n    X, y, X_test = data\n    X[cat_features] = X[cat_features].astype('category')\n    X_test[cat_features] = X_test[cat_features].astype('category')\n       \n    cv = TimeSeriesSplit(n_splits=10)\n    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n        X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n        X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n        \n        model = XGBRegressor(**model_params)\n        model.fit(\n            X_train, y_train,\n            eval_set=[(X_val, y_val)],\n            verbose=0\n        )\n\n        val_preds = model.predict(X_val)\n        test_preds[f'fold{fold}'] = model.predict(X_test)\n\n        score = mean_squared_error(y_val, val_preds, squared=False)\n        scores.append(score)\n        print(f'Fold #{fold}: ' \\\n              f'(Data size: train = {X_train.shape[0]:>5}, test = {X_val.shape[0]:4})' \\\n              f' RMSE = {score:.5f} ({model.best_iteration} rounds)')\n        _ = gc.collect()\n    \n    print(f'Avg. RMSE = {np.mean(scores):.5f} +/- {np.std(scores):.5f}')\n    \n    test_preds = pd.DataFrame.from_dict(test_preds)\n    test_preds['mean'] = test_preds.mean(axis=1)\n\n    return test_preds","metadata":{"id":"0UBSsqwvj0I2","execution":{"iopub.status.busy":"2022-11-18T16:21:09.272367Z","iopub.execute_input":"2022-11-18T16:21:09.273306Z","iopub.status.idle":"2022-11-18T16:21:09.284094Z","shell.execute_reply.started":"2022-11-18T16:21:09.273240Z","shell.execute_reply":"2022-11-18T16:21:09.283443Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def run_experiment(data, cat_features, n_trials=5):\n    \n    X, y, X_test = data\n\n    base_params = {\n        'objective': 'reg:squarederror',\n        'n_estimators': 20000,\n        'booster': 'gbtree',\n        'eval_metric': 'rmse',\n        'early_stopping_rounds': 100,\n        'tree_method': 'gpu_hist' if HAVE_GPU else 'hist',\n        'predictor': 'gpu_predictor' if HAVE_GPU else 'cpu_predictor',\n        'enable_categorical': HAVE_GPU,\n        'verbosity': 1,\n        'seed': SEED\n    }\n    \n    model = XGBRegressor(**base_params)\n    \n    print(f'----------Hyperparameter tuning----------')\n    start = time.time()\n    study = tune_params(\n        data=(X, y),\n        cat_features=cat_features,\n        base_params=base_params,\n        n_trials=n_trials, \n        direction='minimize' #metric: RMSE -> lower is better\n    )\n    end = time.time()\n    print(f'Best trial: {study.best_trial.number} -> Best value: {study.best_value:.5f}')\n    print(f'Best hyperparameters:')\n    for k, v in study.best_params.items():\n        print(f'{k:15} - {v}')\n    print(f'[Time taken: {end - start:.2f}s]\\n')\n    \n    print(f'-----Cross-validation and prediction-----')\n    start = time.time()\n    model_params = {**base_params, **study.best_params}\n    test_preds = cross_validate_predict(data, cat_features, model_params)\n    end = time.time()\n    print(f'[Time taken: {end - start:.2f}s]\\n')\n\n    return test_preds","metadata":{"id":"KkMeqc7EkKx-","execution":{"iopub.status.busy":"2022-11-18T16:21:09.285224Z","iopub.execute_input":"2022-11-18T16:21:09.286135Z","iopub.status.idle":"2022-11-18T16:21:09.299102Z","shell.execute_reply.started":"2022-11-18T16:21:09.286098Z","shell.execute_reply":"2022-11-18T16:21:09.298218Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**Trial runs**","metadata":{"id":"Ri22_Ef0kzB0"}},{"cell_type":"code","source":"optuna.logging.set_verbosity(optuna.logging.INFO)","metadata":{"id":"1lWtr5SYk0yu","execution":{"iopub.status.busy":"2022-11-18T16:21:09.300430Z","iopub.execute_input":"2022-11-18T16:21:09.300843Z","iopub.status.idle":"2022-11-18T16:21:09.312743Z","shell.execute_reply.started":"2022-11-18T16:21:09.300809Z","shell.execute_reply":"2022-11-18T16:21:09.311674Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"%%time\ntp = run_experiment(\n    data=(train_drop[features], train_drop[TARGET], test[features]),\n    cat_features=cat_features_1,\n    n_trials=3\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QAPuSH6Jk4o8","outputId":"67faae42-c00a-4099-b47c-0b85deb79795","execution":{"iopub.status.busy":"2022-11-18T16:21:09.314147Z","iopub.execute_input":"2022-11-18T16:21:09.314562Z","iopub.status.idle":"2022-11-18T16:22:30.144452Z","shell.execute_reply.started":"2022-11-18T16:21:09.314529Z","shell.execute_reply":"2022-11-18T16:22:30.142470Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2022-11-18 16:21:09,324]\u001b[0m A new study created in memory with name: no-name-db9d79af-73dc-4b8d-a9fa-3fc6cd0d19b4\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"----------Hyperparameter tuning----------\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-11-18 16:21:28,662]\u001b[0m Trial 0 finished with value: 195.78783017865436 and parameters: {'learning_rate': 0.2, 'max_depth': 11, 'min_child_weight': 57, 'gamma': 3.0, 'alpha': 0.25, 'lambda': 177.1345546784436, 'subsample': 0.75, 'colsample_bytree': 0.75, 'colsample_bylevel': 0.95, 'colsample_bynode': 0.9, 'max_cat_to_onehot': 12}. Best is trial 0 with value: 195.78783017865436.\u001b[0m\n\u001b[32m[I 2022-11-18 16:21:42,534]\u001b[0m Trial 1 finished with value: 200.60882550235922 and parameters: {'learning_rate': 0.45000000000000007, 'max_depth': 12, 'min_child_weight': 148, 'gamma': 2.3000000000000003, 'alpha': 3.35, 'lambda': 1.3459766417243109, 'subsample': 0.9, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.95, 'colsample_bynode': 0.85, 'max_cat_to_onehot': 12}. Best is trial 0 with value: 195.78783017865436.\u001b[0m\n\u001b[32m[I 2022-11-18 16:22:05,711]\u001b[0m Trial 2 finished with value: 191.05386319982154 and parameters: {'learning_rate': 0.15000000000000002, 'max_depth': 7, 'min_child_weight': 157, 'gamma': 6.0, 'alpha': 3.5500000000000003, 'lambda': 3131.3882809486845, 'subsample': 0.85, 'colsample_bytree': 0.85, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.95, 'max_cat_to_onehot': 4}. Best is trial 2 with value: 191.05386319982154.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Best trial: 2 -> Best value: 191.05386\nBest hyperparameters:\nlearning_rate   - 0.15000000000000002\nmax_depth       - 7\nmin_child_weight - 157\ngamma           - 6.0\nalpha           - 3.5500000000000003\nlambda          - 3131.3882809486845\nsubsample       - 0.85\ncolsample_bytree - 0.85\ncolsample_bylevel - 1.0\ncolsample_bynode - 0.95\nmax_cat_to_onehot - 4\n[Time taken: 56.51s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8472, test = 8462) RMSE = 155.16923 (348 rounds)\nFold #1: (Data size: train = 16934, test = 8462) RMSE = 147.59368 (246 rounds)\nFold #2: (Data size: train = 25396, test = 8462) RMSE = 158.18230 (85 rounds)\nFold #3: (Data size: train = 33858, test = 8462) RMSE = 179.35086 (250 rounds)\nFold #4: (Data size: train = 42320, test = 8462) RMSE = 157.20717 (253 rounds)\nFold #5: (Data size: train = 50782, test = 8462) RMSE = 309.73006 (391 rounds)\nFold #6: (Data size: train = 59244, test = 8462) RMSE = 218.70306 (98 rounds)\nFold #7: (Data size: train = 67706, test = 8462) RMSE = 184.17637 (89 rounds)\nFold #8: (Data size: train = 76168, test = 8462) RMSE = 201.54348 (240 rounds)\nFold #9: (Data size: train = 84630, test = 8462) RMSE = 198.88242 (161 rounds)\nAvg. RMSE = 191.05386 +/- 45.39463\n[Time taken: 24.31s]\n\nCPU times: user 1min 22s, sys: 385 ms, total: 1min 23s\nWall time: 1min 20s\n","output_type":"stream"}]},{"cell_type":"code","source":"optuna.logging.set_verbosity(optuna.logging.ERROR)","metadata":{"id":"j6CPkw2AwBfu","execution":{"iopub.status.busy":"2022-11-18T16:22:30.146016Z","iopub.execute_input":"2022-11-18T16:22:30.146411Z","iopub.status.idle":"2022-11-18T16:22:30.151498Z","shell.execute_reply.started":"2022-11-18T16:22:30.146376Z","shell.execute_reply":"2022-11-18T16:22:30.150307Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### Dataset 1: train_drop","metadata":{"id":"d1b8UEwV2mlw"}},{"cell_type":"code","source":"%%time\ntp_1_1 = run_experiment(\n    data=(train_drop[features], train_drop[TARGET], test[features]),\n    cat_features=cat_features_1,\n    n_trials=100\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O72SFORuwyH-","outputId":"088884c7-60d6-4471-b7af-33f7f9cf318b","execution":{"iopub.status.busy":"2022-11-18T16:22:30.153313Z","iopub.execute_input":"2022-11-18T16:22:30.154076Z","iopub.status.idle":"2022-11-18T16:37:38.876249Z","shell.execute_reply.started":"2022-11-18T16:22:30.154041Z","shell.execute_reply":"2022-11-18T16:37:38.875244Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 41 -> Best value: 180.82483\nBest hyperparameters:\nlearning_rate   - 0.2\nmax_depth       - 3\nmin_child_weight - 236\ngamma           - 4.4\nalpha           - 3.4000000000000004\nlambda          - 0.010038563400505355\nsubsample       - 0.95\ncolsample_bytree - 0.85\ncolsample_bylevel - 0.8\ncolsample_bynode - 0.95\nmax_cat_to_onehot - 4\n[Time taken: 901.98s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8472, test = 8462) RMSE = 145.37247 (50 rounds)\nFold #1: (Data size: train = 16934, test = 8462) RMSE = 151.36063 (16 rounds)\nFold #2: (Data size: train = 25396, test = 8462) RMSE = 152.96819 (30 rounds)\nFold #3: (Data size: train = 33858, test = 8462) RMSE = 164.82529 (313 rounds)\nFold #4: (Data size: train = 42320, test = 8462) RMSE = 151.70146 (79 rounds)\nFold #5: (Data size: train = 50782, test = 8462) RMSE = 276.26640 (159 rounds)\nFold #6: (Data size: train = 59244, test = 8462) RMSE = 184.61034 (31 rounds)\nFold #7: (Data size: train = 67706, test = 8462) RMSE = 178.43726 (55 rounds)\nFold #8: (Data size: train = 76168, test = 8462) RMSE = 199.72949 (322 rounds)\nFold #9: (Data size: train = 84630, test = 8462) RMSE = 202.97681 (248 rounds)\nAvg. RMSE = 180.82483 +/- 37.39302\n[Time taken: 6.73s]\n\nCPU times: user 15min 59s, sys: 7.8 s, total: 16min 7s\nWall time: 15min 8s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ntp_1_2 = run_experiment(\n    data=(train_drop[features], train_drop[TARGET], test[features]),\n    cat_features=cat_features_2,\n    n_trials=100\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d1lsU-MM3Bfq","outputId":"874b723f-b718-4594-9277-330235afb94a","execution":{"iopub.status.busy":"2022-11-18T16:37:38.877530Z","iopub.execute_input":"2022-11-18T16:37:38.877897Z","iopub.status.idle":"2022-11-18T16:55:33.080941Z","shell.execute_reply.started":"2022-11-18T16:37:38.877860Z","shell.execute_reply":"2022-11-18T16:55:33.080027Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 88 -> Best value: 181.48380\nBest hyperparameters:\nlearning_rate   - 0.2\nmax_depth       - 3\nmin_child_weight - 256\ngamma           - 2.0\nalpha           - 2.6\nlambda          - 0.052211555913631455\nsubsample       - 0.8\ncolsample_bytree - 0.95\ncolsample_bylevel - 0.9\ncolsample_bynode - 0.9\nmax_cat_to_onehot - 4\n[Time taken: 1068.25s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8472, test = 8462) RMSE = 147.03869 (54 rounds)\nFold #1: (Data size: train = 16934, test = 8462) RMSE = 155.57162 (16 rounds)\nFold #2: (Data size: train = 25396, test = 8462) RMSE = 149.71451 (41 rounds)\nFold #3: (Data size: train = 33858, test = 8462) RMSE = 162.72819 (158 rounds)\nFold #4: (Data size: train = 42320, test = 8462) RMSE = 146.75381 (90 rounds)\nFold #5: (Data size: train = 50782, test = 8462) RMSE = 263.00072 (235 rounds)\nFold #6: (Data size: train = 59244, test = 8462) RMSE = 206.48062 (24 rounds)\nFold #7: (Data size: train = 67706, test = 8462) RMSE = 181.87189 (40 rounds)\nFold #8: (Data size: train = 76168, test = 8462) RMSE = 201.12295 (177 rounds)\nFold #9: (Data size: train = 84630, test = 8462) RMSE = 200.55504 (101 rounds)\nAvg. RMSE = 181.48380 +/- 35.27683\n[Time taken: 5.94s]\n\nCPU times: user 18min 46s, sys: 7.47 s, total: 18min 53s\nWall time: 17min 54s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ntp_1_3 = run_experiment(\n    data=(train_drop[features], train_drop[TARGET], test[features]),\n    cat_features=cat_features_3,\n    n_trials=100\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jvNifG793CXO","outputId":"305c6577-58dc-4028-b3ae-3a2bb9d73ac3","execution":{"iopub.status.busy":"2022-11-18T16:55:33.082486Z","iopub.execute_input":"2022-11-18T16:55:33.082823Z","iopub.status.idle":"2022-11-18T17:17:25.694328Z","shell.execute_reply.started":"2022-11-18T16:55:33.082789Z","shell.execute_reply":"2022-11-18T17:17:25.693249Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 83 -> Best value: 183.14384\nBest hyperparameters:\nlearning_rate   - 0.2\nmax_depth       - 3\nmin_child_weight - 255\ngamma           - 19.700000000000003\nalpha           - 1.9500000000000002\nlambda          - 0.18167571986081854\nsubsample       - 0.75\ncolsample_bytree - 0.85\ncolsample_bylevel - 0.85\ncolsample_bynode - 0.85\nmax_cat_to_onehot - 7\n[Time taken: 1306.25s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8472, test = 8462) RMSE = 136.53887 (50 rounds)\nFold #1: (Data size: train = 16934, test = 8462) RMSE = 149.35229 (25 rounds)\nFold #2: (Data size: train = 25396, test = 8462) RMSE = 150.10780 (34 rounds)\nFold #3: (Data size: train = 33858, test = 8462) RMSE = 171.56640 (119 rounds)\nFold #4: (Data size: train = 42320, test = 8462) RMSE = 151.15926 (97 rounds)\nFold #5: (Data size: train = 50782, test = 8462) RMSE = 279.97502 (335 rounds)\nFold #6: (Data size: train = 59244, test = 8462) RMSE = 199.00130 (27 rounds)\nFold #7: (Data size: train = 67706, test = 8462) RMSE = 180.28260 (41 rounds)\nFold #8: (Data size: train = 76168, test = 8462) RMSE = 208.83498 (121 rounds)\nFold #9: (Data size: train = 84630, test = 8462) RMSE = 204.61983 (107 rounds)\nAvg. RMSE = 183.14384 +/- 40.39740\n[Time taken: 6.35s]\n\nCPU times: user 22min 45s, sys: 7.76 s, total: 22min 53s\nWall time: 21min 52s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Dataset 2: train_ffill","metadata":{"id":"S1Q2z48k3LRa"}},{"cell_type":"code","source":"%%time\ntp_2_1 = run_experiment(\n    data=(train_ffill[features], train_ffill[TARGET], test[features]),\n    cat_features=cat_features_1,\n    n_trials=100\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_rOhcASV3LRb","outputId":"0cd01c77-c9c1-4b37-807c-70632f5b8754","execution":{"iopub.status.busy":"2022-11-18T17:17:25.696300Z","iopub.execute_input":"2022-11-18T17:17:25.696979Z","iopub.status.idle":"2022-11-18T17:31:43.921496Z","shell.execute_reply.started":"2022-11-18T17:17:25.696941Z","shell.execute_reply":"2022-11-18T17:31:43.920265Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 99 -> Best value: 182.84446\nBest hyperparameters:\nlearning_rate   - 0.2\nmax_depth       - 3\nmin_child_weight - 209\ngamma           - 5.2\nalpha           - 3.0\nlambda          - 0.04587935317552276\nsubsample       - 0.95\ncolsample_bytree - 0.9\ncolsample_bylevel - 1.0\ncolsample_bynode - 0.9\nmax_cat_to_onehot - 4\n[Time taken: 852.02s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8642, test = 8635) RMSE = 149.49857 (44 rounds)\nFold #1: (Data size: train = 17277, test = 8635) RMSE = 153.73984 (21 rounds)\nFold #2: (Data size: train = 25912, test = 8635) RMSE = 153.81181 (35 rounds)\nFold #3: (Data size: train = 34547, test = 8635) RMSE = 157.98132 (255 rounds)\nFold #4: (Data size: train = 43182, test = 8635) RMSE = 152.67486 (60 rounds)\nFold #5: (Data size: train = 51817, test = 8635) RMSE = 280.94161 (164 rounds)\nFold #6: (Data size: train = 60452, test = 8635) RMSE = 181.91048 (30 rounds)\nFold #7: (Data size: train = 69087, test = 8635) RMSE = 180.72091 (59 rounds)\nFold #8: (Data size: train = 77722, test = 8635) RMSE = 212.95411 (200 rounds)\nFold #9: (Data size: train = 86357, test = 8635) RMSE = 204.21109 (148 rounds)\nAvg. RMSE = 182.84446 +/- 39.14315\n[Time taken: 6.19s]\n\nCPU times: user 15min 10s, sys: 7.87 s, total: 15min 18s\nWall time: 14min 18s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ntp_2_2 = run_experiment(\n    data=(train_ffill[features], train_ffill[TARGET], test[features]),\n    cat_features=cat_features_2,\n    n_trials=100\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"htDBpKGi3LRb","outputId":"a37f86a1-28a3-4ffc-862a-bc32cbfa4256","execution":{"iopub.status.busy":"2022-11-18T17:31:43.922944Z","iopub.execute_input":"2022-11-18T17:31:43.923430Z","iopub.status.idle":"2022-11-18T17:50:31.991063Z","shell.execute_reply.started":"2022-11-18T17:31:43.923390Z","shell.execute_reply":"2022-11-18T17:50:31.990071Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 91 -> Best value: 181.37630\nBest hyperparameters:\nlearning_rate   - 0.15000000000000002\nmax_depth       - 3\nmin_child_weight - 241\ngamma           - 17.8\nalpha           - 4.45\nlambda          - 0.06395872229902426\nsubsample       - 0.9\ncolsample_bytree - 0.9\ncolsample_bylevel - 0.85\ncolsample_bynode - 0.8\nmax_cat_to_onehot - 4\n[Time taken: 1120.71s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8642, test = 8635) RMSE = 151.37181 (48 rounds)\nFold #1: (Data size: train = 17277, test = 8635) RMSE = 156.20781 (25 rounds)\nFold #2: (Data size: train = 25912, test = 8635) RMSE = 148.28728 (45 rounds)\nFold #3: (Data size: train = 34547, test = 8635) RMSE = 159.05417 (284 rounds)\nFold #4: (Data size: train = 43182, test = 8635) RMSE = 147.95721 (115 rounds)\nFold #5: (Data size: train = 51817, test = 8635) RMSE = 276.91299 (239 rounds)\nFold #6: (Data size: train = 60452, test = 8635) RMSE = 191.74464 (29 rounds)\nFold #7: (Data size: train = 69087, test = 8635) RMSE = 182.73065 (57 rounds)\nFold #8: (Data size: train = 77722, test = 8635) RMSE = 200.70727 (378 rounds)\nFold #9: (Data size: train = 86357, test = 8635) RMSE = 198.78922 (251 rounds)\nAvg. RMSE = 181.37630 +/- 37.62607\n[Time taken: 7.35s]\n\nCPU times: user 19min 40s, sys: 8.18 s, total: 19min 48s\nWall time: 18min 48s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ntp_2_3 = run_experiment(\n    data=(train_ffill[features], train_ffill[TARGET], test[features]),\n    cat_features=cat_features_3,\n    n_trials=100\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EsSTJa0D3LRc","outputId":"d5561408-37c7-4901-b2b8-f75cb8ec5c67","execution":{"iopub.status.busy":"2022-11-18T17:50:31.992714Z","iopub.execute_input":"2022-11-18T17:50:31.993078Z","iopub.status.idle":"2022-11-18T18:12:14.991214Z","shell.execute_reply.started":"2022-11-18T17:50:31.993042Z","shell.execute_reply":"2022-11-18T18:12:14.990249Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 87 -> Best value: 183.07864\nBest hyperparameters:\nlearning_rate   - 0.2\nmax_depth       - 3\nmin_child_weight - 239\ngamma           - 9.0\nalpha           - 5.0\nlambda          - 0.9345649158392516\nsubsample       - 0.75\ncolsample_bytree - 0.85\ncolsample_bylevel - 0.75\ncolsample_bynode - 1.0\nmax_cat_to_onehot - 7\n[Time taken: 1296.53s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8642, test = 8635) RMSE = 135.06189 (41 rounds)\nFold #1: (Data size: train = 17277, test = 8635) RMSE = 154.61332 (17 rounds)\nFold #2: (Data size: train = 25912, test = 8635) RMSE = 153.58767 (26 rounds)\nFold #3: (Data size: train = 34547, test = 8635) RMSE = 175.99744 (193 rounds)\nFold #4: (Data size: train = 43182, test = 8635) RMSE = 155.66210 (76 rounds)\nFold #5: (Data size: train = 51817, test = 8635) RMSE = 278.22915 (365 rounds)\nFold #6: (Data size: train = 60452, test = 8635) RMSE = 186.54346 (25 rounds)\nFold #7: (Data size: train = 69087, test = 8635) RMSE = 179.41475 (50 rounds)\nFold #8: (Data size: train = 77722, test = 8635) RMSE = 209.44148 (244 rounds)\nFold #9: (Data size: train = 86357, test = 8635) RMSE = 202.23514 (77 rounds)\nAvg. RMSE = 183.07864 +/- 38.63733\n[Time taken: 6.46s]\n\nCPU times: user 22min 35s, sys: 7.75 s, total: 22min 43s\nWall time: 21min 42s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Dataset 3: train_bfill","metadata":{"id":"5TDaZNBr3ing"}},{"cell_type":"code","source":"%%time\ntp_3_1 = run_experiment(\n    data=(train_bfill[features], train_bfill[TARGET], test[features]),\n    cat_features=cat_features_1,\n    n_trials=100\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tmeHJnmt3inh","outputId":"987f5cc6-6140-47e4-b2b1-06b4937b6729","execution":{"iopub.status.busy":"2022-11-18T18:12:14.992778Z","iopub.execute_input":"2022-11-18T18:12:14.993111Z","iopub.status.idle":"2022-11-18T18:28:57.893398Z","shell.execute_reply.started":"2022-11-18T18:12:14.993077Z","shell.execute_reply":"2022-11-18T18:28:57.892451Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 94 -> Best value: 182.79927\nBest hyperparameters:\nlearning_rate   - 0.2\nmax_depth       - 3\nmin_child_weight - 15\ngamma           - 1.3\nalpha           - 4.8500000000000005\nlambda          - 2.2381124974760804\nsubsample       - 0.85\ncolsample_bytree - 0.95\ncolsample_bylevel - 0.85\ncolsample_bynode - 1.0\nmax_cat_to_onehot - 4\n[Time taken: 996.95s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8642, test = 8635) RMSE = 156.50045 (39 rounds)\nFold #1: (Data size: train = 17277, test = 8635) RMSE = 155.68745 (22 rounds)\nFold #2: (Data size: train = 25912, test = 8635) RMSE = 157.18357 (40 rounds)\nFold #3: (Data size: train = 34547, test = 8635) RMSE = 165.42386 (175 rounds)\nFold #4: (Data size: train = 43182, test = 8635) RMSE = 154.86009 (97 rounds)\nFold #5: (Data size: train = 51817, test = 8635) RMSE = 277.20765 (144 rounds)\nFold #6: (Data size: train = 60452, test = 8635) RMSE = 179.35359 (26 rounds)\nFold #7: (Data size: train = 69087, test = 8635) RMSE = 180.96979 (62 rounds)\nFold #8: (Data size: train = 77722, test = 8635) RMSE = 194.50935 (270 rounds)\nFold #9: (Data size: train = 86357, test = 8635) RMSE = 206.29691 (157 rounds)\nAvg. RMSE = 182.79927 +/- 35.75300\n[Time taken: 5.94s]\n\nCPU times: user 17min 33s, sys: 7.84 s, total: 17min 41s\nWall time: 16min 42s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ntp_3_2 = run_experiment(\n    data=(train_bfill[features], train_bfill[TARGET], test[features]),\n    cat_features=cat_features_2,\n    n_trials=100\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9YIW3YzS3inh","outputId":"9b944842-6dd1-43ae-eea0-f84796349f29","execution":{"iopub.status.busy":"2022-11-18T18:28:57.894976Z","iopub.execute_input":"2022-11-18T18:28:57.895290Z","iopub.status.idle":"2022-11-18T18:48:28.950799Z","shell.execute_reply.started":"2022-11-18T18:28:57.895262Z","shell.execute_reply":"2022-11-18T18:48:28.948925Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 80 -> Best value: 182.66172\nBest hyperparameters:\nlearning_rate   - 0.15000000000000002\nmax_depth       - 4\nmin_child_weight - 214\ngamma           - 19.0\nalpha           - 3.85\nlambda          - 0.1048582995497879\nsubsample       - 0.8\ncolsample_bytree - 0.8\ncolsample_bylevel - 0.75\ncolsample_bynode - 0.75\nmax_cat_to_onehot - 4\n[Time taken: 1162.56s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8642, test = 8635) RMSE = 149.97273 (49 rounds)\nFold #1: (Data size: train = 17277, test = 8635) RMSE = 155.75569 (20 rounds)\nFold #2: (Data size: train = 25912, test = 8635) RMSE = 147.60262 (38 rounds)\nFold #3: (Data size: train = 34547, test = 8635) RMSE = 162.59706 (225 rounds)\nFold #4: (Data size: train = 43182, test = 8635) RMSE = 148.77962 (93 rounds)\nFold #5: (Data size: train = 51817, test = 8635) RMSE = 291.77645 (215 rounds)\nFold #6: (Data size: train = 60452, test = 8635) RMSE = 188.00260 (28 rounds)\nFold #7: (Data size: train = 69087, test = 8635) RMSE = 177.55744 (67 rounds)\nFold #8: (Data size: train = 77722, test = 8635) RMSE = 202.58711 (163 rounds)\nFold #9: (Data size: train = 86357, test = 8635) RMSE = 201.98591 (85 rounds)\nAvg. RMSE = 182.66172 +/- 41.59721\n[Time taken: 8.49s]\n\nCPU times: user 20min 22s, sys: 7.88 s, total: 20min 30s\nWall time: 19min 31s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ntp_3_3 = run_experiment(\n    data=(train_bfill[features], train_bfill[TARGET], test[features]),\n    cat_features=cat_features_3,\n    n_trials=100\n)","metadata":{"id":"UqQlyyfZ3ini","execution":{"iopub.status.busy":"2022-11-18T18:48:28.952468Z","iopub.execute_input":"2022-11-18T18:48:28.952818Z","iopub.status.idle":"2022-11-18T19:08:51.154756Z","shell.execute_reply.started":"2022-11-18T18:48:28.952784Z","shell.execute_reply":"2022-11-18T19:08:51.152952Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 97 -> Best value: 183.56230\nBest hyperparameters:\nlearning_rate   - 0.1\nmax_depth       - 3\nmin_child_weight - 205\ngamma           - 9.200000000000001\nalpha           - 1.55\nlambda          - 0.20452161396044213\nsubsample       - 0.9\ncolsample_bytree - 0.85\ncolsample_bylevel - 0.85\ncolsample_bynode - 0.9\nmax_cat_to_onehot - 4\n[Time taken: 1214.27s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8642, test = 8635) RMSE = 136.78337 (70 rounds)\nFold #1: (Data size: train = 17277, test = 8635) RMSE = 151.31620 (38 rounds)\nFold #2: (Data size: train = 25912, test = 8635) RMSE = 150.66626 (51 rounds)\nFold #3: (Data size: train = 34547, test = 8635) RMSE = 174.06109 (261 rounds)\nFold #4: (Data size: train = 43182, test = 8635) RMSE = 148.59353 (143 rounds)\nFold #5: (Data size: train = 51817, test = 8635) RMSE = 289.22180 (561 rounds)\nFold #6: (Data size: train = 60452, test = 8635) RMSE = 193.57316 (46 rounds)\nFold #7: (Data size: train = 69087, test = 8635) RMSE = 178.85044 (99 rounds)\nFold #8: (Data size: train = 77722, test = 8635) RMSE = 211.24612 (133 rounds)\nFold #9: (Data size: train = 86357, test = 8635) RMSE = 201.31097 (137 rounds)\nAvg. RMSE = 183.56230 +/- 42.41589\n[Time taken: 7.92s]\n\nCPU times: user 21min 17s, sys: 8.32 s, total: 21min 25s\nWall time: 20min 22s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Dataset 4: train_linear","metadata":{"id":"W18uPeG13inj"}},{"cell_type":"code","source":"%%time\ntp_4_1 = run_experiment(\n    data=(train_linear[features], train_linear[TARGET], test[features]),\n    cat_features=cat_features_1,\n    n_trials=100\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aEtFs-j83inj","outputId":"b1079329-e9ef-4904-a418-bbf6a4adc132","execution":{"iopub.status.busy":"2022-11-18T19:08:51.156391Z","iopub.execute_input":"2022-11-18T19:08:51.156747Z","iopub.status.idle":"2022-11-18T19:26:06.046636Z","shell.execute_reply.started":"2022-11-18T19:08:51.156712Z","shell.execute_reply":"2022-11-18T19:26:06.045649Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 96 -> Best value: 183.28997\nBest hyperparameters:\nlearning_rate   - 0.1\nmax_depth       - 3\nmin_child_weight - 12\ngamma           - 18.7\nalpha           - 2.85\nlambda          - 0.7041541403292714\nsubsample       - 0.75\ncolsample_bytree - 0.8\ncolsample_bylevel - 0.8\ncolsample_bynode - 0.9\nmax_cat_to_onehot - 4\n[Time taken: 1025.48s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8642, test = 8635) RMSE = 145.10162 (84 rounds)\nFold #1: (Data size: train = 17277, test = 8635) RMSE = 152.57850 (39 rounds)\nFold #2: (Data size: train = 25912, test = 8635) RMSE = 150.13628 (101 rounds)\nFold #3: (Data size: train = 34547, test = 8635) RMSE = 164.75381 (402 rounds)\nFold #4: (Data size: train = 43182, test = 8635) RMSE = 152.15575 (213 rounds)\nFold #5: (Data size: train = 51817, test = 8635) RMSE = 298.74851 (428 rounds)\nFold #6: (Data size: train = 60452, test = 8635) RMSE = 198.00055 (54 rounds)\nFold #7: (Data size: train = 69087, test = 8635) RMSE = 178.17131 (129 rounds)\nFold #8: (Data size: train = 77722, test = 8635) RMSE = 192.78433 (799 rounds)\nFold #9: (Data size: train = 86357, test = 8635) RMSE = 200.46908 (300 rounds)\nAvg. RMSE = 183.28997 +/- 43.32688\n[Time taken: 9.40s]\n\nCPU times: user 18min 6s, sys: 7.94 s, total: 18min 14s\nWall time: 17min 14s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ntp_4_2 = run_experiment(\n    data=(train_linear[features], train_linear[TARGET], test[features]),\n    cat_features=cat_features_2,\n    n_trials=100\n)","metadata":{"id":"oD4VBOXk3inj","execution":{"iopub.status.busy":"2022-11-18T19:26:06.047999Z","iopub.execute_input":"2022-11-18T19:26:06.049459Z","iopub.status.idle":"2022-11-18T19:44:28.232304Z","shell.execute_reply.started":"2022-11-18T19:26:06.049421Z","shell.execute_reply":"2022-11-18T19:44:28.231255Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 36 -> Best value: 180.47819\nBest hyperparameters:\nlearning_rate   - 0.15000000000000002\nmax_depth       - 3\nmin_child_weight - 239\ngamma           - 14.4\nalpha           - 3.5500000000000003\nlambda          - 0.011325915331149764\nsubsample       - 0.9\ncolsample_bytree - 0.85\ncolsample_bylevel - 0.9\ncolsample_bynode - 0.95\nmax_cat_to_onehot - 4\n[Time taken: 1094.79s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8642, test = 8635) RMSE = 146.17872 (47 rounds)\nFold #1: (Data size: train = 17277, test = 8635) RMSE = 154.37345 (22 rounds)\nFold #2: (Data size: train = 25912, test = 8635) RMSE = 150.69021 (45 rounds)\nFold #3: (Data size: train = 34547, test = 8635) RMSE = 158.10051 (371 rounds)\nFold #4: (Data size: train = 43182, test = 8635) RMSE = 150.99174 (102 rounds)\nFold #5: (Data size: train = 51817, test = 8635) RMSE = 278.30587 (257 rounds)\nFold #6: (Data size: train = 60452, test = 8635) RMSE = 185.75418 (27 rounds)\nFold #7: (Data size: train = 69087, test = 8635) RMSE = 180.53697 (52 rounds)\nFold #8: (Data size: train = 77722, test = 8635) RMSE = 201.14142 (274 rounds)\nFold #9: (Data size: train = 86357, test = 8635) RMSE = 198.70887 (156 rounds)\nAvg. RMSE = 180.47819 +/- 38.04322\n[Time taken: 7.38s]\n\nCPU times: user 19min 15s, sys: 8.09 s, total: 19min 23s\nWall time: 18min 22s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ntp_4_3 = run_experiment(\n    data=(train_linear[features], train_linear[TARGET], test[features]),\n    cat_features=cat_features_3,\n    n_trials=100\n)","metadata":{"id":"zCTF25rk3ink","execution":{"iopub.status.busy":"2022-11-18T19:44:28.233607Z","iopub.execute_input":"2022-11-18T19:44:28.234269Z","iopub.status.idle":"2022-11-18T20:05:29.827034Z","shell.execute_reply.started":"2022-11-18T19:44:28.234231Z","shell.execute_reply":"2022-11-18T20:05:29.826097Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 86 -> Best value: 183.92572\nBest hyperparameters:\nlearning_rate   - 0.2\nmax_depth       - 3\nmin_child_weight - 237\ngamma           - 9.3\nalpha           - 4.15\nlambda          - 0.49621855924589847\nsubsample       - 1.0\ncolsample_bytree - 0.85\ncolsample_bylevel - 0.85\ncolsample_bynode - 0.85\nmax_cat_to_onehot - 12\n[Time taken: 1255.33s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8642, test = 8635) RMSE = 139.45133 (35 rounds)\nFold #1: (Data size: train = 17277, test = 8635) RMSE = 157.23101 (17 rounds)\nFold #2: (Data size: train = 25912, test = 8635) RMSE = 152.54543 (28 rounds)\nFold #3: (Data size: train = 34547, test = 8635) RMSE = 172.88700 (196 rounds)\nFold #4: (Data size: train = 43182, test = 8635) RMSE = 152.95206 (64 rounds)\nFold #5: (Data size: train = 51817, test = 8635) RMSE = 275.48049 (182 rounds)\nFold #6: (Data size: train = 60452, test = 8635) RMSE = 187.34701 (27 rounds)\nFold #7: (Data size: train = 69087, test = 8635) RMSE = 184.39684 (44 rounds)\nFold #8: (Data size: train = 77722, test = 8635) RMSE = 208.51464 (118 rounds)\nFold #9: (Data size: train = 86357, test = 8635) RMSE = 208.45142 (53 rounds)\nAvg. RMSE = 183.92572 +/- 37.89043\n[Time taken: 6.26s]\n\nCPU times: user 21min 56s, sys: 7.97 s, total: 22min 4s\nWall time: 21min 1s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Dataset 5: train_poly3","metadata":{"id":"wQVLB-ql36jh"}},{"cell_type":"code","source":"%%time\ntp_5_1 = run_experiment(\n    data=(train_poly3[features], train_poly3[TARGET], test[features]),\n    cat_features=cat_features_1,\n    n_trials=100\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"hry4Xefw36jh","outputId":"6c8f3f2d-a988-49de-ed21-9518bc6977c9","execution":{"iopub.status.busy":"2022-11-18T20:05:29.833248Z","iopub.execute_input":"2022-11-18T20:05:29.833542Z","iopub.status.idle":"2022-11-18T20:20:50.423926Z","shell.execute_reply.started":"2022-11-18T20:05:29.833515Z","shell.execute_reply":"2022-11-18T20:20:50.422896Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 47 -> Best value: 183.58647\nBest hyperparameters:\nlearning_rate   - 0.15000000000000002\nmax_depth       - 3\nmin_child_weight - 229\ngamma           - 11.0\nalpha           - 4.9\nlambda          - 21.164423819825146\nsubsample       - 0.9\ncolsample_bytree - 0.95\ncolsample_bylevel - 0.75\ncolsample_bynode - 1.0\nmax_cat_to_onehot - 4\n[Time taken: 912.60s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8642, test = 8635) RMSE = 153.31141 (260 rounds)\nFold #1: (Data size: train = 17277, test = 8635) RMSE = 153.47656 (36 rounds)\nFold #2: (Data size: train = 25912, test = 8635) RMSE = 157.98843 (59 rounds)\nFold #3: (Data size: train = 34547, test = 8635) RMSE = 160.31351 (349 rounds)\nFold #4: (Data size: train = 43182, test = 8635) RMSE = 151.73767 (110 rounds)\nFold #5: (Data size: train = 51817, test = 8635) RMSE = 283.76824 (283 rounds)\nFold #6: (Data size: train = 60452, test = 8635) RMSE = 188.84530 (32 rounds)\nFold #7: (Data size: train = 69087, test = 8635) RMSE = 177.99335 (72 rounds)\nFold #8: (Data size: train = 77722, test = 8635) RMSE = 204.44559 (607 rounds)\nFold #9: (Data size: train = 86357, test = 8635) RMSE = 203.98462 (271 rounds)\nAvg. RMSE = 183.58647 +/- 38.70521\n[Time taken: 7.98s]\n\nCPU times: user 16min 13s, sys: 8.1 s, total: 16min 21s\nWall time: 15min 20s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ntp_5_2 = run_experiment(\n    data=(train_poly3[features], train_poly3[TARGET], test[features]),\n    cat_features=cat_features_2,\n    n_trials=100\n)","metadata":{"id":"CnG9vt0A36ji","execution":{"iopub.status.busy":"2022-11-18T20:20:50.426040Z","iopub.execute_input":"2022-11-18T20:20:50.427043Z","iopub.status.idle":"2022-11-18T20:38:35.580430Z","shell.execute_reply.started":"2022-11-18T20:20:50.427004Z","shell.execute_reply":"2022-11-18T20:38:35.579399Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 81 -> Best value: 181.14221\nBest hyperparameters:\nlearning_rate   - 0.25\nmax_depth       - 3\nmin_child_weight - 247\ngamma           - 13.3\nalpha           - 4.1000000000000005\nlambda          - 1.6441607746861542\nsubsample       - 0.9\ncolsample_bytree - 0.75\ncolsample_bylevel - 0.9\ncolsample_bynode - 0.85\nmax_cat_to_onehot - 7\n[Time taken: 1058.59s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8642, test = 8635) RMSE = 146.28250 (37 rounds)\nFold #1: (Data size: train = 17277, test = 8635) RMSE = 153.55646 (13 rounds)\nFold #2: (Data size: train = 25912, test = 8635) RMSE = 145.53395 (34 rounds)\nFold #3: (Data size: train = 34547, test = 8635) RMSE = 163.85966 (164 rounds)\nFold #4: (Data size: train = 43182, test = 8635) RMSE = 153.57197 (108 rounds)\nFold #5: (Data size: train = 51817, test = 8635) RMSE = 284.14752 (149 rounds)\nFold #6: (Data size: train = 60452, test = 8635) RMSE = 183.40755 (28 rounds)\nFold #7: (Data size: train = 69087, test = 8635) RMSE = 179.32037 (40 rounds)\nFold #8: (Data size: train = 77722, test = 8635) RMSE = 199.35461 (411 rounds)\nFold #9: (Data size: train = 86357, test = 8635) RMSE = 202.38749 (220 rounds)\nAvg. RMSE = 181.14221 +/- 39.62894\n[Time taken: 6.56s]\n\nCPU times: user 18min 37s, sys: 7.75 s, total: 18min 45s\nWall time: 17min 45s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ntp_5_3 = run_experiment(\n    data=(train_poly3[features], train_poly3[TARGET], test[features]),\n    cat_features=cat_features_3,\n    n_trials=100\n)","metadata":{"id":"0lNIO0yB36ji","execution":{"iopub.status.busy":"2022-11-18T20:38:35.582025Z","iopub.execute_input":"2022-11-18T20:38:35.582631Z","iopub.status.idle":"2022-11-18T20:59:04.979175Z","shell.execute_reply.started":"2022-11-18T20:38:35.582594Z","shell.execute_reply":"2022-11-18T20:59:04.978091Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 55 -> Best value: 184.58300\nBest hyperparameters:\nlearning_rate   - 0.30000000000000004\nmax_depth       - 3\nmin_child_weight - 216\ngamma           - 11.5\nalpha           - 1.35\nlambda          - 0.5971331530602634\nsubsample       - 0.95\ncolsample_bytree - 0.85\ncolsample_bylevel - 0.95\ncolsample_bynode - 0.85\nmax_cat_to_onehot - 7\n[Time taken: 1224.09s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8642, test = 8635) RMSE = 140.44804 (28 rounds)\nFold #1: (Data size: train = 17277, test = 8635) RMSE = 156.54361 (11 rounds)\nFold #2: (Data size: train = 25912, test = 8635) RMSE = 153.88581 (20 rounds)\nFold #3: (Data size: train = 34547, test = 8635) RMSE = 168.19640 (78 rounds)\nFold #4: (Data size: train = 43182, test = 8635) RMSE = 154.45726 (63 rounds)\nFold #5: (Data size: train = 51817, test = 8635) RMSE = 279.73373 (132 rounds)\nFold #6: (Data size: train = 60452, test = 8635) RMSE = 196.91836 (22 rounds)\nFold #7: (Data size: train = 69087, test = 8635) RMSE = 178.48529 (40 rounds)\nFold #8: (Data size: train = 77722, test = 8635) RMSE = 207.97103 (43 rounds)\nFold #9: (Data size: train = 86357, test = 8635) RMSE = 209.19050 (45 rounds)\nAvg. RMSE = 184.58300 +/- 39.04873\n[Time taken: 5.29s]\n\nCPU times: user 21min 22s, sys: 7.32 s, total: 21min 29s\nWall time: 20min 29s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Dataset 6: train_poly5","metadata":{"id":"L0RbOvsl36ji"}},{"cell_type":"code","source":"%%time\ntp_6_1 = run_experiment(\n    data=(train_poly5[features], train_poly5[TARGET], test[features]),\n    cat_features=cat_features_1,\n    n_trials=100\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"FcJVqll036jj","outputId":"fdade9fd-d158-4d1b-c9c3-f87c8bb3e325","execution":{"iopub.status.busy":"2022-11-18T20:59:04.980716Z","iopub.execute_input":"2022-11-18T20:59:04.981069Z","iopub.status.idle":"2022-11-18T21:11:19.846271Z","shell.execute_reply.started":"2022-11-18T20:59:04.981035Z","shell.execute_reply":"2022-11-18T21:11:19.845253Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 76 -> Best value: 181.55543\nBest hyperparameters:\nlearning_rate   - 0.25\nmax_depth       - 4\nmin_child_weight - 15\ngamma           - 0.6000000000000001\nalpha           - 3.75\nlambda          - 0.14967373371356124\nsubsample       - 1.0\ncolsample_bytree - 0.9\ncolsample_bylevel - 0.8\ncolsample_bynode - 0.85\nmax_cat_to_onehot - 12\n[Time taken: 729.54s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8642, test = 8635) RMSE = 152.94669 (36 rounds)\nFold #1: (Data size: train = 17277, test = 8635) RMSE = 147.01375 (13 rounds)\nFold #2: (Data size: train = 25912, test = 8635) RMSE = 153.98375 (26 rounds)\nFold #3: (Data size: train = 34547, test = 8635) RMSE = 166.96919 (91 rounds)\nFold #4: (Data size: train = 43182, test = 8635) RMSE = 158.71125 (58 rounds)\nFold #5: (Data size: train = 51817, test = 8635) RMSE = 265.07341 (205 rounds)\nFold #6: (Data size: train = 60452, test = 8635) RMSE = 177.50076 (16 rounds)\nFold #7: (Data size: train = 69087, test = 8635) RMSE = 186.56071 (26 rounds)\nFold #8: (Data size: train = 77722, test = 8635) RMSE = 201.04946 (218 rounds)\nFold #9: (Data size: train = 86357, test = 8635) RMSE = 205.74529 (64 rounds)\nAvg. RMSE = 181.55543 +/- 33.89441\n[Time taken: 5.32s]\n\nCPU times: user 13min 6s, sys: 7.16 s, total: 13min 13s\nWall time: 12min 14s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ntp_6_2 = run_experiment(\n    data=(train_poly5[features], train_poly5[TARGET], test[features]),\n    cat_features=cat_features_2,\n    n_trials=100\n)","metadata":{"id":"pruQzsIy36jj","execution":{"iopub.status.busy":"2022-11-18T21:11:19.847680Z","iopub.execute_input":"2022-11-18T21:11:19.848479Z","iopub.status.idle":"2022-11-18T21:31:02.185072Z","shell.execute_reply.started":"2022-11-18T21:11:19.848443Z","shell.execute_reply":"2022-11-18T21:31:02.183934Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 44 -> Best value: 180.38660\nBest hyperparameters:\nlearning_rate   - 0.15000000000000002\nmax_depth       - 3\nmin_child_weight - 201\ngamma           - 4.1000000000000005\nalpha           - 3.75\nlambda          - 0.07004965373110639\nsubsample       - 0.8\ncolsample_bytree - 0.8\ncolsample_bylevel - 0.85\ncolsample_bynode - 0.85\nmax_cat_to_onehot - 4\n[Time taken: 1175.19s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8642, test = 8635) RMSE = 150.43260 (48 rounds)\nFold #1: (Data size: train = 17277, test = 8635) RMSE = 152.92657 (26 rounds)\nFold #2: (Data size: train = 25912, test = 8635) RMSE = 145.28758 (47 rounds)\nFold #3: (Data size: train = 34547, test = 8635) RMSE = 156.25517 (186 rounds)\nFold #4: (Data size: train = 43182, test = 8635) RMSE = 147.79236 (104 rounds)\nFold #5: (Data size: train = 51817, test = 8635) RMSE = 279.19718 (250 rounds)\nFold #6: (Data size: train = 60452, test = 8635) RMSE = 183.99374 (28 rounds)\nFold #7: (Data size: train = 69087, test = 8635) RMSE = 178.72696 (75 rounds)\nFold #8: (Data size: train = 77722, test = 8635) RMSE = 207.42126 (394 rounds)\nFold #9: (Data size: train = 86357, test = 8635) RMSE = 201.83260 (277 rounds)\nAvg. RMSE = 180.38660 +/- 39.36756\n[Time taken: 7.13s]\n\nCPU times: user 20min 35s, sys: 8.29 s, total: 20min 43s\nWall time: 19min 42s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ntp_6_3 = run_experiment(\n    data=(train_poly5[features], train_poly5[TARGET], test[features]),\n    cat_features=cat_features_3,\n    n_trials=100\n)","metadata":{"id":"jt-vg4Bg36jj","execution":{"iopub.status.busy":"2022-11-18T21:31:02.186820Z","iopub.execute_input":"2022-11-18T21:31:02.187505Z","iopub.status.idle":"2022-11-18T21:49:32.586348Z","shell.execute_reply.started":"2022-11-18T21:31:02.187468Z","shell.execute_reply":"2022-11-18T21:49:32.585262Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 98 -> Best value: 184.96687\nBest hyperparameters:\nlearning_rate   - 0.30000000000000004\nmax_depth       - 3\nmin_child_weight - 191\ngamma           - 13.600000000000001\nalpha           - 0.05\nlambda          - 0.23987203403604967\nsubsample       - 0.75\ncolsample_bytree - 0.95\ncolsample_bylevel - 0.85\ncolsample_bynode - 0.8\nmax_cat_to_onehot - 4\n[Time taken: 1104.17s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8642, test = 8635) RMSE = 136.93183 (45 rounds)\nFold #1: (Data size: train = 17277, test = 8635) RMSE = 153.52412 (12 rounds)\nFold #2: (Data size: train = 25912, test = 8635) RMSE = 153.72447 (17 rounds)\nFold #3: (Data size: train = 34547, test = 8635) RMSE = 173.66120 (107 rounds)\nFold #4: (Data size: train = 43182, test = 8635) RMSE = 152.31134 (30 rounds)\nFold #5: (Data size: train = 51817, test = 8635) RMSE = 277.03333 (270 rounds)\nFold #6: (Data size: train = 60452, test = 8635) RMSE = 207.63429 (64 rounds)\nFold #7: (Data size: train = 69087, test = 8635) RMSE = 178.48732 (38 rounds)\nFold #8: (Data size: train = 77722, test = 8635) RMSE = 212.53887 (315 rounds)\nFold #9: (Data size: train = 86357, test = 8635) RMSE = 203.82190 (36 rounds)\nAvg. RMSE = 184.96687 +/- 39.51463\n[Time taken: 6.22s]\n\nCPU times: user 19min 24s, sys: 7.57 s, total: 19min 31s\nWall time: 18min 30s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Dataset 7: train_iterimp","metadata":{"id":"EXml8Ycy36jj"}},{"cell_type":"code","source":"%%time\ntp_7_1 = run_experiment(\n    data=(train_iterimp[features], train_iterimp[TARGET], test[features]),\n    cat_features=cat_features_1,\n    n_trials=100\n)","metadata":{"id":"RynoFeri36jk","execution":{"iopub.status.busy":"2022-11-18T21:49:32.587879Z","iopub.execute_input":"2022-11-18T21:49:32.588233Z","iopub.status.idle":"2022-11-18T22:02:14.923985Z","shell.execute_reply.started":"2022-11-18T21:49:32.588181Z","shell.execute_reply":"2022-11-18T22:02:14.922883Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 30 -> Best value: 196.82030\nBest hyperparameters:\nlearning_rate   - 0.25\nmax_depth       - 3\nmin_child_weight - 22\ngamma           - 3.6\nalpha           - 0.0\nlambda          - 0.12232938405694538\nsubsample       - 0.85\ncolsample_bytree - 0.95\ncolsample_bylevel - 0.85\ncolsample_bynode - 1.0\nmax_cat_to_onehot - 12\n[Time taken: 757.49s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8642, test = 8635) RMSE = 169.54536 (30 rounds)\nFold #1: (Data size: train = 17277, test = 8635) RMSE = 172.36554 (14 rounds)\nFold #2: (Data size: train = 25912, test = 8635) RMSE = 172.06723 (30 rounds)\nFold #3: (Data size: train = 34547, test = 8635) RMSE = 176.17466 (170 rounds)\nFold #4: (Data size: train = 43182, test = 8635) RMSE = 173.03082 (62 rounds)\nFold #5: (Data size: train = 51817, test = 8635) RMSE = 293.82073 (122 rounds)\nFold #6: (Data size: train = 60452, test = 8635) RMSE = 183.86992 (20 rounds)\nFold #7: (Data size: train = 69087, test = 8635) RMSE = 195.03287 (48 rounds)\nFold #8: (Data size: train = 77722, test = 8635) RMSE = 213.84517 (220 rounds)\nFold #9: (Data size: train = 86357, test = 8635) RMSE = 218.45068 (141 rounds)\nAvg. RMSE = 196.82030 +/- 36.44800\n[Time taken: 4.84s]\n\nCPU times: user 13min 34s, sys: 7.54 s, total: 13min 41s\nWall time: 12min 42s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ntp_7_2 = run_experiment(\n    data=(train_iterimp[features], train_iterimp[TARGET], test[features]),\n    cat_features=cat_features_2,\n    n_trials=100\n)","metadata":{"id":"eLYz61G536jk","execution":{"iopub.status.busy":"2022-11-18T22:02:14.925666Z","iopub.execute_input":"2022-11-18T22:02:14.926009Z","iopub.status.idle":"2022-11-18T22:21:52.567662Z","shell.execute_reply.started":"2022-11-18T22:02:14.925974Z","shell.execute_reply":"2022-11-18T22:21:52.565872Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 74 -> Best value: 195.25769\nBest hyperparameters:\nlearning_rate   - 0.2\nmax_depth       - 3\nmin_child_weight - 249\ngamma           - 16.400000000000002\nalpha           - 3.2\nlambda          - 0.010468224998474059\nsubsample       - 0.75\ncolsample_bytree - 0.8\ncolsample_bylevel - 0.85\ncolsample_bynode - 0.9\nmax_cat_to_onehot - 12\n[Time taken: 1170.43s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8642, test = 8635) RMSE = 166.89780 (130 rounds)\nFold #1: (Data size: train = 17277, test = 8635) RMSE = 177.31381 (19 rounds)\nFold #2: (Data size: train = 25912, test = 8635) RMSE = 161.29499 (48 rounds)\nFold #3: (Data size: train = 34547, test = 8635) RMSE = 172.27974 (337 rounds)\nFold #4: (Data size: train = 43182, test = 8635) RMSE = 169.35589 (97 rounds)\nFold #5: (Data size: train = 51817, test = 8635) RMSE = 274.88423 (257 rounds)\nFold #6: (Data size: train = 60452, test = 8635) RMSE = 200.81619 (27 rounds)\nFold #7: (Data size: train = 69087, test = 8635) RMSE = 196.97621 (60 rounds)\nFold #8: (Data size: train = 77722, test = 8635) RMSE = 218.87562 (344 rounds)\nFold #9: (Data size: train = 86357, test = 8635) RMSE = 213.88244 (128 rounds)\nAvg. RMSE = 195.25769 +/- 32.79869\n[Time taken: 7.21s]\n\nCPU times: user 20min 29s, sys: 8.34 s, total: 20min 37s\nWall time: 19min 37s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ntp_7_3 = run_experiment(\n    data=(train_iterimp[features], train_iterimp[TARGET], test[features]),\n    cat_features=cat_features_3,\n    n_trials=100\n)","metadata":{"id":"2UGL0LYl36jk","execution":{"iopub.status.busy":"2022-11-18T22:21:52.569149Z","iopub.execute_input":"2022-11-18T22:21:52.569513Z","iopub.status.idle":"2022-11-18T22:42:35.558186Z","shell.execute_reply.started":"2022-11-18T22:21:52.569479Z","shell.execute_reply":"2022-11-18T22:42:35.557257Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"----------Hyperparameter tuning----------\nBest trial: 91 -> Best value: 198.93763\nBest hyperparameters:\nlearning_rate   - 0.15000000000000002\nmax_depth       - 3\nmin_child_weight - 249\ngamma           - 17.0\nalpha           - 1.05\nlambda          - 1.1007237447909146\nsubsample       - 0.8\ncolsample_bytree - 0.85\ncolsample_bylevel - 0.85\ncolsample_bynode - 1.0\nmax_cat_to_onehot - 12\n[Time taken: 1235.60s]\n\n-----Cross-validation and prediction-----\nFold #0: (Data size: train =  8642, test = 8635) RMSE = 150.96151 (69 rounds)\nFold #1: (Data size: train = 17277, test = 8635) RMSE = 175.66440 (25 rounds)\nFold #2: (Data size: train = 25912, test = 8635) RMSE = 168.49465 (40 rounds)\nFold #3: (Data size: train = 34547, test = 8635) RMSE = 187.11395 (133 rounds)\nFold #4: (Data size: train = 43182, test = 8635) RMSE = 174.31470 (92 rounds)\nFold #5: (Data size: train = 51817, test = 8635) RMSE = 292.27393 (354 rounds)\nFold #6: (Data size: train = 60452, test = 8635) RMSE = 204.84516 (30 rounds)\nFold #7: (Data size: train = 69087, test = 8635) RMSE = 198.23157 (90 rounds)\nFold #8: (Data size: train = 77722, test = 8635) RMSE = 224.66983 (285 rounds)\nFold #9: (Data size: train = 86357, test = 8635) RMSE = 212.80660 (150 rounds)\nAvg. RMSE = 198.93763 +/- 37.57362\n[Time taken: 7.38s]\n\nCPU times: user 21min 36s, sys: 7.91 s, total: 21min 44s\nWall time: 20min 42s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Submission files","metadata":{"id":"EahA1dJ47Z1P"}},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7npzUESt7bGc","outputId":"fbf02c19-bbaf-48bb-be25-b483a6533c5d","execution":{"iopub.status.busy":"2022-11-18T22:42:35.559774Z","iopub.execute_input":"2022-11-18T22:42:35.560120Z","iopub.status.idle":"2022-11-18T22:42:35.564397Z","shell.execute_reply.started":"2022-11-18T22:42:35.560086Z","shell.execute_reply":"2022-11-18T22:42:35.563255Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# NOTEBOOK = '01'\n# SUBMISSION_PATH = f'/content/drive/MyDrive/data_science_competitions/analytics_vidhya/jobathon_nov22/submissions/nb_{NOTEBOOK}'\n# if not os.path.isdir(SUBMISSION_PATH):\n#     os.makedirs(SUBMISSION_PATH)","metadata":{"id":"Z39yNfKD7b95","execution":{"iopub.status.busy":"2022-11-18T22:42:35.565805Z","iopub.execute_input":"2022-11-18T22:42:35.566384Z","iopub.status.idle":"2022-11-18T22:42:35.576906Z","shell.execute_reply.started":"2022-11-18T22:42:35.566347Z","shell.execute_reply":"2022-11-18T22:42:35.575923Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def create_submission_files(test_preds: pd.DataFrame, config: str):\n    for col in (test_preds.columns):\n        sub = sample_sub.copy()\n        sub[TARGET] = test_preds[col]\n        sub.to_csv(f'{config}_{col}.csv', index=False)","metadata":{"id":"5y6XhjNx8OJT","execution":{"iopub.status.busy":"2022-11-18T22:42:35.578281Z","iopub.execute_input":"2022-11-18T22:42:35.578632Z","iopub.status.idle":"2022-11-18T22:42:35.588541Z","shell.execute_reply.started":"2022-11-18T22:42:35.578597Z","shell.execute_reply":"2022-11-18T22:42:35.587692Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"create_submission_files(tp_1_1, '1_1')\ncreate_submission_files(tp_1_2, '1_2')\ncreate_submission_files(tp_1_3, '1_3')","metadata":{"id":"Ii5dHRpk8Rve","execution":{"iopub.status.busy":"2022-11-18T22:42:35.589946Z","iopub.execute_input":"2022-11-18T22:42:35.590326Z","iopub.status.idle":"2022-11-18T22:42:36.804783Z","shell.execute_reply.started":"2022-11-18T22:42:35.590271Z","shell.execute_reply":"2022-11-18T22:42:36.803676Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"create_submission_files(tp_2_1, '2_1')\ncreate_submission_files(tp_2_2, '2_2')\ncreate_submission_files(tp_2_3, '2_3')","metadata":{"id":"2x7orA-c46q_","execution":{"iopub.status.busy":"2022-11-18T22:42:36.806079Z","iopub.execute_input":"2022-11-18T22:42:36.806625Z","iopub.status.idle":"2022-11-18T22:42:38.015973Z","shell.execute_reply.started":"2022-11-18T22:42:36.806588Z","shell.execute_reply":"2022-11-18T22:42:38.015022Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"create_submission_files(tp_3_1, '3_1')\ncreate_submission_files(tp_3_2, '3_2')\ncreate_submission_files(tp_3_3, '3_3')","metadata":{"id":"qYDZjVeX47iJ","execution":{"iopub.status.busy":"2022-11-18T22:42:38.017465Z","iopub.execute_input":"2022-11-18T22:42:38.017808Z","iopub.status.idle":"2022-11-18T22:42:39.199692Z","shell.execute_reply.started":"2022-11-18T22:42:38.017773Z","shell.execute_reply":"2022-11-18T22:42:39.198768Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"create_submission_files(tp_4_1, '4_1')\ncreate_submission_files(tp_4_2, '4_2')\ncreate_submission_files(tp_4_3, '4_3')","metadata":{"id":"NnbmJQVf48OL","execution":{"iopub.status.busy":"2022-11-18T22:42:39.201271Z","iopub.execute_input":"2022-11-18T22:42:39.201640Z","iopub.status.idle":"2022-11-18T22:42:40.400121Z","shell.execute_reply.started":"2022-11-18T22:42:39.201604Z","shell.execute_reply":"2022-11-18T22:42:40.399240Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"create_submission_files(tp_5_1, '5_1')\ncreate_submission_files(tp_5_2, '5_2')\ncreate_submission_files(tp_5_3, '5_3')","metadata":{"id":"IBuUyJ5o5Dxy","execution":{"iopub.status.busy":"2022-11-18T22:42:40.401647Z","iopub.execute_input":"2022-11-18T22:42:40.402017Z","iopub.status.idle":"2022-11-18T22:42:41.657027Z","shell.execute_reply.started":"2022-11-18T22:42:40.401982Z","shell.execute_reply":"2022-11-18T22:42:41.656135Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"create_submission_files(tp_6_1, '6_1')\ncreate_submission_files(tp_6_2, '6_2')\ncreate_submission_files(tp_6_3, '6_3')","metadata":{"id":"2phhvLg85Er0","execution":{"iopub.status.busy":"2022-11-18T22:42:41.658551Z","iopub.execute_input":"2022-11-18T22:42:41.658935Z","iopub.status.idle":"2022-11-18T22:42:42.878050Z","shell.execute_reply.started":"2022-11-18T22:42:41.658898Z","shell.execute_reply":"2022-11-18T22:42:42.877160Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"create_submission_files(tp_7_1, '7_1')\ncreate_submission_files(tp_7_2, '7_2')\ncreate_submission_files(tp_7_3, '7_3')","metadata":{"id":"Sx_8zECt5FYP","execution":{"iopub.status.busy":"2022-11-18T22:42:42.879394Z","iopub.execute_input":"2022-11-18T22:42:42.880102Z","iopub.status.idle":"2022-11-18T22:42:44.099822Z","shell.execute_reply.started":"2022-11-18T22:42:42.880066Z","shell.execute_reply":"2022-11-18T22:42:44.098874Z"},"trusted":true},"execution_count":46,"outputs":[]}]}