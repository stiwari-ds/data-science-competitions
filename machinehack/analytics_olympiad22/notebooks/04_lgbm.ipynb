{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2f4wl769btH4FtP6H77GM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stiwari-ds/data-science-competitions/blob/main/machinehack/analytics_olympiad22/notebooks/04_lgbm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "HO96_P_uh3mj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oJGZ2XRPhK5A"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade optuna\n",
        "!pip install --upgrade lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import time\n",
        "import warnings\n",
        "import subprocess\n",
        "\n",
        "gc.enable()\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.precision', 4)\n",
        "np.set_printoptions(precision=4)\n",
        "\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.pruners import HyperbandPruner\n",
        "\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import log_loss"
      ],
      "metadata": {
        "id": "_t390KWjhZ-D"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove cell to run future versions\n",
        "assert optuna.__version__ == '3.0.3', f'Change in Optuna version. Original notebook version: 3.0.2'\n",
        "assert lgb.__version__ == '3.3.3', f'Change in LightGBM version. Original notebook version: 3.3.3'"
      ],
      "metadata": {
        "id": "NybqUn3whlFZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check GPU availability\n",
        "try:\n",
        "    subprocess.check_output('nvidia-smi')\n",
        "    HAVE_GPU = True\n",
        "except Exception:\n",
        "    HAVE_GPU = False\n",
        "\n",
        "print(f'GPU available: {HAVE_GPU}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUNg_6eUhluU",
        "outputId": "6dd0ee4a-bdc1-413e-a14d-6bb56eaa9b63"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 23\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "QZFT1zVDj31u"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "ZR_l09PCSu-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_URL = 'https://raw.githubusercontent.com/stiwari-ds/data-science-competitions/main/machinehack/analytics_olympiad22/data'\n",
        "\n",
        "train_full = pd.read_csv(f'{DATA_URL}/processed/train_proc.csv')\n",
        "train_clip = pd.read_csv(f'{DATA_URL}/processed/train_clip.csv')\n",
        "test = pd.read_csv(f'{DATA_URL}/processed/test_proc.csv')\n",
        "sample_sub = pd.read_csv(f'{DATA_URL}/raw/submission.csv')"
      ],
      "metadata": {
        "id": "ZHFqgGFSaMM5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET = 'OUTCOME'"
      ],
      "metadata": {
        "id": "DgmNSET-IB49"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = [f for f in test.columns \n",
        "            if f not in ('ID', 'POSTAL_CODE', 'ANNUAL_MILEAGE')]\n",
        "\n",
        "num_features = ['ID_COUNT', 'CREDIT_SCORE', 'ANNUAL_MILEAGE_K', 'DUIS', \n",
        "                'SPEEDING_VIOLATIONS', 'PAST_ACCIDENTS', 'TOTAL_PAST_INCIDENTS']\n",
        "\n",
        "cat_features = [f for f in features if f not in num_features]"
      ],
      "metadata": {
        "id": "yKL2IhrA2VnM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_full[cat_features] = train_full[cat_features].astype('category')\n",
        "# train_clip[cat_features] = train_clip[cat_features].astype('category')\n",
        "# test[cat_features] = test[cat_features].astype('category')"
      ],
      "metadata": {
        "id": "ijTShF4Q2wKN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_features = ['AGE', 'GENDER', 'DRIVING_EXPERIENCE', 'EDUCATION', 'INCOME', \n",
        "                     'CREDIT_SCORE', 'VEHICLE_OWNERSHIP', 'VEHICLE_YEAR', 'MARRIED', \n",
        "                     'CHILDREN', 'POSTAL_CODE_SUBREGION', 'ANNUAL_MILEAGE_K', \n",
        "                     'SPEEDING_VIOLATIONS', 'DUIS', 'PAST_ACCIDENTS', 'TYPE_OF_VEHICLE']\n",
        "\n",
        "cat_only_features = ['AGE', 'GENDER', 'DRIVING_EXPERIENCE', 'EDUCATION', 'INCOME', \n",
        "                     'VEHICLE_OWNERSHIP', 'VEHICLE_YEAR', 'MARRIED', 'CHILDREN', \n",
        "                     'TYPE_OF_VEHICLE', 'IS_ID_REPEATED', 'CREDIT_SCORE_BINS', \n",
        "                     'POSTAL_CODE_REGION', 'ANNUAL_MILEAGE_RANGE', 'HAS_PRIOR_DUIS', \n",
        "                     'HAS_PRIOR_SPEEDING_VIOLATIONS', 'HAS_PAST_ACCIDENTS',\n",
        "                     'HAS_PAST_INCIDENTS']\n",
        "\n",
        "#based on F-test and Chi2-test\n",
        "reduced_features = ['GENDER', 'DRIVING_EXPERIENCE', 'POSTAL_CODE_SUBREGION']\n",
        "\n",
        "#based on mutual information score\n",
        "mi_features = ['AGE', 'GENDER', 'DRIVING_EXPERIENCE', 'EDUCATION', 'INCOME', \n",
        "               'VEHICLE_OWNERSHIP', 'VEHICLE_YEAR', 'MARRIED', 'CHILDREN', \n",
        "               'TYPE_OF_VEHICLE', 'ID_COUNT', 'CREDIT_SCORE_BINS', 'POSTAL_CODE_REGION', \n",
        "               'POSTAL_CODE_SUBREGION', 'ANNUAL_MILEAGE_RANGE', 'TOTAL_PAST_INCIDENTS', \n",
        "               'HAS_PAST_INCIDENTS']"
      ],
      "metadata": {
        "id": "gTmm9UDA5qPb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline"
      ],
      "metadata": {
        "id": "l-ZLgtRMrJDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "scores = []\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "X, y = train_full[original_features], train_full[TARGET]\n",
        "feature_name = list(X.columns)\n",
        "categorical_feature = [f for f in feature_name if f in cat_features]\n",
        "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
        "    X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n",
        "    X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n",
        "\n",
        "    model = LGBMClassifier(\n",
        "        objective='binary',\n",
        "        boosting_type='goss',\n",
        "        device_type='cpu',\n",
        "        random_state=SEED\n",
        "    ) \n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        early_stopping_rounds=100,\n",
        "        eval_metric='binary_logloss',\n",
        "        feature_name=feature_name,\n",
        "        categorical_feature=categorical_feature,\n",
        "        verbose=0\n",
        "    )\n",
        "    val_preds = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "    score = log_loss(y_val, val_preds)\n",
        "    scores.append(score)\n",
        "    print(f'Fold #{fold}: ({model.best_iteration_} rounds) Logloss = {score:.6f}')\n",
        "    _ = gc.collect()\n",
        "\n",
        "print(f'\\nAvg Logloss = {np.mean(scores):.6f} +/- {np.std(scores):.6f}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccFthHeorwUe",
        "outputId": "9eae6947-d77f-4cb2-a9e6-697e00626017"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #0: (8 rounds) Logloss = 0.681001\n",
            "Fold #1: (11 rounds) Logloss = 0.680963\n",
            "Fold #2: (1 rounds) Logloss = 0.681105\n",
            "Fold #3: (2 rounds) Logloss = 0.681002\n",
            "Fold #4: (7 rounds) Logloss = 0.681159\n",
            "\n",
            "Avg Logloss = 0.681046 +/- 0.000074\n",
            "\n",
            "CPU times: user 19.1 s, sys: 122 ms, total: 19.2 s\n",
            "Wall time: 11.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVZEqwhQ2oi2"
      },
      "source": [
        "# Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "i3VeEFRe2oBe"
      },
      "outputs": [],
      "source": [
        "def objective(trial, data, base_params):\n",
        "\n",
        "    scores = []\n",
        "    X, y = data\n",
        "    feature_name = list(X.columns)\n",
        "    categorical_feature = [f for f in feature_name if f in cat_features]\n",
        "\n",
        "    param_grid = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, step=0.01),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 200, step=0.1),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 200, step=0.1),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 1000, step=5),\n",
        "        # 'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 0, 500, step=2),\n",
        "        'min_split_gain': trial.suggest_float('min_split_gain', 0, 15, step=0.01),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.95, step=0.05),\n",
        "        'top_rate': trial.suggest_float('top_rate', 0.1, 0.5, step=0.05),\n",
        "        'other_rate': trial.suggest_float('other_rate', 0.05, 0.5, step=0.05),\n",
        "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 0.75, 1.5, step=0.05)\n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
        "        X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n",
        "        X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n",
        "        \n",
        "        model = LGBMClassifier(**base_params, **param_grid)\n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            eval_metric='binary_logloss',\n",
        "            early_stopping_rounds=100,\n",
        "            feature_name=feature_name,\n",
        "            categorical_feature=categorical_feature,\n",
        "            verbose=False\n",
        "        )\n",
        "        val_preds = model.predict_proba(X_val)[:, 1]\n",
        "        scores.append(log_loss(y_val, val_preds))\n",
        "\n",
        "    return np.mean(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7JCjxMSuT3Ep"
      },
      "outputs": [],
      "source": [
        "def tune_params(data, base_params, n_trials, direction):\n",
        "    study = optuna.create_study(\n",
        "        sampler=TPESampler(seed=SEED),\n",
        "        pruner=HyperbandPruner(),\n",
        "        direction=direction\n",
        "    )\n",
        "    \n",
        "    study.optimize(\n",
        "        func=lambda trial: objective(trial, data, base_params),\n",
        "        n_trials=n_trials,\n",
        "        gc_after_trial=True\n",
        "    )\n",
        "    \n",
        "    return study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-89LWIEHeTr"
      },
      "source": [
        "# Cross-validation and experiment setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "OsTtaJBBYryk"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(data, model_params, verbose=True):\n",
        "    oof_preds = {}  #out-of-fold predictions on train set\n",
        "    test_preds = {} #predictions on test set for each fold\n",
        "    scores = [] #F1 scores on validation set\n",
        "\n",
        "    X, y, X_test = data\n",
        "    feature_name = list(X.columns)\n",
        "    categorical_feature = [f for f in feature_name if f in cat_features]\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
        "        X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n",
        "        X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n",
        "        \n",
        "        model = LGBMClassifier(**model_params)\n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            eval_metric='binary_logloss',\n",
        "            early_stopping_rounds=100,\n",
        "            feature_name=feature_name,\n",
        "            categorical_feature=categorical_feature,\n",
        "            verbose=False\n",
        "        )\n",
        "        val_preds = model.predict_proba(X_val)[:, 1]\n",
        "        oof_preds.update(dict(zip(val_idx, val_preds)))\n",
        "        \n",
        "        test_preds[f'fold{fold}'] = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        score = log_loss(y_val, val_preds)\n",
        "        scores.append(score)\n",
        "        if verbose:\n",
        "            print(f'Fold #{fold}: ({model.best_iteration_} rounds) Logloss = {score:.6f}')\n",
        "        \n",
        "        _ = gc.collect()\n",
        "\n",
        "    print(f'\\nAvg Logloss = {np.mean(scores):.6f} +/- {np.std(scores):.6f}')\n",
        "    \n",
        "    oof_preds = pd.Series(oof_preds).sort_index()\n",
        "    test_preds = pd.DataFrame.from_dict(test_preds)\n",
        "    test_preds['mean'] = test_preds.mean(axis=1)\n",
        "\n",
        "    return oof_preds, test_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "I0TOKMzxhRt-"
      },
      "outputs": [],
      "source": [
        "def run_experiment(data, n_trials=5):\n",
        "        \n",
        "    X, y, X_test = data\n",
        "    \n",
        "    base_params = {\n",
        "        'objective': 'binary',\n",
        "        'n_estimators': 10000,\n",
        "        'boosting_type': 'goss',\n",
        "        'extra_trees': True,\n",
        "        'verbosity': -1,\n",
        "        'device_type': 'cpu',\n",
        "        'random_state': SEED\n",
        "    }\n",
        "    \n",
        "    print(f'---------------Hyperparameter tuning---------------')\n",
        "    study = tune_params(\n",
        "        data=(X, y), \n",
        "        base_params=base_params,\n",
        "        n_trials=n_trials,\n",
        "        direction='minimize' #logloss -> lower is better\n",
        "    )\n",
        "    print(f'Best trial: {study.best_trial.number} -> Best value(Logloss): {study.best_value:.5f}')\n",
        "    print(f'Best hyperparameters:')\n",
        "    for k, v in study.best_params.items():\n",
        "        print(f'{k:20} - {v}')\n",
        "    \n",
        "    model_params = {**base_params, **study.best_params}\n",
        "    print(f'-----------------Cross-validation------------------')\n",
        "    oof_preds, test_preds = evaluate_model(\n",
        "        data=data, \n",
        "        model_params=model_params\n",
        "    )\n",
        "    return oof_preds, test_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trial run"
      ],
      "metadata": {
        "id": "mYCj8JFXHgoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
        "op, tp = run_experiment(\n",
        "    data=(train_full[original_features], train_full[TARGET], test[original_features]),\n",
        "    n_trials=3\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMBeUzM5HkAW",
        "outputId": "b41d5fbe-d85a-46f0-d7a0-f52d7e18fac9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-06 10:49:47,312]\u001b[0m A new study created in memory with name: no-name-e6e4953a-433b-4715-a91e-c703b7099dbb\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Hyperparameter tuning---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-06 10:49:53,028]\u001b[0m Trial 0 finished with value: 0.6812176390865174 and parameters: {'learning_rate': 0.16, 'reg_alpha': 189.4, 'reg_lambda': 153.1, 'num_leaves': 295, 'min_child_samples': 110, 'min_split_gain': 10.3, 'colsample_bytree': 0.55, 'top_rate': 0.25, 'other_rate': 0.35000000000000003, 'scale_pos_weight': 1.05}. Best is trial 0 with value: 0.6812176390865174.\u001b[0m\n",
            "\u001b[32m[I 2022-11-06 10:49:56,736]\u001b[0m Trial 1 finished with value: 0.6811322019561752 and parameters: {'learning_rate': 0.01, 'reg_alpha': 176.8, 'reg_lambda': 177.0, 'num_leaves': 315, 'min_child_samples': 294, 'min_split_gain': 14.68, 'colsample_bytree': 0.9, 'top_rate': 0.1, 'other_rate': 0.15000000000000002, 'scale_pos_weight': 0.95}. Best is trial 1 with value: 0.6811322019561752.\u001b[0m\n",
            "\u001b[32m[I 2022-11-06 10:50:01,791]\u001b[0m Trial 2 finished with value: 0.6811442185514551 and parameters: {'learning_rate': 0.25, 'reg_alpha': 125.2, 'reg_lambda': 22.1, 'num_leaves': 20, 'min_child_samples': 472, 'min_split_gain': 2.12, 'colsample_bytree': 0.7, 'top_rate': 0.25, 'other_rate': 0.45, 'scale_pos_weight': 1.05}. Best is trial 1 with value: 0.6811322019561752.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: 1 -> Best value(Logloss): 0.68113\n",
            "Best hyperparameters:\n",
            "learning_rate        - 0.01\n",
            "reg_alpha            - 176.8\n",
            "reg_lambda           - 177.0\n",
            "num_leaves           - 315\n",
            "min_child_samples    - 294\n",
            "min_split_gain       - 14.68\n",
            "colsample_bytree     - 0.9\n",
            "top_rate             - 0.1\n",
            "other_rate           - 0.15000000000000002\n",
            "scale_pos_weight     - 0.95\n",
            "-----------------Cross-validation------------------\n",
            "Fold #0: (1 rounds) Logloss = 0.681123\n",
            "Fold #1: (1 rounds) Logloss = 0.681123\n",
            "Fold #2: (1 rounds) Logloss = 0.681138\n",
            "Fold #3: (1 rounds) Logloss = 0.681138\n",
            "Fold #4: (1 rounds) Logloss = 0.681138\n",
            "\n",
            "Avg Logloss = 0.681132 +/- 0.000007\n",
            "CPU times: user 34.5 s, sys: 162 ms, total: 34.7 s\n",
            "Wall time: 19 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.logging.set_verbosity(optuna.logging.ERROR)"
      ],
      "metadata": {
        "id": "FaWBqUuHK6QN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op1, tp1 = run_experiment(\n",
        "    data=(train_full[original_features], train_full[TARGET], test[original_features]),\n",
        "    n_trials=100\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVXmcQmfMFws",
        "outputId": "b1852df6-79de-40d4-aa78-cb21a4f29b82"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Hyperparameter tuning---------------\n",
            "Best trial: 73 -> Best value(Logloss): 0.68094\n",
            "Best hyperparameters:\n",
            "learning_rate        - 0.19\n",
            "reg_alpha            - 22.5\n",
            "reg_lambda           - 151.9\n",
            "num_leaves           - 215\n",
            "min_child_samples    - 354\n",
            "min_split_gain       - 1.35\n",
            "colsample_bytree     - 0.5\n",
            "top_rate             - 0.25\n",
            "other_rate           - 0.15000000000000002\n",
            "scale_pos_weight     - 1.0\n",
            "-----------------Cross-validation------------------\n",
            "Fold #0: (17 rounds) Logloss = 0.680838\n",
            "Fold #1: (25 rounds) Logloss = 0.680912\n",
            "Fold #2: (9 rounds) Logloss = 0.681052\n",
            "Fold #3: (14 rounds) Logloss = 0.680839\n",
            "Fold #4: (5 rounds) Logloss = 0.681071\n",
            "\n",
            "Avg Logloss = 0.680942 +/- 0.000101\n",
            "CPU times: user 24min 22s, sys: 5.28 s, total: 24min 27s\n",
            "Wall time: 12min 52s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op2, tp2 = run_experiment(\n",
        "    data=(train_clip[original_features], train_clip[TARGET], test[original_features]),\n",
        "    n_trials=100\n",
        ")"
      ],
      "metadata": {
        "id": "UnyM2deiMuFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "324429d1-43d9-4c66-94e7-1836dce036a2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Hyperparameter tuning---------------\n",
            "Best trial: 99 -> Best value(Logloss): 0.68091\n",
            "Best hyperparameters:\n",
            "learning_rate        - 0.17\n",
            "reg_alpha            - 11.9\n",
            "reg_lambda           - 181.8\n",
            "num_leaves           - 905\n",
            "min_child_samples    - 62\n",
            "min_split_gain       - 1.08\n",
            "colsample_bytree     - 0.7\n",
            "top_rate             - 0.35\n",
            "other_rate           - 0.1\n",
            "scale_pos_weight     - 1.0\n",
            "-----------------Cross-validation------------------\n",
            "Fold #0: (2 rounds) Logloss = 0.681083\n",
            "Fold #1: (10 rounds) Logloss = 0.680983\n",
            "Fold #2: (9 rounds) Logloss = 0.680846\n",
            "Fold #3: (11 rounds) Logloss = 0.680812\n",
            "Fold #4: (8 rounds) Logloss = 0.680822\n",
            "\n",
            "Avg Logloss = 0.680909 +/- 0.000106\n",
            "CPU times: user 20min 45s, sys: 4.64 s, total: 20min 50s\n",
            "Wall time: 10min 58s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op3, tp3 = run_experiment(\n",
        "    data=(train_full[cat_only_features], train_full[TARGET], test[cat_only_features]),\n",
        "    n_trials=100\n",
        ")"
      ],
      "metadata": {
        "id": "9gy6vhfVM1va",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb0e886a-3f00-419f-a49a-01551f8086c0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Hyperparameter tuning---------------\n",
            "Best trial: 84 -> Best value(Logloss): 0.68093\n",
            "Best hyperparameters:\n",
            "learning_rate        - 0.29000000000000004\n",
            "reg_alpha            - 106.80000000000001\n",
            "reg_lambda           - 186.4\n",
            "num_leaves           - 865\n",
            "min_child_samples    - 114\n",
            "min_split_gain       - 0.29\n",
            "colsample_bytree     - 0.5\n",
            "top_rate             - 0.45000000000000007\n",
            "other_rate           - 0.1\n",
            "scale_pos_weight     - 1.0\n",
            "-----------------Cross-validation------------------\n",
            "Fold #0: (139 rounds) Logloss = 0.680711\n",
            "Fold #1: (5 rounds) Logloss = 0.681043\n",
            "Fold #2: (11 rounds) Logloss = 0.681062\n",
            "Fold #3: (36 rounds) Logloss = 0.680827\n",
            "Fold #4: (11 rounds) Logloss = 0.681002\n",
            "\n",
            "Avg Logloss = 0.680929 +/- 0.000137\n",
            "CPU times: user 23min 7s, sys: 4.09 s, total: 23min 12s\n",
            "Wall time: 12min 9s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op4, tp4 = run_experiment(\n",
        "    data=(train_clip[cat_only_features], train_clip[TARGET], test[cat_only_features]),\n",
        "    n_trials=100\n",
        ")"
      ],
      "metadata": {
        "id": "tDX6qWpiM1vb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61dccc0-3586-4ca3-d035-feb229c72c32"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Hyperparameter tuning---------------\n",
            "Best trial: 32 -> Best value(Logloss): 0.68092\n",
            "Best hyperparameters:\n",
            "learning_rate        - 0.28\n",
            "reg_alpha            - 49.800000000000004\n",
            "reg_lambda           - 11.8\n",
            "num_leaves           - 750\n",
            "min_child_samples    - 288\n",
            "min_split_gain       - 2.94\n",
            "colsample_bytree     - 0.5\n",
            "top_rate             - 0.25\n",
            "other_rate           - 0.1\n",
            "scale_pos_weight     - 1.0\n",
            "-----------------Cross-validation------------------\n",
            "Fold #0: (7 rounds) Logloss = 0.680989\n",
            "Fold #1: (3 rounds) Logloss = 0.681026\n",
            "Fold #2: (8 rounds) Logloss = 0.680899\n",
            "Fold #3: (10 rounds) Logloss = 0.680794\n",
            "Fold #4: (8 rounds) Logloss = 0.680916\n",
            "\n",
            "Avg Logloss = 0.680925 +/- 0.000080\n",
            "CPU times: user 20min 13s, sys: 3.74 s, total: 20min 17s\n",
            "Wall time: 10min 39s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op5, tp5 = run_experiment(\n",
        "    data=(train_full[mi_features], train_full[TARGET], test[mi_features]),\n",
        "    n_trials=100\n",
        ")"
      ],
      "metadata": {
        "id": "IuPyrO84Nfwc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "289795e5-e578-4047-debf-8d19db786719"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Hyperparameter tuning---------------\n",
            "Best trial: 76 -> Best value(Logloss): 0.68096\n",
            "Best hyperparameters:\n",
            "learning_rate        - 0.12\n",
            "reg_alpha            - 21.1\n",
            "reg_lambda           - 99.80000000000001\n",
            "num_leaves           - 290\n",
            "min_child_samples    - 290\n",
            "min_split_gain       - 0.78\n",
            "colsample_bytree     - 0.75\n",
            "top_rate             - 0.30000000000000004\n",
            "other_rate           - 0.3\n",
            "scale_pos_weight     - 1.0\n",
            "-----------------Cross-validation------------------\n",
            "Fold #0: (33 rounds) Logloss = 0.680832\n",
            "Fold #1: (4 rounds) Logloss = 0.681023\n",
            "Fold #2: (20 rounds) Logloss = 0.680963\n",
            "Fold #3: (16 rounds) Logloss = 0.680899\n",
            "Fold #4: (6 rounds) Logloss = 0.681087\n",
            "\n",
            "Avg Logloss = 0.680961 +/- 0.000090\n",
            "CPU times: user 20min 56s, sys: 4.92 s, total: 21min 1s\n",
            "Wall time: 11min 5s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op6, tp6 = run_experiment(\n",
        "    data=(train_clip[mi_features], train_clip[TARGET], test[mi_features]),\n",
        "    n_trials=100\n",
        ")"
      ],
      "metadata": {
        "id": "iPc-FJw9Nfwd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45593f59-4273-4dd1-c326-d459012f8c0d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Hyperparameter tuning---------------\n",
            "Best trial: 91 -> Best value(Logloss): 0.68094\n",
            "Best hyperparameters:\n",
            "learning_rate        - 0.26\n",
            "reg_alpha            - 52.5\n",
            "reg_lambda           - 10.5\n",
            "num_leaves           - 785\n",
            "min_child_samples    - 380\n",
            "min_split_gain       - 1.1\n",
            "colsample_bytree     - 0.7\n",
            "top_rate             - 0.15000000000000002\n",
            "other_rate           - 0.35000000000000003\n",
            "scale_pos_weight     - 1.0\n",
            "-----------------Cross-validation------------------\n",
            "Fold #0: (1 rounds) Logloss = 0.681060\n",
            "Fold #1: (7 rounds) Logloss = 0.680914\n",
            "Fold #2: (10 rounds) Logloss = 0.680976\n",
            "Fold #3: (10 rounds) Logloss = 0.680803\n",
            "Fold #4: (25 rounds) Logloss = 0.680953\n",
            "\n",
            "Avg Logloss = 0.680941 +/- 0.000084\n",
            "CPU times: user 20min 55s, sys: 4.83 s, total: 21min\n",
            "Wall time: 11min 1s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op7, tp7 = run_experiment(\n",
        "    data=(train_full[reduced_features], train_full[TARGET], test[reduced_features]),\n",
        "    n_trials=100\n",
        ")"
      ],
      "metadata": {
        "id": "4bzkBKJDNoAN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52783fef-6699-466b-b5b0-d13fbfca7d42"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Hyperparameter tuning---------------\n",
            "Best trial: 71 -> Best value(Logloss): 0.68101\n",
            "Best hyperparameters:\n",
            "learning_rate        - 0.15000000000000002\n",
            "reg_alpha            - 21.200000000000003\n",
            "reg_lambda           - 81.5\n",
            "num_leaves           - 175\n",
            "min_child_samples    - 250\n",
            "min_split_gain       - 0.5700000000000001\n",
            "colsample_bytree     - 0.6\n",
            "top_rate             - 0.15000000000000002\n",
            "other_rate           - 0.5\n",
            "scale_pos_weight     - 1.0\n",
            "-----------------Cross-validation------------------\n",
            "Fold #0: (29 rounds) Logloss = 0.680903\n",
            "Fold #1: (11 rounds) Logloss = 0.680983\n",
            "Fold #2: (4 rounds) Logloss = 0.681126\n",
            "Fold #3: (22 rounds) Logloss = 0.680950\n",
            "Fold #4: (26 rounds) Logloss = 0.681096\n",
            "\n",
            "Avg Logloss = 0.681012 +/- 0.000086\n",
            "CPU times: user 14min 17s, sys: 2.74 s, total: 14min 20s\n",
            "Wall time: 7min 33s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op8, tp8 = run_experiment(\n",
        "    data=(train_clip[reduced_features], train_clip[TARGET], test[reduced_features]),\n",
        "    n_trials=100\n",
        ")"
      ],
      "metadata": {
        "id": "CDaq7QVANoAO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea6d8214-4430-4869-b712-f7ce47b78414"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Hyperparameter tuning---------------\n",
            "Best trial: 61 -> Best value(Logloss): 0.68098\n",
            "Best hyperparameters:\n",
            "learning_rate        - 0.26\n",
            "reg_alpha            - 34.9\n",
            "reg_lambda           - 160.0\n",
            "num_leaves           - 895\n",
            "min_child_samples    - 284\n",
            "min_split_gain       - 0.28\n",
            "colsample_bytree     - 0.95\n",
            "top_rate             - 0.35\n",
            "other_rate           - 0.3\n",
            "scale_pos_weight     - 1.0\n",
            "-----------------Cross-validation------------------\n",
            "Fold #0: (2 rounds) Logloss = 0.681091\n",
            "Fold #1: (9 rounds) Logloss = 0.680977\n",
            "Fold #2: (6 rounds) Logloss = 0.681004\n",
            "Fold #3: (54 rounds) Logloss = 0.680891\n",
            "Fold #4: (8 rounds) Logloss = 0.680950\n",
            "\n",
            "Avg Logloss = 0.680983 +/- 0.000066\n",
            "CPU times: user 12min 1s, sys: 2.42 s, total: 12min 4s\n",
            "Wall time: 6min 22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating submission files"
      ],
      "metadata": {
        "id": "77yayiraLXYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Y_o0kubsb5bP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ac4215-677f-430c-a2d8-9f82411686d7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NOTEBOOK = '04'\n",
        "SUBMISSION_PATH = f'/content/drive/MyDrive/data_science_competitions/machinehack/analytics_olympiad22/submissions/nb_{NOTEBOOK}'\n",
        "if not os.path.isdir(SUBMISSION_PATH):\n",
        "    os.makedirs(SUBMISSION_PATH)"
      ],
      "metadata": {
        "id": "NO44h9WwLaf4"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_submission_files(test_preds: pd.DataFrame, expt_num: int):\n",
        "    for col in (test_preds.columns):\n",
        "        sub = sample_sub.copy()\n",
        "        sub[TARGET] = test_preds[col]\n",
        "        sub.to_csv(f'{SUBMISSION_PATH}/{expt_num}_{col}.csv', index=False)"
      ],
      "metadata": {
        "id": "SjlGeP1bLuw5"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_submission_files(tp1, '01')\n",
        "create_submission_files(tp2, '02')\n",
        "create_submission_files(tp3, '03')\n",
        "create_submission_files(tp4, '04')\n",
        "create_submission_files(tp5, '05')\n",
        "create_submission_files(tp6, '06')\n",
        "create_submission_files(tp7, '07')\n",
        "create_submission_files(tp8, '08')"
      ],
      "metadata": {
        "id": "BlCRKnAFg7Fp"
      },
      "execution_count": 37,
      "outputs": []
    }
  ]
}