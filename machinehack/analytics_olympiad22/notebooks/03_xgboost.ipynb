{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYpZcAjotdHsqkesSIDKXE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stiwari-ds/data-science-competitions/blob/main/machinehack/analytics_olympiad22/notebooks/03_xgboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "fMe_ffy2a_ac"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wyde65PCala3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade xgboost\n",
        "!pip install --upgrade optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import time\n",
        "import warnings\n",
        "import subprocess\n",
        "\n",
        "gc.enable()\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import xgboost\n",
        "import optuna\n",
        "\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.pruners import HyperbandPruner\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "SEED = 23\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "eKfBaXpBbBUQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove cell to run future versions\n",
        "assert optuna.__version__ == '3.0.3', f'Change in Optuna version. Original notebook version: 3.0.3'\n",
        "assert xgboost.__version__ == '1.6.2', f'Change in XGBoost version. Original notebook version: 1.6.2'"
      ],
      "metadata": {
        "id": "QU6c1orQbm3A"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check GPU availability\n",
        "try:\n",
        "    subprocess.check_output('nvidia-smi')\n",
        "    HAVE_GPU = True\n",
        "except Exception:\n",
        "    HAVE_GPU = False\n",
        "\n",
        "print(f'GPU available: {HAVE_GPU}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBzLRr5pbr7Z",
        "outputId": "eddd5105-5ee1-4308-b14c-2b9ea5de17f4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "ZR_l09PCSu-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_URL = 'https://raw.githubusercontent.com/stiwari-ds/data-science-competitions/main/machinehack/analytics_olympiad22/data'\n",
        "\n",
        "train_full = pd.read_csv(f'{DATA_URL}/processed/train_proc.csv')\n",
        "train_clip = pd.read_csv(f'{DATA_URL}/processed/train_clip.csv')\n",
        "test = pd.read_csv(f'{DATA_URL}/processed/test_proc.csv')\n",
        "sample_sub = pd.read_csv(f'{DATA_URL}/raw/submission.csv')"
      ],
      "metadata": {
        "id": "ZHFqgGFSaMM5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET = 'OUTCOME'"
      ],
      "metadata": {
        "id": "DgmNSET-IB49"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = [f for f in test.columns \n",
        "            if f not in ('ID', 'POSTAL_CODE', 'ANNUAL_MILEAGE')]\n",
        "\n",
        "num_features = ['ID_COUNT', 'CREDIT_SCORE', 'ANNUAL_MILEAGE_K', 'DUIS', \n",
        "                'SPEEDING_VIOLATIONS', 'PAST_ACCIDENTS', 'TOTAL_PAST_INCIDENTS']\n",
        "\n",
        "cat_features = [f for f in features if f not in num_features]"
      ],
      "metadata": {
        "id": "yKL2IhrA2VnM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_full[cat_features] = train_full[cat_features].astype('category')\n",
        "train_clip[cat_features] = train_clip[cat_features].astype('category')\n",
        "test[cat_features] = test[cat_features].astype('category')"
      ],
      "metadata": {
        "id": "ijTShF4Q2wKN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_features = ['AGE', 'GENDER', 'DRIVING_EXPERIENCE', 'EDUCATION', 'INCOME', \n",
        "                     'CREDIT_SCORE', 'VEHICLE_OWNERSHIP', 'VEHICLE_YEAR', 'MARRIED', \n",
        "                     'CHILDREN', 'POSTAL_CODE_SUBREGION', 'ANNUAL_MILEAGE_K', \n",
        "                     'SPEEDING_VIOLATIONS', 'DUIS', 'PAST_ACCIDENTS', 'TYPE_OF_VEHICLE']\n",
        "\n",
        "cat_only_features = ['AGE', 'GENDER', 'DRIVING_EXPERIENCE', 'EDUCATION', 'INCOME', \n",
        "                     'VEHICLE_OWNERSHIP', 'VEHICLE_YEAR', 'MARRIED', 'CHILDREN', \n",
        "                     'TYPE_OF_VEHICLE', 'IS_ID_REPEATED', 'CREDIT_SCORE_BINS', \n",
        "                     'POSTAL_CODE_REGION', 'ANNUAL_MILEAGE_RANGE', 'HAS_PRIOR_DUIS', \n",
        "                     'HAS_PRIOR_SPEEDING_VIOLATIONS', 'HAS_PAST_ACCIDENTS',\n",
        "                     'HAS_PAST_INCIDENTS']\n",
        "\n",
        "#based on F-test and Chi2-test\n",
        "reduced_features = ['GENDER', 'DRIVING_EXPERIENCE', 'POSTAL_CODE_SUBREGION']\n",
        "\n",
        "#based on mutual information score\n",
        "mi_features = ['AGE', 'GENDER', 'DRIVING_EXPERIENCE', 'EDUCATION', 'INCOME', \n",
        "               'VEHICLE_OWNERSHIP', 'VEHICLE_YEAR', 'MARRIED', 'CHILDREN', \n",
        "               'TYPE_OF_VEHICLE', 'ID_COUNT', 'CREDIT_SCORE_BINS', 'POSTAL_CODE_REGION', \n",
        "               'POSTAL_CODE_SUBREGION', 'ANNUAL_MILEAGE_RANGE', 'TOTAL_PAST_INCIDENTS', \n",
        "               'HAS_PAST_INCIDENTS']"
      ],
      "metadata": {
        "id": "gTmm9UDA5qPb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline"
      ],
      "metadata": {
        "id": "l-ZLgtRMrJDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "scores = []\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "X, y = train_full[original_features], train_full[TARGET]\n",
        "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
        "    X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n",
        "    X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n",
        "\n",
        "    model = XGBClassifier(\n",
        "        objective='binary:logistic',\n",
        "        tree_method='gpu_hist' if HAVE_GPU else 'hist',\n",
        "        enable_categorical=HAVE_GPU,\n",
        "        eval_metric='logloss',\n",
        "        early_stopping_rounds=50, \n",
        "        seed=SEED\n",
        "    ) \n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        verbose=0\n",
        "    )\n",
        "    val_preds = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "    score = log_loss(y_val, val_preds)\n",
        "    scores.append(score)\n",
        "    print(f'Fold #{fold}: ({model.best_iteration} rounds) Logloss = {score:.6f}')\n",
        "    _ = gc.collect()\n",
        "\n",
        "print(f'\\nAvg Logloss = {np.mean(scores):.6f} +/- {np.std(scores):.6f}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccFthHeorwUe",
        "outputId": "76b38e34-31cd-468e-f2f7-62f19caf25cb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #0: (4 rounds) Logloss = 0.682039\n",
            "Fold #1: (4 rounds) Logloss = 0.682480\n",
            "Fold #2: (9 rounds) Logloss = 0.682147\n",
            "Fold #3: (4 rounds) Logloss = 0.682025\n",
            "Fold #4: (5 rounds) Logloss = 0.682392\n",
            "\n",
            "Avg Logloss = 0.682217 +/- 0.000186\n",
            "\n",
            "CPU times: user 3.91 s, sys: 58.9 ms, total: 3.97 s\n",
            "Wall time: 3.44 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVZEqwhQ2oi2"
      },
      "source": [
        "# Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "i3VeEFRe2oBe"
      },
      "outputs": [],
      "source": [
        "def objective(trial, data, base_params):\n",
        "\n",
        "    scores = []\n",
        "    X, y = data\n",
        "\n",
        "    param_grid = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, step=0.01),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 2, 20),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 20, step=0.1), #complexity-control\n",
        "        'alpha': trial.suggest_float('alpha', 0, 5, step=0.05), #L1-reg\n",
        "        'lambda': trial.suggest_float('lambda', 1e-3, 1e5, log=True), #L2-reg\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0, step=0.05),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0, step=0.05),\n",
        "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1.0, step=0.05),\n",
        "        'colsample_bynode': trial.suggest_float('colsample_bynode', 0.5, 1.0, step=0.05),\n",
        "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 0.75, 1.5, step=0.05)\n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
        "        X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n",
        "        X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n",
        "        \n",
        "        model = XGBClassifier(**base_params, **param_grid)\n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            verbose=0\n",
        "        )\n",
        "        val_preds = model.predict_proba(X_val)[:, 1]\n",
        "        scores.append(log_loss(y_val, val_preds))\n",
        "\n",
        "    return np.mean(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7JCjxMSuT3Ep"
      },
      "outputs": [],
      "source": [
        "def tune_params(data, base_params, n_trials=10, direction='maximize'):\n",
        "    study = optuna.create_study(\n",
        "        sampler=TPESampler(seed=SEED),\n",
        "        pruner=HyperbandPruner(),\n",
        "        direction=direction\n",
        "    )\n",
        "    \n",
        "    study.optimize(\n",
        "        func=lambda trial: objective(trial, data, base_params),\n",
        "        n_trials=n_trials,\n",
        "        gc_after_trial=True\n",
        "    )\n",
        "    \n",
        "    return study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-89LWIEHeTr"
      },
      "source": [
        "# Cross-validation and experiment setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OsTtaJBBYryk"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(data, model_params, verbose=True):\n",
        "    oof_preds = {}  #out-of-fold predictions on train set\n",
        "    test_preds = {} #predictions on test set for each fold\n",
        "    scores = [] #F1 scores on validation set\n",
        "\n",
        "    X, y, X_test = data\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
        "        X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n",
        "        X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n",
        "        \n",
        "        model = XGBClassifier(**model_params)\n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            verbose=0\n",
        "        )\n",
        "        val_preds = model.predict_proba(X_val)[:, 1]\n",
        "        oof_preds.update(dict(zip(val_idx, val_preds)))\n",
        "        \n",
        "        test_preds[f'fold{fold}'] = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        score = log_loss(y_val, val_preds)\n",
        "        scores.append(score)\n",
        "        if verbose:\n",
        "            print(f'Fold #{fold}: ({model.best_iteration} rounds) Logloss = {score:.6f}')\n",
        "        \n",
        "        _ = gc.collect()\n",
        "\n",
        "    print(f'\\nAvg Logloss = {np.mean(scores):.6f} +/- {np.std(scores):.6f}')\n",
        "    \n",
        "    oof_preds = pd.Series(oof_preds).sort_index()\n",
        "    test_preds = pd.DataFrame.from_dict(test_preds)\n",
        "    test_preds['mean'] = test_preds.mean(axis=1)\n",
        "\n",
        "    return oof_preds, test_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "I0TOKMzxhRt-"
      },
      "outputs": [],
      "source": [
        "def run_experiment(data, n_trials=5):\n",
        "        \n",
        "    X, y, X_test = data\n",
        "    \n",
        "    base_params = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'n_estimators': 10000,\n",
        "        'booster': 'gbtree',\n",
        "        'eval_metric': 'logloss',\n",
        "        'early_stopping_rounds': 100,\n",
        "        'tree_method': 'gpu_hist' if HAVE_GPU else 'hist',\n",
        "        'predictor': 'gpu_predictor' if HAVE_GPU else 'cpu_predictor',\n",
        "        'enable_categorical': HAVE_GPU,\n",
        "        'verbosity': 1,\n",
        "        'seed': SEED\n",
        "    }\n",
        "    \n",
        "    print(f'---------------Hyperparameter tuning---------------')\n",
        "    study = tune_params(\n",
        "        data=(X, y), \n",
        "        base_params=base_params,\n",
        "        n_trials=n_trials,\n",
        "        direction='minimize' #logloss -> lower is better\n",
        "    )\n",
        "    print(f'Best trial: {study.best_trial.number} -> Best value(Logloss): {study.best_value:.5f}')\n",
        "    print(f'Best hyperparameters:')\n",
        "    for k, v in study.best_params.items():\n",
        "        print(f'{k:20} - {v}')\n",
        "    \n",
        "    model_params = {**base_params, **study.best_params}\n",
        "    print(f'-----------------Cross-validation------------------')\n",
        "    oof_preds, test_preds = evaluate_model(\n",
        "        data=data, \n",
        "        model_params=model_params\n",
        "    )\n",
        "    return oof_preds, test_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trial run"
      ],
      "metadata": {
        "id": "mYCj8JFXHgoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
        "op, tp = run_experiment(\n",
        "    data=(train_full[original_features], train_full[TARGET], test[original_features]),\n",
        "    n_trials=3\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMBeUzM5HkAW",
        "outputId": "c984bf0b-358e-4e7f-ab78-f21b53eb4c7e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-06 10:37:21,873]\u001b[0m A new study created in memory with name: no-name-fc28b95b-67d9-48b8-880a-ace8d2402ab2\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Hyperparameter tuning---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-06 10:37:23,433]\u001b[0m Trial 0 finished with value: 0.6811924729296139 and parameters: {'learning_rate': 0.16, 'max_depth': 12, 'min_child_weight': 16, 'gamma': 5.6000000000000005, 'alpha': 1.1, 'lambda': 308.87067834937415, 'subsample': 0.55, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.8, 'colsample_bynode': 0.7, 'scale_pos_weight': 0.75}. Best is trial 0 with value: 0.6811924729296139.\u001b[0m\n",
            "\u001b[32m[I 2022-11-06 10:37:25,786]\u001b[0m Trial 1 finished with value: 0.6869966374908174 and parameters: {'learning_rate': 0.27, 'max_depth': 11, 'min_child_weight': 7, 'gamma': 11.8, 'alpha': 4.9, 'lambda': 5764.3531133041315, 'subsample': 0.5, 'colsample_bytree': 0.65, 'colsample_bylevel': 0.65, 'colsample_bynode': 0.95, 'scale_pos_weight': 1.25}. Best is trial 0 with value: 0.6811924729296139.\u001b[0m\n",
            "\u001b[32m[I 2022-11-06 10:37:28,829]\u001b[0m Trial 2 finished with value: 0.6810671264211337 and parameters: {'learning_rate': 0.04, 'max_depth': 3, 'min_child_weight': 19, 'gamma': 2.8000000000000003, 'alpha': 2.1, 'lambda': 0.5914465750030369, 'subsample': 0.95, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.95, 'colsample_bynode': 0.8500000000000001, 'scale_pos_weight': 0.8}. Best is trial 2 with value: 0.6810671264211337.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: 2 -> Best value(Logloss): 0.68107\n",
            "Best hyperparameters:\n",
            "learning_rate        - 0.04\n",
            "max_depth            - 3\n",
            "min_child_weight     - 19\n",
            "gamma                - 2.8000000000000003\n",
            "alpha                - 2.1\n",
            "lambda               - 0.5914465750030369\n",
            "subsample            - 0.95\n",
            "colsample_bytree     - 0.7\n",
            "colsample_bylevel    - 0.95\n",
            "colsample_bynode     - 0.8500000000000001\n",
            "scale_pos_weight     - 0.8\n",
            "-----------------Cross-validation------------------\n",
            "Fold #0: (21 rounds) Logloss = 0.680976\n",
            "Fold #1: (21 rounds) Logloss = 0.681067\n",
            "Fold #2: (21 rounds) Logloss = 0.681134\n",
            "Fold #3: (21 rounds) Logloss = 0.681036\n",
            "Fold #4: (21 rounds) Logloss = 0.681122\n",
            "\n",
            "Avg Logloss = 0.681067 +/- 0.000058\n",
            "CPU times: user 12 s, sys: 320 ms, total: 12.3 s\n",
            "Wall time: 12.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.logging.set_verbosity(optuna.logging.ERROR)"
      ],
      "metadata": {
        "id": "FaWBqUuHK6QN"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op1, tp1 = run_experiment(\n",
        "    data=(train_full[original_features], train_full[TARGET], test[original_features]),\n",
        "    n_trials=100\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVXmcQmfMFws",
        "outputId": "9b4ead3c-d49b-4253-c8d6-e6b2a322e048"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Hyperparameter tuning---------------\n",
            "Best trial: 86 -> Best value(Logloss): 0.68099\n",
            "Best hyperparameters:\n",
            "learning_rate        - 0.27\n",
            "max_depth            - 11\n",
            "min_child_weight     - 17\n",
            "gamma                - 5.800000000000001\n",
            "alpha                - 1.1500000000000001\n",
            "lambda               - 246.70108756972104\n",
            "subsample            - 0.8\n",
            "colsample_bytree     - 0.8\n",
            "colsample_bylevel    - 0.75\n",
            "colsample_bynode     - 0.7\n",
            "scale_pos_weight     - 1.0\n",
            "-----------------Cross-validation------------------\n",
            "Fold #0: (40 rounds) Logloss = 0.680865\n",
            "Fold #1: (19 rounds) Logloss = 0.681009\n",
            "Fold #2: (11 rounds) Logloss = 0.681129\n",
            "Fold #3: (38 rounds) Logloss = 0.680885\n",
            "Fold #4: (11 rounds) Logloss = 0.681061\n",
            "\n",
            "Avg Logloss = 0.680990 +/- 0.000101\n",
            "CPU times: user 5min 6s, sys: 5.06 s, total: 5min 11s\n",
            "Wall time: 4min 17s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op2, tp2 = run_experiment(\n",
        "    data=(train_clip[original_features], train_clip[TARGET], test[original_features]),\n",
        "    n_trials=100\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnyM2deiMuFU",
        "outputId": "9a3b8517-3364-4049-bdf6-463e32dadfb4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Hyperparameter tuning---------------\n",
            "Best trial: 46 -> Best value(Logloss): 0.68101\n",
            "Best hyperparameters:\n",
            "learning_rate        - 0.09\n",
            "max_depth            - 6\n",
            "min_child_weight     - 11\n",
            "gamma                - 7.7\n",
            "alpha                - 1.6500000000000001\n",
            "lambda               - 243.9703669028142\n",
            "subsample            - 0.8500000000000001\n",
            "colsample_bytree     - 0.75\n",
            "colsample_bylevel    - 1.0\n",
            "colsample_bynode     - 0.8\n",
            "scale_pos_weight     - 1.0\n",
            "-----------------Cross-validation------------------\n",
            "Fold #0: (34 rounds) Logloss = 0.681067\n",
            "Fold #1: (39 rounds) Logloss = 0.681026\n",
            "Fold #2: (77 rounds) Logloss = 0.680982\n",
            "Fold #3: (133 rounds) Logloss = 0.680947\n",
            "Fold #4: (251 rounds) Logloss = 0.681004\n",
            "\n",
            "Avg Logloss = 0.681005 +/- 0.000040\n",
            "CPU times: user 4min 44s, sys: 4.51 s, total: 4min 49s\n",
            "Wall time: 3min 53s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op3, tp3 = run_experiment(\n",
        "    data=(train_full[cat_only_features], train_full[TARGET], test[cat_only_features]),\n",
        "    n_trials=100\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gy6vhfVM1va",
        "outputId": "c72ec366-33d1-4cee-fb06-77d9858772d2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Hyperparameter tuning---------------\n",
            "Best trial: 57 -> Best value(Logloss): 0.68092\n",
            "Best hyperparameters:\n",
            "learning_rate        - 0.2\n",
            "max_depth            - 11\n",
            "min_child_weight     - 18\n",
            "gamma                - 6.2\n",
            "alpha                - 0.45\n",
            "lambda               - 564.1280043879658\n",
            "subsample            - 0.55\n",
            "colsample_bytree     - 0.9\n",
            "colsample_bylevel    - 0.7\n",
            "colsample_bynode     - 1.0\n",
            "scale_pos_weight     - 1.0\n",
            "-----------------Cross-validation------------------\n",
            "Fold #0: (153 rounds) Logloss = 0.680748\n",
            "Fold #1: (39 rounds) Logloss = 0.681014\n",
            "Fold #2: (189 rounds) Logloss = 0.680956\n",
            "Fold #3: (72 rounds) Logloss = 0.680827\n",
            "Fold #4: (27 rounds) Logloss = 0.681057\n",
            "\n",
            "Avg Logloss = 0.680921 +/- 0.000116\n",
            "CPU times: user 4min 29s, sys: 4.08 s, total: 4min 33s\n",
            "Wall time: 3min 40s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op4, tp4 = run_experiment(\n",
        "    data=(train_clip[cat_only_features], train_clip[TARGET], test[cat_only_features]),\n",
        "    n_trials=100\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDX6qWpiM1vb",
        "outputId": "57c01614-a4ef-4892-d863-9b3a4ce9fcb6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Hyperparameter tuning---------------\n",
            "Best trial: 47 -> Best value(Logloss): 0.68098\n",
            "Best hyperparameters:\n",
            "learning_rate        - 0.18000000000000002\n",
            "max_depth            - 3\n",
            "min_child_weight     - 20\n",
            "gamma                - 3.2\n",
            "alpha                - 5.0\n",
            "lambda               - 0.020432133604794865\n",
            "subsample            - 0.8500000000000001\n",
            "colsample_bytree     - 0.6\n",
            "colsample_bylevel    - 0.9\n",
            "colsample_bynode     - 0.9\n",
            "scale_pos_weight     - 1.0\n",
            "-----------------Cross-validation------------------\n",
            "Fold #0: (20 rounds) Logloss = 0.681038\n",
            "Fold #1: (17 rounds) Logloss = 0.681063\n",
            "Fold #2: (77 rounds) Logloss = 0.680990\n",
            "Fold #3: (69 rounds) Logloss = 0.680801\n",
            "Fold #4: (75 rounds) Logloss = 0.680987\n",
            "\n",
            "Avg Logloss = 0.680976 +/- 0.000092\n",
            "CPU times: user 4min 13s, sys: 3.87 s, total: 4min 17s\n",
            "Wall time: 3min 25s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op5, tp5 = run_experiment(\n",
        "    data=(train_full[mi_features], train_full[TARGET], test[mi_features]),\n",
        "    n_trials=100\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuPyrO84Nfwc",
        "outputId": "a4e2294f-1ab6-4b98-d31c-f5683c30ad24"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Hyperparameter tuning---------------\n",
            "Best trial: 90 -> Best value(Logloss): 0.68104\n",
            "Best hyperparameters:\n",
            "learning_rate        - 0.03\n",
            "max_depth            - 9\n",
            "min_child_weight     - 19\n",
            "gamma                - 1.6\n",
            "alpha                - 1.85\n",
            "lambda               - 52.30229703346206\n",
            "subsample            - 0.7\n",
            "colsample_bytree     - 0.6\n",
            "colsample_bylevel    - 0.9\n",
            "colsample_bynode     - 0.95\n",
            "scale_pos_weight     - 0.9\n",
            "-----------------Cross-validation------------------\n",
            "Fold #0: (46 rounds) Logloss = 0.680985\n",
            "Fold #1: (47 rounds) Logloss = 0.681069\n",
            "Fold #2: (46 rounds) Logloss = 0.681037\n",
            "Fold #3: (47 rounds) Logloss = 0.681026\n",
            "Fold #4: (49 rounds) Logloss = 0.681098\n",
            "\n",
            "Avg Logloss = 0.681043 +/- 0.000039\n",
            "CPU times: user 5min 10s, sys: 3.96 s, total: 5min 14s\n",
            "Wall time: 4min 18s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op6, tp6 = run_experiment(\n",
        "    data=(train_clip[mi_features], train_clip[TARGET], test[mi_features]),\n",
        "    n_trials=100\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPc-FJw9Nfwd",
        "outputId": "cdb0fb70-98b8-4b52-bd90-62c93fbfe4ae"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Hyperparameter tuning---------------\n",
            "Best trial: 93 -> Best value(Logloss): 0.68096\n",
            "Best hyperparameters:\n",
            "learning_rate        - 0.17\n",
            "max_depth            - 8\n",
            "min_child_weight     - 7\n",
            "gamma                - 2.1\n",
            "alpha                - 3.8000000000000003\n",
            "lambda               - 3058.771815197645\n",
            "subsample            - 0.8\n",
            "colsample_bytree     - 0.5\n",
            "colsample_bylevel    - 0.55\n",
            "colsample_bynode     - 0.6\n",
            "scale_pos_weight     - 1.0\n",
            "-----------------Cross-validation------------------\n",
            "Fold #0: (132 rounds) Logloss = 0.680996\n",
            "Fold #1: (72 rounds) Logloss = 0.680967\n",
            "Fold #2: (53 rounds) Logloss = 0.680998\n",
            "Fold #3: (148 rounds) Logloss = 0.680879\n",
            "Fold #4: (221 rounds) Logloss = 0.680965\n",
            "\n",
            "Avg Logloss = 0.680961 +/- 0.000043\n",
            "CPU times: user 4min 54s, sys: 4.31 s, total: 4min 58s\n",
            "Wall time: 4min 2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op7, tp7 = run_experiment(\n",
        "    data=(train_full[reduced_features], train_full[TARGET], test[reduced_features]),\n",
        "    n_trials=100\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bzkBKJDNoAN",
        "outputId": "8a7865b2-cff8-4e97-8f3c-12fa680a0a32"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Hyperparameter tuning---------------\n",
            "Best trial: 50 -> Best value(Logloss): 0.68099\n",
            "Best hyperparameters:\n",
            "learning_rate        - 0.23\n",
            "max_depth            - 3\n",
            "min_child_weight     - 10\n",
            "gamma                - 0.0\n",
            "alpha                - 2.3000000000000003\n",
            "lambda               - 2811.8695592903473\n",
            "subsample            - 0.6\n",
            "colsample_bytree     - 0.75\n",
            "colsample_bylevel    - 0.9\n",
            "colsample_bynode     - 0.95\n",
            "scale_pos_weight     - 1.0\n",
            "-----------------Cross-validation------------------\n",
            "Fold #0: (117 rounds) Logloss = 0.680794\n",
            "Fold #1: (67 rounds) Logloss = 0.680988\n",
            "Fold #2: (16 rounds) Logloss = 0.681178\n",
            "Fold #3: (35 rounds) Logloss = 0.680940\n",
            "Fold #4: (22 rounds) Logloss = 0.681067\n",
            "\n",
            "Avg Logloss = 0.680993 +/- 0.000128\n",
            "CPU times: user 2min 56s, sys: 3.13 s, total: 2min 59s\n",
            "Wall time: 2min 30s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op8, tp8 = run_experiment(\n",
        "    data=(train_clip[reduced_features], train_clip[TARGET], test[reduced_features]),\n",
        "    n_trials=100\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDaq7QVANoAO",
        "outputId": "da8d6328-a09a-4dbb-cff3-9acc818ccf46"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Hyperparameter tuning---------------\n",
            "Best trial: 94 -> Best value(Logloss): 0.68097\n",
            "Best hyperparameters:\n",
            "learning_rate        - 0.29000000000000004\n",
            "max_depth            - 9\n",
            "min_child_weight     - 12\n",
            "gamma                - 5.2\n",
            "alpha                - 4.65\n",
            "lambda               - 8.255276200724126\n",
            "subsample            - 0.75\n",
            "colsample_bytree     - 0.55\n",
            "colsample_bylevel    - 0.9\n",
            "colsample_bynode     - 0.9\n",
            "scale_pos_weight     - 1.0\n",
            "-----------------Cross-validation------------------\n",
            "Fold #0: (16 rounds) Logloss = 0.681004\n",
            "Fold #1: (15 rounds) Logloss = 0.681000\n",
            "Fold #2: (26 rounds) Logloss = 0.680982\n",
            "Fold #3: (13 rounds) Logloss = 0.680919\n",
            "Fold #4: (11 rounds) Logloss = 0.680947\n",
            "\n",
            "Avg Logloss = 0.680970 +/- 0.000032\n",
            "CPU times: user 2min 31s, sys: 2.69 s, total: 2min 34s\n",
            "Wall time: 2min 5s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating submission files"
      ],
      "metadata": {
        "id": "77yayiraLXYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Y_o0kubsb5bP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b147d4c2-4af1-41e1-cedb-5c2b30bb79d9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NOTEBOOK = '03'\n",
        "SUBMISSION_PATH = f'/content/drive/MyDrive/data_science_competitions/machinehack/analytics_olympiad22/submissions/nb_{NOTEBOOK}'\n",
        "if not os.path.isdir(SUBMISSION_PATH):\n",
        "    os.makedirs(SUBMISSION_PATH)"
      ],
      "metadata": {
        "id": "NO44h9WwLaf4"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_submission_files(test_preds: pd.DataFrame, expt_num: int):\n",
        "    for col in (test_preds.columns):\n",
        "        sub = sample_sub.copy()\n",
        "        sub[TARGET] = test_preds[col]\n",
        "        sub.to_csv(f'{SUBMISSION_PATH}/{expt_num}_{col}.csv', index=False)"
      ],
      "metadata": {
        "id": "SjlGeP1bLuw5"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_submission_files(tp1, '01')\n",
        "create_submission_files(tp2, '02')\n",
        "create_submission_files(tp3, '03')\n",
        "create_submission_files(tp4, '04')\n",
        "create_submission_files(tp5, '05')\n",
        "create_submission_files(tp6, '06')\n",
        "create_submission_files(tp7, '07')\n",
        "create_submission_files(tp8, '08')"
      ],
      "metadata": {
        "id": "BlCRKnAFg7Fp"
      },
      "execution_count": 46,
      "outputs": []
    }
  ]
}