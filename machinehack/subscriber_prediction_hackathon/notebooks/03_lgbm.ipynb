{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOK9ObiCe0SKwkSxFE1JIAr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stiwari-ds/data-science-competitions/blob/main/machinehack/subscriber_prediction_hackathon/notebooks/03_lgbm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "fMe_ffy2a_ac"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wyde65PCala3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade optuna\n",
        "!pip install --upgrade lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "gc.enable()\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.precision', 4)\n",
        "np.set_printoptions(precision=4)\n",
        "\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.pruners import HyperbandPruner\n",
        "\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "SEED = 23\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "eKfBaXpBbBUQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove cell to run future versions\n",
        "assert optuna.__version__ == '3.0.3', f'Change in Optuna version. Original notebook version: 3.0.2'\n",
        "assert lgb.__version__ == '3.3.3', f'Change in LightGBM version. Original notebook version: 3.3.3'"
      ],
      "metadata": {
        "id": "QU6c1orQbm3A"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_URL = 'https://raw.githubusercontent.com/stiwari-ds/data-science-competitions/main/machinehack/subscriber_prediction_hackathon/data'\n",
        "\n",
        "train = pd.read_csv(f'{DATA_URL}/processed/train.csv') #processed dataset from notebook 00\n",
        "test = pd.read_csv(f'{DATA_URL}/processed/test.csv')\n",
        "sample_sub = pd.read_csv(f'{DATA_URL}/raw/submission.csv')"
      ],
      "metadata": {
        "id": "LOHMVhw1ZZS6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET = 'y_bool'"
      ],
      "metadata": {
        "id": "KEJQopfVZppB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(test.columns)\n",
        "num_features = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
        "cat_features = [f for f in features if f not in num_features]"
      ],
      "metadata": {
        "id": "3zTnF1bvZx-o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_features = ['age', 'job', 'marital', 'education', 'default', 'balance',\n",
        "                     'housing', 'loan', 'contact', 'day', 'month', 'duration', \n",
        "                     'campaign', 'pdays', 'previous', 'poutcome']\n",
        "\n",
        "cat_only_features = ['age_bins', 'job_groups', 'marital', 'education', 'default',\n",
        "                     'balance_bins', 'housing', 'loan', 'contact', 'day_bins', \n",
        "                     'month_bins', 'duration_bins', 'campaign_bins', 'pdays_bins',\n",
        "                     'pdays_bool', 'previous_bins', 'previous_bool', 'poutcome']"
      ],
      "metadata": {
        "id": "-12ZFzcHHLbV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline"
      ],
      "metadata": {
        "id": "uur7dQEjf6CY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "scores = []\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "X, y = train[features], train[TARGET]\n",
        "feature_name = list(X.columns)\n",
        "categorical_feature = [f for f in feature_name if f in cat_features]\n",
        "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
        "    X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n",
        "    X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n",
        "\n",
        "    model = LGBMClassifier(\n",
        "        objective='binary',\n",
        "        boosting_type='goss',\n",
        "        device_type='cpu',\n",
        "        random_state=SEED\n",
        "    ) \n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        early_stopping_rounds=100,\n",
        "        eval_metric='binary_logloss',\n",
        "        feature_name=feature_name,\n",
        "        categorical_feature=categorical_feature,\n",
        "        verbose=0\n",
        "    )\n",
        "    val_preds = model.predict_proba(X_val)[:, 1]\n",
        "    score = log_loss(y_val, val_preds)\n",
        "    scores.append(score)\n",
        "    print(f'Fold #{fold}: ({model.best_iteration_} rounds) Logloss = {score:.5f}')\n",
        "    _ = gc.collect()\n",
        "\n",
        "print(f'\\nAvg Logloss = {np.mean(scores):.5f} +/- {np.std(scores):.5f}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkFlWjOhf5Au",
        "outputId": "e0bb63bb-1491-4a52-fd7b-fb866ee815eb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #0: (9 rounds) Logloss = 0.58086\n",
            "Fold #1: (4 rounds) Logloss = 0.58116\n",
            "Fold #2: (10 rounds) Logloss = 0.57947\n",
            "Fold #3: (4 rounds) Logloss = 0.58144\n",
            "Fold #4: (7 rounds) Logloss = 0.57997\n",
            "\n",
            "Avg Logloss = 0.58058 +/- 0.00074\n",
            "\n",
            "CPU times: user 5.22 s, sys: 98.1 ms, total: 5.32 s\n",
            "Wall time: 3.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVZEqwhQ2oi2"
      },
      "source": [
        "# Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "i3VeEFRe2oBe"
      },
      "outputs": [],
      "source": [
        "def objective(trial, data, model):\n",
        "\n",
        "    scores = []\n",
        "    X, y = data\n",
        "\n",
        "    feature_name = list(X.columns)\n",
        "    categorical_feature = [f for f in feature_name if f in cat_features]\n",
        "\n",
        "    param_grid = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.025, 0.3, step=0.025),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 200, step=0.1),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 200, step=0.1),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 2000, step=5),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 13),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 0, 1000, step=2),\n",
        "        'min_split_gain': trial.suggest_float('min_split_gain', 0, 10, step=0.01),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.95, step=0.05),\n",
        "        'top_rate': trial.suggest_float('top_rate', 0.1, 0.5, step=0.05),\n",
        "        'other_rate': trial.suggest_float('other_rate', 0.05, 0.5, step=0.05),\n",
        "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1, 5, step=0.05),\n",
        "        'max_cat_to_onehot': trial.suggest_categorical('max_cat_to_onehot', [2, 5, 12])\n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
        "        X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n",
        "        X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n",
        "        \n",
        "        model.set_params(**param_grid)\n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            eval_metric='binary_logloss',\n",
        "            early_stopping_rounds=100,\n",
        "            feature_name=feature_name,\n",
        "            categorical_feature=categorical_feature,\n",
        "            verbose=False\n",
        "        )\n",
        "        val_preds = model.predict_proba(X_val)[:, 1]\n",
        "        scores.append(log_loss(y_val, val_preds))\n",
        "\n",
        "    return np.mean(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7JCjxMSuT3Ep"
      },
      "outputs": [],
      "source": [
        "def tune_params(data, model, n_trials, direction):\n",
        "    study = optuna.create_study(\n",
        "        sampler=TPESampler(seed=SEED),\n",
        "        pruner=HyperbandPruner(),\n",
        "        direction=direction\n",
        "    )\n",
        "    study.optimize(\n",
        "        func=lambda trial: objective(trial, data, model),\n",
        "        n_trials=n_trials,\n",
        "        gc_after_trial=True\n",
        "    )\n",
        "    return study"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross-validation"
      ],
      "metadata": {
        "id": "_IdnAvEkjxqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validate_predict(data, model, n_splits=5):\n",
        "    oof_preds = {}  #out-of-fold predictions on train set\n",
        "    test_preds = {} #predictions on test set for each fold\n",
        "    scores = [] #scores on validation set\n",
        "\n",
        "    X, y, X_test = data\n",
        "    feature_name = list(X.columns)\n",
        "    categorical_feature = [f for f in feature_name if f in cat_features]\n",
        "       \n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
        "        X_train, y_train = X.loc[train_idx], y.iloc[train_idx]\n",
        "        X_val, y_val = X.loc[val_idx], y.iloc[val_idx]\n",
        "        \n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            eval_metric='binary_logloss',\n",
        "            early_stopping_rounds=100,\n",
        "            feature_name=feature_name,\n",
        "            categorical_feature=categorical_feature,\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        val_preds = model.predict_proba(X_val)[:, 1]\n",
        "        test_preds[f'fold{fold}'] = model.predict_proba(X_test)[:, 1]\n",
        "        oof_preds.update(dict(zip(val_idx, val_preds)))\n",
        "\n",
        "        score = log_loss(y_val, val_preds)\n",
        "        scores.append(score)\n",
        "        print(f'Fold #{fold}: ({model.best_iteration_} rounds) Logloss = {score:.5f}')\n",
        "        _ = gc.collect()\n",
        "    print(f'Avg. Logloss = {np.mean(scores):.5f} +/- {np.std(scores):.5f}')\n",
        "    \n",
        "    oof_preds = pd.Series(oof_preds).sort_index()\n",
        "    test_preds = pd.DataFrame.from_dict(test_preds)\n",
        "    test_preds['mean'] = test_preds.mean(axis=1)\n",
        "\n",
        "    return oof_preds, test_preds"
      ],
      "metadata": {
        "id": "0UBSsqwvj0I2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(data, n_trials=10):\n",
        "    \n",
        "    X, y, X_test = data\n",
        "\n",
        "    base_params = {\n",
        "        'objective': 'binary',\n",
        "        'n_estimators': 10000,\n",
        "        'boosting_type': 'goss',\n",
        "        'extra_trees': True,\n",
        "        'verbosity': -1,\n",
        "        'device_type': 'cpu',\n",
        "        'random_state': SEED\n",
        "    }\n",
        "    \n",
        "    model = LGBMClassifier(**base_params)\n",
        "    \n",
        "    print(f'----------Hyperparameter tuning----------')\n",
        "    start = time.time()\n",
        "    study = tune_params(\n",
        "        data=(X, y),\n",
        "        model=model,\n",
        "        n_trials=n_trials, \n",
        "        direction='minimize' #metric: logloss -> lower is better\n",
        "    )\n",
        "    end = time.time()\n",
        "    print(f'Best trial: {study.best_trial.number} -> Best value: {study.best_value:.5f}')\n",
        "    print(f'Best hyperparameters:')\n",
        "    for k, v in study.best_params.items():\n",
        "        print(f'{k:15} - {v}')\n",
        "    print(f'[Time taken: {end - start:.2f}s]\\n')\n",
        "    \n",
        "    print(f'-----Cross-validation and prediction-----')\n",
        "    start = time.time()\n",
        "    model.set_params(**study.best_params)\n",
        "    oof_preds, test_preds = cross_validate_predict(data, model)\n",
        "    end = time.time()\n",
        "    print(f'[Time taken: {end - start:.2f}s]\\n')\n",
        "\n",
        "    return oof_preds, test_preds"
      ],
      "metadata": {
        "id": "KkMeqc7EkKx-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trial run**"
      ],
      "metadata": {
        "id": "Ri22_Ef0kzB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.logging.set_verbosity(optuna.logging.INFO)"
      ],
      "metadata": {
        "id": "1lWtr5SYk0yu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op, tp = run_experiment(\n",
        "    data=(train[features], train[TARGET], test[features]),\n",
        "    n_trials=3\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAPuSH6Jk4o8",
        "outputId": "acb734c6-e9e6-43c1-c89d-bb27099aa693"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-16 04:16:39,392]\u001b[0m A new study created in memory with name: no-name-9791dab7-709e-4439-b2e3-00e20b7c6a75\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------Hyperparameter tuning----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-16 04:16:40,698]\u001b[0m Trial 0 finished with value: 0.5823568784232547 and parameters: {'learning_rate': 0.17500000000000002, 'reg_alpha': 189.4, 'reg_lambda': 153.1, 'num_leaves': 580, 'max_depth': 5, 'min_child_samples': 686, 'min_split_gain': 1.67, 'colsample_bytree': 0.65, 'top_rate': 0.35, 'other_rate': 0.25, 'scale_pos_weight': 1.0, 'max_cat_to_onehot': 5}. Best is trial 0 with value: 0.5823568784232547.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 04:16:41,788]\u001b[0m Trial 1 finished with value: 0.5823568784232547 and parameters: {'learning_rate': 0.2, 'reg_alpha': 195.70000000000002, 'reg_lambda': 169.10000000000002, 'num_leaves': 145, 'max_depth': 6, 'min_child_samples': 288, 'min_split_gain': 8.23, 'colsample_bytree': 0.8, 'top_rate': 0.1, 'other_rate': 0.05, 'scale_pos_weight': 4.800000000000001, 'max_cat_to_onehot': 5}. Best is trial 0 with value: 0.5823568784232547.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 04:16:43,307]\u001b[0m Trial 2 finished with value: 0.5823568784232547 and parameters: {'learning_rate': 0.275, 'reg_alpha': 85.7, 'reg_lambda': 165.8, 'num_leaves': 1440, 'max_depth': 4, 'min_child_samples': 596, 'min_split_gain': 1.29, 'colsample_bytree': 0.5, 'top_rate': 0.45000000000000007, 'other_rate': 0.25, 'scale_pos_weight': 1.65, 'max_cat_to_onehot': 12}. Best is trial 0 with value: 0.5823568784232547.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: 0 -> Best value: 0.58236\n",
            "Best hyperparameters:\n",
            "learning_rate   - 0.17500000000000002\n",
            "reg_alpha       - 189.4\n",
            "reg_lambda      - 153.1\n",
            "num_leaves      - 580\n",
            "max_depth       - 5\n",
            "min_child_samples - 686\n",
            "min_split_gain  - 1.67\n",
            "colsample_bytree - 0.65\n",
            "top_rate        - 0.35\n",
            "other_rate      - 0.25\n",
            "scale_pos_weight - 1.0\n",
            "max_cat_to_onehot - 5\n",
            "[Time taken: 4.00s]\n",
            "\n",
            "-----Cross-validation and prediction-----\n",
            "Fold #0: (1 rounds) Logloss = 0.58231\n",
            "Fold #1: (1 rounds) Logloss = 0.58231\n",
            "Fold #2: (1 rounds) Logloss = 0.58231\n",
            "Fold #3: (1 rounds) Logloss = 0.58231\n",
            "Fold #4: (1 rounds) Logloss = 0.58255\n",
            "Avg. Logloss = 0.58236 +/- 0.00010\n",
            "[Time taken: 4.22s]\n",
            "\n",
            "CPU times: user 11.4 s, sys: 87.3 ms, total: 11.5 s\n",
            "Wall time: 8.23 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.logging.set_verbosity(optuna.logging.ERROR)"
      ],
      "metadata": {
        "id": "j6CPkw2AwBfu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exp 1"
      ],
      "metadata": {
        "id": "XEosvKAmzvvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op1, tp1 = run_experiment(\n",
        "    data=(train[features], train[TARGET], test[features]),\n",
        "    n_trials=200\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSTivemPzzNo",
        "outputId": "f3833884-832e-4767-acc0-50475913abbd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------Hyperparameter tuning----------\n",
            "Best trial: 174 -> Best value: 0.57972\n",
            "Best hyperparameters:\n",
            "learning_rate   - 0.225\n",
            "reg_alpha       - 4.3\n",
            "reg_lambda      - 163.8\n",
            "num_leaves      - 1640\n",
            "max_depth       - 7\n",
            "min_child_samples - 968\n",
            "min_split_gain  - 1.08\n",
            "colsample_bytree - 0.95\n",
            "top_rate        - 0.15000000000000002\n",
            "other_rate      - 0.2\n",
            "scale_pos_weight - 1.0\n",
            "max_cat_to_onehot - 2\n",
            "[Time taken: 472.37s]\n",
            "\n",
            "-----Cross-validation and prediction-----\n",
            "Fold #0: (13 rounds) Logloss = 0.58032\n",
            "Fold #1: (13 rounds) Logloss = 0.58109\n",
            "Fold #2: (53 rounds) Logloss = 0.57746\n",
            "Fold #3: (20 rounds) Logloss = 0.58051\n",
            "Fold #4: (51 rounds) Logloss = 0.57924\n",
            "Avg. Logloss = 0.57972 +/- 0.00128\n",
            "[Time taken: 2.71s]\n",
            "\n",
            "CPU times: user 14min 16s, sys: 5.29 s, total: 14min 21s\n",
            "Wall time: 7min 55s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exp 2"
      ],
      "metadata": {
        "id": "A3PbmLOsz5eN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op2, tp2 = run_experiment(\n",
        "    data=(train[original_features], train[TARGET], test[original_features]),\n",
        "    n_trials=200\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkMLAYWpz9i6",
        "outputId": "af0ceb58-85f1-494b-9ea9-c3bdb7f4f997"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------Hyperparameter tuning----------\n",
            "Best trial: 73 -> Best value: 0.58014\n",
            "Best hyperparameters:\n",
            "learning_rate   - 0.2\n",
            "reg_alpha       - 20.400000000000002\n",
            "reg_lambda      - 77.7\n",
            "num_leaves      - 1565\n",
            "max_depth       - 7\n",
            "min_child_samples - 716\n",
            "min_split_gain  - 0.04\n",
            "colsample_bytree - 0.95\n",
            "top_rate        - 0.25\n",
            "other_rate      - 0.15000000000000002\n",
            "scale_pos_weight - 1.0\n",
            "max_cat_to_onehot - 2\n",
            "[Time taken: 368.24s]\n",
            "\n",
            "-----Cross-validation and prediction-----\n",
            "Fold #0: (46 rounds) Logloss = 0.58049\n",
            "Fold #1: (9 rounds) Logloss = 0.58170\n",
            "Fold #2: (170 rounds) Logloss = 0.57886\n",
            "Fold #3: (31 rounds) Logloss = 0.58090\n",
            "Fold #4: (115 rounds) Logloss = 0.57876\n",
            "Avg. Logloss = 0.58014 +/- 0.00116\n",
            "[Time taken: 3.17s]\n",
            "\n",
            "CPU times: user 10min 55s, sys: 4.44 s, total: 10min 59s\n",
            "Wall time: 6min 11s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exp 3"
      ],
      "metadata": {
        "id": "gRM7h23vaukK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "op3, tp3 = run_experiment(\n",
        "    data=(train[cat_only_features], train[TARGET], test[cat_only_features]),\n",
        "    n_trials=200\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b707e846-5a3f-463e-af2e-9401c96a58d8",
        "id": "8xp6FNh1aukk"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------Hyperparameter tuning----------\n",
            "Best trial: 131 -> Best value: 0.57983\n",
            "Best hyperparameters:\n",
            "learning_rate   - 0.3\n",
            "reg_alpha       - 17.2\n",
            "reg_lambda      - 153.5\n",
            "num_leaves      - 1160\n",
            "max_depth       - 8\n",
            "min_child_samples - 980\n",
            "min_split_gain  - 0.29\n",
            "colsample_bytree - 0.5\n",
            "top_rate        - 0.2\n",
            "other_rate      - 0.3\n",
            "scale_pos_weight - 1.0\n",
            "max_cat_to_onehot - 2\n",
            "[Time taken: 380.67s]\n",
            "\n",
            "-----Cross-validation and prediction-----\n",
            "Fold #0: (25 rounds) Logloss = 0.58013\n",
            "Fold #1: (14 rounds) Logloss = 0.58074\n",
            "Fold #2: (82 rounds) Logloss = 0.57833\n",
            "Fold #3: (25 rounds) Logloss = 0.58078\n",
            "Fold #4: (182 rounds) Logloss = 0.57915\n",
            "Avg. Logloss = 0.57983 +/- 0.00095\n",
            "[Time taken: 3.27s]\n",
            "\n",
            "CPU times: user 11min 36s, sys: 4.04 s, total: 11min 40s\n",
            "Wall time: 6min 23s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission files"
      ],
      "metadata": {
        "id": "EahA1dJ47Z1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7npzUESt7bGc",
        "outputId": "32ff985b-631a-4126-9a11-71c52a3f94a5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NOTEBOOK = '03'\n",
        "SUBMISSION_PATH = f'/content/drive/MyDrive/data_science_competitions/machinehack/subscriber_prediction_hackathon/submissions/nb_{NOTEBOOK}'\n",
        "if not os.path.isdir(SUBMISSION_PATH):\n",
        "    os.makedirs(SUBMISSION_PATH)"
      ],
      "metadata": {
        "id": "Z39yNfKD7b95"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_submission_files(test_preds: pd.DataFrame, expt_num: int):\n",
        "    for col in (test_preds.columns):\n",
        "        sub = sample_sub.copy()\n",
        "        sub[TARGET] = test_preds[col]\n",
        "        sub.to_csv(f'{SUBMISSION_PATH}/{expt_num}_{col}.csv', index=False)"
      ],
      "metadata": {
        "id": "5y6XhjNx8OJT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_submission_files(tp1, '01')\n",
        "create_submission_files(tp2, '02')\n",
        "create_submission_files(tp3, '03')"
      ],
      "metadata": {
        "id": "Ii5dHRpk8Rve"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}